
diff --git a/code/my_functions.py b/code/my_functions.py
index 83c9aae..1d55af1 100644
--- a/code/my_functions.py
+++ b/code/my_functions.py
@@ -274,7 +274,7 @@ def similarity(query_tokens, query_ngrams, change, position, ngram, thresholds,
 
         ranked_list.append(temporary_list)
 
-
+#Query digits normalization and n-grams and tokens computation
 def query_normalization(query, ngrams):
     query_normalize = []
 
diff --git a/code/tests.py b/code/tests.py
index 67e329b..9b25953 100644
--- a/code/tests.py
+++ b/code/tests.py
@@ -6,15 +6,27 @@
     #walker.walk(printer, tree)
   #  print(tree.toStringTree())
     
-import csv
-from itertools import zip_longest
+import antlr4 
 
-def dataset_csv(list1, list2):
-    d = [list1, list2]
-    export_data = zip_longest(*d, fillvalue = '')
+import sys
+sys.path.insert(1, './code/antlr4')
+from SearchLexer import SearchLexer
+from SearchListener import SearchListener
+from SearchParser import SearchParser
 
-    with open('numbers.csv', 'w', encoding="ISO-8859-1", newline='') as myfile:
-        wr = csv.writer(myfile)
-        wr.writerow(("Normal", "Abstract"))
-        wr.writerows(export_data)
-    myfile.close()
+class SearchPrintListener(SearchListener):
+    def enterHi(self, ctx):
+        print("Hello: %s" % ctx.ID())
+
+def main(query):
+    lexer = SearchLexer(antlr4.InputStream(query))
+    stream = antlr4.CommonTokenStream(lexer)
+    parser = SearchParser(stream)
+    tree = parser.query()
+    printer = SearchPrintListener()
+    walker = antlr4.ParseTreeWalker()
+    walker.walk(printer, tree)
+    #print(tree.toStringTree())
+
+if __name__ == '__main__':
+    main('if(#ID<.>#OP<1>#LT<.>){ -> if(#ID<.>#OP<1>#LT<.>){<')
diff --git a/code/constants.py b/code/constants.py
index 8931387..d0a86e0 100644
--- a/code/constants.py
+++ b/code/constants.py
@@ -2,4 +2,4 @@
 #NORMAL: Clone repository from Github.com
 #TEST: Use local repository
 #FAST: Use directly a diff_changes.txt file
-MODE = "NORMAL"
\ No newline at end of file
+MODE = "FAST"
\ No newline at end of file
diff --git a/code/git_changes.txt b/code/git_changes.txt
new file mode 100644
index 0000000..3276ed5
--- /dev/null
+++ b/code/git_changes.txt
@@ -0,0 +1,59 @@
diff --git a/code/git_functions.py b/code/git_functions.py
index 72092d3..36e35a4 100644
--- a/code/git_functions.py
+++ b/code/git_functions.py
@@ -25,9 +25,9 @@ def git_clone():
 def git_log(repository):
     commit_log = []
 
-    command = "cd " + repository + "&& git log > ./code/git_log.txt"
+    command = "git log > ./test-changes/git_log.txt"
     os.system(command)
-    filename = repository + "./code/git_log.txt"
+    filename ="test-changes/git_log.txt"
 
     with open(filename) as fp:
         for line in fp:
@@ -45,9 +45,9 @@ def git_log(repository):
 #Compute the git diff
 def git_diff(commit_log, repository):
 
-    command = "echo '' > git_changes.txt"
+    command = "echo '' > ./test_changes/git_changes.txt"
     os.system(command)
 
     for i in commit_log:
-        command = "cd " + repository + "&& git diff " + i + " HEAD >> git_changes.txt"
+        command = "cd ./test-changes && git diff " + i + " HEAD >> git_changes.txt"
         os.system(command)
\ No newline at end of file
diff --git a/code/git_log.txt b/code/git_log.txt
new file mode 100644
index 0000000..a4fc5ab
--- /dev/null
+++ b/code/git_log.txt
@@ -0,0 +1,69 @@
+commit 996d90b9e5288a2bb5d925761bb66d1b4a78b7a5
+Author: lucadigrazia <luca.digrazia94@gmail.com>
+Date:   Thu Sep 26 15:02:09 2019 +0200
+
+    Some changes added
+
+commit 9a48cecdf12b9a8274e18e8657650dfec44752cc
+Author: lucadigrazia <luca.digrazia94@gmail.com>
+Date:   Thu Sep 26 14:39:33 2019 +0200
+
+    java test file
+
+commit 01015ab896759c43d04cc38c9ba3a5ee4f4bdc12
+Author: lucadigrazia <luca.digrazia94@gmail.com>
+Date:   Thu Sep 26 14:09:41 2019 +0200
+
+    Delete Area.java
+
+commit 52db44ce3950501d90a688fcc2131d2ed9251458
+Author: lucadigrazia <luca.digrazia94@gmail.com>
+Date:   Thu Sep 26 14:07:27 2019 +0200
+
+    New java file
+
+commit 62a946d41b1b39a4f619d572fe9956d47a2113fb
+Author: moz94 <luca.digrazia94@gmail.com>
+Date:   Mon Sep 16 10:09:14 2019 +0200
+
+    change return condition
+
+commit bef4d643886fa7da87ba9cda031e755858ca6841
+Author: moz94 <luca.digrazia94@gmail.com>
+Date:   Thu Sep 12 13:12:05 2019 +0200
+
+    Changes added
+    
+    - add method and call
+    - change method argument
+    - for conditions
+
+commit d67bdf625f07a0062ea57b650b9d8bac07fa99ed
+Author: moz94 <luca.digrazia94@gmail.com>
+Date:   Wed Sep 11 15:49:47 2019 +0200
+
+    Several changes added
+    
+    change if condition DONE
+    swap arguments DONE
+    insert null check DONE
+    change operation DONE
+    change return condition DONE
+
+commit 24ff5ccd06b08495163063470058172f5f8fe7ba
+Author: moz94 <luca.digrazia94@gmail.com>
+Date:   Wed Sep 11 14:56:04 2019 +0200
+
+    update branch condition
+
+commit d93336cd0d1453e03e2f82d907a5e99a6baf0843
+Author: moz94 <luca.digrazia94@gmail.com>
+Date:   Wed Sep 11 14:52:57 2019 +0200
+
+    if branch changes
+
+commit 175a57a92392f64685ef63f91db456cd63e637c1
+Author: ¨moz94¨ <¨luca.digrazia94@gmail.com¨>
+Date:   Wed Sep 11 14:32:52 2019 +0200
+
+    ¨first¨
diff --git a/code/main.py b/code/main.py
index abd7b52..c95c46d 100644
--- a/code/main.py
+++ b/code/main.py
@@ -31,10 +31,12 @@ def main():
     ngrams = 3
 
     #[0] cosine distance threshold [1] jaccard distance threshold
-    thresholds = [0.5, 0.5]
+    thresholds = [0.83, 0.8]
     ranked_list = []
 
     query_tokens, query_ngrams = my_functions.query_normalization(query,ngrams)
+
+    my_functions.dataset_csv(changes_list_real, changes_list_abstract)
     
     for change in changes_list_abstract:
         my_functions.similarity(query_tokens, query_ngrams, change, position, ngrams, thresholds, changes_list_real, ranked_list)
diff --git a/code/my_functions.py b/code/my_functions.py
index 6f28aac..1d55af1 100644
--- a/code/my_functions.py
+++ b/code/my_functions.py
@@ -7,6 +7,8 @@ from math import*
 from decimal import Decimal
 import copy
 from collections import Counter
+import csv
+from itertools import zip_longest
 import antlr4 
 
 import sys
@@ -272,7 +274,7 @@ def similarity(query_tokens, query_ngrams, change, position, ngram, thresholds,
 
         ranked_list.append(temporary_list)
 
-
+#Query digits normalization and n-grams and tokens computation
 def query_normalization(query, ngrams):
     query_normalize = []
 
@@ -317,4 +319,4 @@ def query_normalization(query, ngrams):
     query_ngrams = getNgrams(query_n, ngrams)
     
 
-    return query_tokens, query_ngrams
\ No newline at end of file
+    return query_tokens, query_ngrams
diff --git a/code/tests.py b/code/tests.py
index 6e72061..9b25953 100644
--- a/code/tests.py
+++ b/code/tests.py
@@ -1,41 +1,32 @@
+ #  stream = antlr4.CommonTokenStream(lexer)
+   # parser = SearchParser(stream)
+   # tree = parser.query()
+    #printer = SearchPrintListener()
+   # walker = antlr4.ParseTreeWalker()
+    #walker.walk(printer, tree)
+  #  print(tree.toStringTree())
+    
 import antlr4 
 
 import sys
-# insert at 1, 0 is the script path (or '' in REPL)
-sys.path.insert(1, './antlr4')
-
+sys.path.insert(1, './code/antlr4')
 from SearchLexer import SearchLexer
 from SearchListener import SearchListener
 from SearchParser import SearchParser
 
-#echo "3 * 3 - 2 + 2 * 2" | python main.py
-
 class SearchPrintListener(SearchListener):
-    def enterSearch(self, ctx):
-        print("Search: %s" % ctx.ID())
+    def enterHi(self, ctx):
+        print("Hello: %s" % ctx.ID())
 
-def antlr4_AbstractGrammar_Tokenizer(query):
+def main(query):
     lexer = SearchLexer(antlr4.InputStream(query))
-    list_abstract_token = []
-    while(1):
-        token = lexer.nextToken()
-        if(token.text == '<EOF>'):
-            break
-        list_abstract_token.append(token.text)
-
-    
-    for i in list_abstract_token:
-       print(i)
-
-    return list_abstract_token
-  #  stream = antlr4.CommonTokenStream(lexer)
-   # parser = SearchParser(stream)
-   # tree = parser.query()
-    #printer = SearchPrintListener()
-   # walker = antlr4.ParseTreeWalker()
-    #walker.walk(printer, tree)
-  #  print(tree.toStringTree())
-    
+    stream = antlr4.CommonTokenStream(lexer)
+    parser = SearchParser(stream)
+    tree = parser.query()
+    printer = SearchPrintListener()
+    walker = antlr4.ParseTreeWalker()
+    walker.walk(printer, tree)
+    #print(tree.toStringTree())
 
 if __name__ == '__main__':
-    antlr4_AbstractGrammar_Tokenizer('if(#ID<.>#OP<0>#N<.>) -> if(#ID<.>#OP<3>#N<.>)')
+    main('if(#ID<.>#OP<1>#LT<.>){ -> if(#ID<.>#OP<1>#LT<.>){<')
diff --git a/test-changes b/test-changes
deleted file mode 160000
index 8805699..0000000
--- a/test-changes
+++ /dev/null
@@ -1 +0,0 @@
-Subproject commit 880569952c329bd34cad07d382d831b7d1f5d8fb
diff --git a/code/antlr4/Search.g4 b/code/antlr4/Search.g4
index 5756186..dfdb50c 100644
--- a/code/antlr4/Search.g4
+++ b/code/antlr4/Search.g4
@@ -18,4 +18,5 @@ literal: '#LT<' digit* '>' | '#LT<!' digit* '>' | '#LT<.>';
 
 digit:  '0' | '1' | '2' | '3' | '4' | '5' | '6' |'7' | '8' | '9';
 
+
 WS:     [ \t\r\n]+ -> skip ;
\ No newline at end of file
diff --git a/code/example.txt b/code/example.txt
index 0a7289b..a8ab280 100644
--- a/code/example.txt
+++ b/code/example.txt
@@ -12,7 +12,8 @@ if(#ID<.>#OP<0>#LT<.>){->if(#ID<.>#OP<1>#LT<.>){
 if(#ID<.>#OP<.>#LT<0>){->if(#ID<.>#OP<.>#LT<1>){
 
 if(#ID<.>#OP<0>#LT<.>) -> if(#ID<.>#OP<!0>#LT<.>)
-if(#ID<.>#OP<.>#LT<0>) -> if(#ID<.>#OP<.>#LT<1>)
+if(#ID<.>#OP<1>#LT<.>) -> if(#ID<.>#OP<1>#LT<.>)
+if(#ID<.>#OP<1>#LT<.>){ -> if(#ID<.>#OP<1>#LT<.>){
 
 #ID<.>.#ID<.>(#LT<100>,#LT<21321>)->#ID<.>.#ID<.>(#LT<23222>,,#LT<2312313>
 
@@ -20,5 +21,3 @@ if(#ID<.>#OP<0>#LT<.>){ -> if(#ID<.>#OP<3>#LT<.>){
 if(#ID<.>#OP<1>#LT<.>) -> if(#ID<.>#OP<2>#LT<.>)
 for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<1>;#ID<.>#OP<.>)->for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<2>;#ID<.>#OP<.>)
 _ ->#ID<.>.#ID<.>(#LT<.>,#LT<.>);
-
-if(#ID<.>#OP<0>#N<.>) -> if(#ID<.>#OP<!0>#N<.>)
\ No newline at end of file
diff --git a/code/git_changes.txt b/code/git_changes.txt
index cdb8153..3276ed5 100644
--- a/code/git_changes.txt
+++ b/code/git_changes.txt
@@ -33,45 +33,27 @@ index d58db74..f1c27f0 100644
         }
 
 

diff --git a/code/git_functions.py b/code/git_functions.py
index 059745e..36e35a4 100644
--- a/code/git_functions.py
+++ b/code/git_functions.py
@@ -25,9 +25,9 @@ def git_clone():
 def git_log(repository):
     commit_log = []
 
-    command = "cd " + repository + "&& git log > git_log.txt"
+    command = "git log > ./test-changes/git_log.txt"
     os.system(command)
-    filename = repository + "/git_log.txt"
+    filename ="test-changes/git_log.txt"
 
     with open(filename) as fp:
         for line in fp:
@@ -45,9 +45,9 @@ def git_log(repository):
 #Compute the git diff
 def git_diff(commit_log, repository):
 
-    command = "echo '' > git_changes.txt"
+    command = "echo '' > ./test_changes/git_changes.txt"
     os.system(command)
 
     for i in commit_log:
-        command = "cd " + repository + "&& git diff " + i + " HEAD >> git_changes.txt"
+        command = "cd ./test-changes && git diff " + i + " HEAD >> git_changes.txt"
         os.system(command)
\ No newline at end of file
diff --git a/code/main.py b/code/main.py
index 1db9616..c95c46d 100644
--- a/code/main.py
+++ b/code/main.py
@@ -29,14 +29,26 @@ def main():
     #Computation of similarity in different ways(cosine distance and jaccard index)
     position = 0
     ngrams = 3
+
     #[0] cosine distance threshold [1] jaccard distance threshold
     thresholds = [0.83, 0.8]
+    ranked_list = []
 
-    print("\nThe changes found are:\n ")
+    query_tokens, query_ngrams = my_functions.query_normalization(query,ngrams)
+
+    my_functions.dataset_csv(changes_list_real, changes_list_abstract)
+    
     for change in changes_list_abstract:
-        my_functions.similarity(query.replace(' ', '').replace('\n', ''), change, position, ngrams, thresholds, changes_list_real)
+        my_functions.similarity(query_tokens, query_ngrams, change, position, ngrams, thresholds, changes_list_real, ranked_list)
         position += 1
 
+    # sort list with key
+    ranked_list.sort(reverse=True, key=my_functions.takeSecond)
+
+    print("\nThe changes found are:\n ")
+    for i in ranked_list:
+        print(i[0] + ' cosine: ' + i[1] + ' jaccard: ' +  i[2])
+
     #Programs ends
     end = time.time()
     print("\nThe program ends in:", round(end - start_time,1), "seconds. Total changes in the repository: ", position) 
diff --git a/code/my_functions.py b/code/my_functions.py
index 3ed184d..1d55af1 100644
--- a/code/my_functions.py
+++ b/code/my_functions.py
@@ -7,6 +7,8 @@ from math import*
 from decimal import Decimal
 import copy
 from collections import Counter
+import csv
+from itertools import zip_longest
 import antlr4 
 
 import sys
@@ -22,6 +24,10 @@ def diff(first, second):
     else:
         return [i for i in range(len(first)) if first[i] != second[i]]
 
+#Take second element for list sorting key
+def takeSecond(elem):
+    return elem[1]
+    
 #Compute ngram of a string
 def ngram(change, ngrams):
     ngrams_list = {}
@@ -178,20 +184,20 @@ def scanner(changes_list):
                         
                     if token == '+' or token =='-' or token =='*' or token == '--' or token == '++' or token =='/' or token =='<' or token =='>' or token =='<=' or token =='>=' or token =='==' or token =='!=' or token =='&&' or token =='||':
                         if(count in diff1 and bool == False):
-                            new[count] = '#OP<!' + str(n_op) + '>'
+                            new[count] = '#OP<' + str(n_op) + '>'
                             n_op = n_op + 1
                         else:
                             new[count] = '#OP<.>'
                     else:
                         if token.isdigit():
                             if(count in diff1 and bool == False):
-                                new[count] = '#LT<!' + str(n_num) + '>'
+                                new[count] = '#LT<' + str(n_num) + '>'
                                 n_num = n_num + 1 
                             else:    
                                 new[count] = '#LT<.>'
                         else: 
                             if(count in diff1 and bool == False):
-                                new[count] = '#ID<!' + str(n_id) + '>'
+                                new[count] = '#ID<' + str(n_id) + '>'
                                 n_id = n_id + 1 
                             else:  
                                 new[count] = '#ID<.>'
@@ -247,16 +253,70 @@ def jaccard_similarity(x,y):
     return intersection/float(union)
 
 #Compute the similarity between query and one change using different similarity algorithm. Print the change if over thresholds 
-def similarity(query, change, position, ngram, thresholds, changes_list_real):
+def similarity(query_tokens, query_ngrams, change, position, ngram, thresholds, changes_list_real, ranked_list):
+
+    temporary_list = []
 
-    ngrams_list1 = getNgrams(query, ngram)
+    #ngrams_list1 = getNgrams(query, ngram)
     ngrams_list2 = getNgrams(change, ngram)
 
-    abstract_tokens1 = antlr4_AbstractGrammar_Tokenizer(query)
+    #abstract_tokens1 = antlr4_AbstractGrammar_Tokenizer(query)
     abstract_tokens2 = antlr4_AbstractGrammar_Tokenizer(change)
 
-    cosine_score = cosine_similarity_ngrams(ngrams_list1,ngrams_list2)
-    jaccard_score = jaccard_similarity(abstract_tokens1, abstract_tokens2)
+    cosine_score = cosine_similarity_ngrams(query_ngrams,ngrams_list2)
+    jaccard_score = jaccard_similarity(query_tokens, abstract_tokens2)
    
     if cosine_score > thresholds[0] and jaccard_score > thresholds[1] :
-        print(changes_list_real[position] + ' cosine: ' + str(round(cosine_score,2)) + ' jaccard: ' + str(round(jaccard_score,2)))#+ ' eucledian: ' + str(round(eucledian_score,2)))
+        
+        temporary_list.append(changes_list_real[position])
+        temporary_list.append(str(round(cosine_score,2)))
+        temporary_list.append(str(round(jaccard_score,2)))
+
+        ranked_list.append(temporary_list)
+
+#Query digits normalization and n-grams and tokens computation
+def query_normalization(query, ngrams):
+    query_normalize = []
+
+    id = 0
+    op = 0
+    lt = 0
+    n = 0
+    l = len(str(query))
+
+    for n in range(0, l):
+        if(query[n] == '-'):
+                id = 0
+                op = 0
+                lt = 0
+
+                query_normalize.append(query[n])
+        else:
+            if query[n].isdigit():
+                if(n > 1):
+                    if(query[n-2] == 'D'):
+                        query_normalize.append(str(id))
+                        id += 1
+                    else:
+                        if(query[n-2] == 'P'):
+                            query_normalize.append(str(op))
+                            op += 1
+                        else:
+                           # if(query[n-2] == 'T'):
+                                query_normalize.append(str(lt))
+                                lt += 1
+                else: 
+                    query_normalize.append(query[n])
+            else: 
+                    query_normalize.append(query[n])
+
+        
+        n += 1
+
+    query_n = ''.join(query_normalize).replace(' ', '').replace('\n', '')
+
+    query_tokens = antlr4_AbstractGrammar_Tokenizer(query_n)
+    query_ngrams = getNgrams(query_n, ngrams)
+    
+
+    return query_tokens, query_ngrams
diff --git a/code/tests.py b/code/tests.py
index 6e72061..9b25953 100644
--- a/code/tests.py
+++ b/code/tests.py
@@ -1,41 +1,32 @@
+ #  stream = antlr4.CommonTokenStream(lexer)
+   # parser = SearchParser(stream)
+   # tree = parser.query()
+    #printer = SearchPrintListener()
+   # walker = antlr4.ParseTreeWalker()
+    #walker.walk(printer, tree)
+  #  print(tree.toStringTree())
+    
 import antlr4 
 
 import sys
-# insert at 1, 0 is the script path (or '' in REPL)
-sys.path.insert(1, './antlr4')
-
+sys.path.insert(1, './code/antlr4')
 from SearchLexer import SearchLexer
 from SearchListener import SearchListener
 from SearchParser import SearchParser
 
-#echo "3 * 3 - 2 + 2 * 2" | python main.py
-
 class SearchPrintListener(SearchListener):
-    def enterSearch(self, ctx):
-        print("Search: %s" % ctx.ID())
+    def enterHi(self, ctx):
+        print("Hello: %s" % ctx.ID())
 
-def antlr4_AbstractGrammar_Tokenizer(query):
+def main(query):
     lexer = SearchLexer(antlr4.InputStream(query))
-    list_abstract_token = []
-    while(1):
-        token = lexer.nextToken()
-        if(token.text == '<EOF>'):
-            break
-        list_abstract_token.append(token.text)
-
-    
-    for i in list_abstract_token:
-       print(i)
-
-    return list_abstract_token
-  #  stream = antlr4.CommonTokenStream(lexer)
-   # parser = SearchParser(stream)
-   # tree = parser.query()
-    #printer = SearchPrintListener()
-   # walker = antlr4.ParseTreeWalker()
-    #walker.walk(printer, tree)
-  #  print(tree.toStringTree())
-    
+    stream = antlr4.CommonTokenStream(lexer)
+    parser = SearchParser(stream)
+    tree = parser.query()
+    printer = SearchPrintListener()
+    walker = antlr4.ParseTreeWalker()
+    walker.walk(printer, tree)
+    #print(tree.toStringTree())
 
 if __name__ == '__main__':
-    antlr4_AbstractGrammar_Tokenizer('if(#ID<.>#OP<0>#N<.>) -> if(#ID<.>#OP<3>#N<.>)')
+    main('if(#ID<.>#OP<1>#LT<.>){ -> if(#ID<.>#OP<1>#LT<.>){<')
diff --git a/code/antlr4/.antlr/Search.interp b/code/antlr4/.antlr/Search.interp
new file mode 100644
index 0000000..b739ec4
--- /dev/null
+++ b/code/antlr4/.antlr/Search.interp
@@ -0,0 +1,102 @@
+token literal names:
+null
+'->'
+'_'
+'if'
+'else'
+'for'
+'forEach'
+'while'
+'return'
+'NULL'
+'('
+')'
+'['
+']'
+'{'
+'}'
+'"'
+'='
+'.'
+','
+';'
+'#ID<'
+'>'
+'#ID<!'
+'#ID<.>'
+'#OP<'
+'#OP<!'
+'#OP<.>'
+'#LT<'
+'#LT<!'
+'#LT<.>'
+'0'
+'1'
+'2'
+'3'
+'4'
+'5'
+'6'
+'7'
+'8'
+'9'
+null
+
+token symbolic names:
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+WS
+
+rule names:
+query
+code
+token
+keyword
+punctuator
+identifier
+operator
+literal
+digit
+
+
+atn:
+[3, 24715, 42794, 33075, 47597, 16764, 15335, 30598, 22884, 3, 43, 138, 4, 2, 9, 2, 4, 3, 9, 3, 4, 4, 9, 4, 4, 5, 9, 5, 4, 6, 9, 6, 4, 7, 9, 7, 4, 8, 9, 8, 4, 9, 9, 9, 4, 10, 9, 10, 3, 2, 3, 2, 3, 2, 3, 2, 3, 3, 7, 3, 26, 10, 3, 12, 3, 14, 3, 29, 11, 3, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 5, 4, 37, 10, 4, 3, 5, 3, 5, 3, 6, 3, 6, 7, 6, 43, 10, 6, 12, 6, 14, 6, 46, 11, 6, 3, 6, 3, 6, 3, 6, 7, 6, 51, 10, 6, 12, 6, 14, 6, 54, 11, 6, 3, 6, 3, 6, 3, 6, 7, 6, 59, 10, 6, 12, 6, 14, 6, 62, 11, 6, 3, 6, 3, 6, 3, 6, 7, 6, 67, 10, 6, 12, 6, 14, 6, 70, 11, 6, 3, 6, 3, 6, 3, 6, 3, 6, 3, 6, 5, 6, 77, 10, 6, 3, 7, 3, 7, 7, 7, 81, 10, 7, 12, 7, 14, 7, 84, 11, 7, 3, 7, 3, 7, 3, 7, 7, 7, 89, 10, 7, 12, 7, 14, 7, 92, 11, 7, 3, 7, 3, 7, 5, 7, 96, 10, 7, 3, 8, 3, 8, 7, 8, 100, 10, 8, 12, 8, 14, 8, 103, 11, 8, 3, 8, 3, 8, 3, 8, 7, 8, 108, 10, 8, 12, 8, 14, 8, 111, 11, 8, 3, 8, 3, 8, 5, 8, 115, 10, 8, 3, 9, 3, 9, 7, 9, 119, 10, 9, 12, 9, 14, 9, 122, 11, 9, 3, 9, 3, 9, 3, 9, 7, 9, 127, 10, 9, 12, 9, 14, 9, 130, 11, 9, 3, 9, 3, 9, 5, 9, 134, 10, 9, 3, 10, 3, 10, 3, 10, 2, 2, 11, 2, 4, 6, 8, 10, 12, 14, 16, 18, 2, 4, 3, 2, 5, 11, 3, 2, 33, 42, 2, 157, 2, 20, 3, 2, 2, 2, 4, 27, 3, 2, 2, 2, 6, 36, 3, 2, 2, 2, 8, 38, 3, 2, 2, 2, 10, 76, 3, 2, 2, 2, 12, 95, 3, 2, 2, 2, 14, 114, 3, 2, 2, 2, 16, 133, 3, 2, 2, 2, 18, 135, 3, 2, 2, 2, 20, 21, 5, 4, 3, 2, 21, 22, 7, 3, 2, 2, 22, 23, 5, 4, 3, 2, 23, 3, 3, 2, 2, 2, 24, 26, 5, 6, 4, 2, 25, 24, 3, 2, 2, 2, 26, 29, 3, 2, 2, 2, 27, 25, 3, 2, 2, 2, 27, 28, 3, 2, 2, 2, 28, 5, 3, 2, 2, 2, 29, 27, 3, 2, 2, 2, 30, 37, 5, 12, 7, 2, 31, 37, 5, 8, 5, 2, 32, 37, 5, 10, 6, 2, 33, 37, 5, 14, 8, 2, 34, 37, 5, 16, 9, 2, 35, 37, 7, 4, 2, 2, 36, 30, 3, 2, 2, 2, 36, 31, 3, 2, 2, 2, 36, 32, 3, 2, 2, 2, 36, 33, 3, 2, 2, 2, 36, 34, 3, 2, 2, 2, 36, 35, 3, 2, 2, 2, 37, 7, 3, 2, 2, 2, 38, 39, 9, 2, 2, 2, 39, 9, 3, 2, 2, 2, 40, 44, 7, 12, 2, 2, 41, 43, 5, 6, 4, 2, 42, 41, 3, 2, 2, 2, 43, 46, 3, 2, 2, 2, 44, 42, 3, 2, 2, 2, 44, 45, 3, 2, 2, 2, 45, 47, 3, 2, 2, 2, 46, 44, 3, 2, 2, 2, 47, 77, 7, 13, 2, 2, 48, 52, 7, 14, 2, 2, 49, 51, 5, 6, 4, 2, 50, 49, 3, 2, 2, 2, 51, 54, 3, 2, 2, 2, 52, 50, 3, 2, 2, 2, 52, 53, 3, 2, 2, 2, 53, 55, 3, 2, 2, 2, 54, 52, 3, 2, 2, 2, 55, 77, 7, 15, 2, 2, 56, 60, 7, 16, 2, 2, 57, 59, 5, 6, 4, 2, 58, 57, 3, 2, 2, 2, 59, 62, 3, 2, 2, 2, 60, 58, 3, 2, 2, 2, 60, 61, 3, 2, 2, 2, 61, 63, 3, 2, 2, 2, 62, 60, 3, 2, 2, 2, 63, 77, 7, 17, 2, 2, 64, 68, 7, 18, 2, 2, 65, 67, 5, 6, 4, 2, 66, 65, 3, 2, 2, 2, 67, 70, 3, 2, 2, 2, 68, 66, 3, 2, 2, 2, 68, 69, 3, 2, 2, 2, 69, 71, 3, 2, 2, 2, 70, 68, 3, 2, 2, 2, 71, 77, 7, 18, 2, 2, 72, 77, 7, 19, 2, 2, 73, 77, 7, 20, 2, 2, 74, 77, 7, 21, 2, 2, 75, 77, 7, 22, 2, 2, 76, 40, 3, 2, 2, 2, 76, 48, 3, 2, 2, 2, 76, 56, 3, 2, 2, 2, 76, 64, 3, 2, 2, 2, 76, 72, 3, 2, 2, 2, 76, 73, 3, 2, 2, 2, 76, 74, 3, 2, 2, 2, 76, 75, 3, 2, 2, 2, 77, 11, 3, 2, 2, 2, 78, 82, 7, 23, 2, 2, 79, 81, 5, 18, 10, 2, 80, 79, 3, 2, 2, 2, 81, 84, 3, 2, 2, 2, 82, 80, 3, 2, 2, 2, 82, 83, 3, 2, 2, 2, 83, 85, 3, 2, 2, 2, 84, 82, 3, 2, 2, 2, 85, 96, 7, 24, 2, 2, 86, 90, 7, 25, 2, 2, 87, 89, 5, 18, 10, 2, 88, 87, 3, 2, 2, 2, 89, 92, 3, 2, 2, 2, 90, 88, 3, 2, 2, 2, 90, 91, 3, 2, 2, 2, 91, 93, 3, 2, 2, 2, 92, 90, 3, 2, 2, 2, 93, 96, 7, 24, 2, 2, 94, 96, 7, 26, 2, 2, 95, 78, 3, 2, 2, 2, 95, 86, 3, 2, 2, 2, 95, 94, 3, 2, 2, 2, 96, 13, 3, 2, 2, 2, 97, 101, 7, 27, 2, 2, 98, 100, 5, 18, 10, 2, 99, 98, 3, 2, 2, 2, 100, 103, 3, 2, 2, 2, 101, 99, 3, 2, 2, 2, 101, 102, 3, 2, 2, 2, 102, 104, 3, 2, 2, 2, 103, 101, 3, 2, 2, 2, 104, 115, 7, 24, 2, 2, 105, 109, 7, 28, 2, 2, 106, 108, 5, 18, 10, 2, 107, 106, 3, 2, 2, 2, 108, 111, 3, 2, 2, 2, 109, 107, 3, 2, 2, 2, 109, 110, 3, 2, 2, 2, 110, 112, 3, 2, 2, 2, 111, 109, 3, 2, 2, 2, 112, 115, 7, 24, 2, 2, 113, 115, 7, 29, 2, 2, 114, 97, 3, 2, 2, 2, 114, 105, 3, 2, 2, 2, 114, 113, 3, 2, 2, 2, 115, 15, 3, 2, 2, 2, 116, 120, 7, 30, 2, 2, 117, 119, 5, 18, 10, 2, 118, 117, 3, 2, 2, 2, 119, 122, 3, 2, 2, 2, 120, 118, 3, 2, 2, 2, 120, 121, 3, 2, 2, 2, 121, 123, 3, 2, 2, 2, 122, 120, 3, 2, 2, 2, 123, 134, 7, 24, 2, 2, 124, 128, 7, 31, 2, 2, 125, 127, 5, 18, 10, 2, 126, 125, 3, 2, 2, 2, 127, 130, 3, 2, 2, 2, 128, 126, 3, 2, 2, 2, 128, 129, 3, 2, 2, 2, 129, 131, 3, 2, 2, 2, 130, 128, 3, 2, 2, 2, 131, 134, 7, 24, 2, 2, 132, 134, 7, 32, 2, 2, 133, 116, 3, 2, 2, 2, 133, 124, 3, 2, 2, 2, 133, 132, 3, 2, 2, 2, 134, 17, 3, 2, 2, 2, 135, 136, 9, 3, 2, 2, 136, 19, 3, 2, 2, 2, 18, 27, 36, 44, 52, 60, 68, 76, 82, 90, 95, 101, 109, 114, 120, 128, 133]
\ No newline at end of file
diff --git a/code/antlr4/.antlr/Search.tokens b/code/antlr4/.antlr/Search.tokens
new file mode 100644
index 0000000..372bf0c
--- /dev/null
+++ b/code/antlr4/.antlr/Search.tokens
@@ -0,0 +1,81 @@
+T__0=1
+T__1=2
+T__2=3
+T__3=4
+T__4=5
+T__5=6
+T__6=7
+T__7=8
+T__8=9
+T__9=10
+T__10=11
+T__11=12
+T__12=13
+T__13=14
+T__14=15
+T__15=16
+T__16=17
+T__17=18
+T__18=19
+T__19=20
+T__20=21
+T__21=22
+T__22=23
+T__23=24
+T__24=25
+T__25=26
+T__26=27
+T__27=28
+T__28=29
+T__29=30
+T__30=31
+T__31=32
+T__32=33
+T__33=34
+T__34=35
+T__35=36
+T__36=37
+T__37=38
+T__38=39
+T__39=40
+WS=41
+'->'=1
+'_'=2
+'if'=3
+'else'=4
+'for'=5
+'forEach'=6
+'while'=7
+'return'=8
+'NULL'=9
+'('=10
+')'=11
+'['=12
+']'=13
+'{'=14
+'}'=15
+'"'=16
+'='=17
+'.'=18
+','=19
+';'=20
+'#ID<'=21
+'>'=22
+'#ID<!'=23
+'#ID<.>'=24
+'#OP<'=25
+'#OP<!'=26
+'#OP<.>'=27
+'#LT<'=28
+'#LT<!'=29
+'#LT<.>'=30
+'0'=31
+'1'=32
+'2'=33
+'3'=34
+'4'=35
+'5'=36
+'6'=37
+'7'=38
+'8'=39
+'9'=40
diff --git a/code/antlr4/.antlr/SearchLexer.interp b/code/antlr4/.antlr/SearchLexer.interp
new file mode 100644
index 0000000..062f29e
--- /dev/null
+++ b/code/antlr4/.antlr/SearchLexer.interp
@@ -0,0 +1,140 @@
+token literal names:
+null
+'->'
+'_'
+'if'
+'else'
+'for'
+'forEach'
+'while'
+'return'
+'NULL'
+'('
+')'
+'['
+']'
+'{'
+'}'
+'"'
+'='
+'.'
+','
+';'
+'#ID<'
+'>'
+'#ID<!'
+'#ID<.>'
+'#OP<'
+'#OP<!'
+'#OP<.>'
+'#LT<'
+'#LT<!'
+'#LT<.>'
+'0'
+'1'
+'2'
+'3'
+'4'
+'5'
+'6'
+'7'
+'8'
+'9'
+null
+
+token symbolic names:
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+WS
+
+rule names:
+T__0
+T__1
+T__2
+T__3
+T__4
+T__5
+T__6
+T__7
+T__8
+T__9
+T__10
+T__11
+T__12
+T__13
+T__14
+T__15
+T__16
+T__17
+T__18
+T__19
+T__20
+T__21
+T__22
+T__23
+T__24
+T__25
+T__26
+T__27
+T__28
+T__29
+T__30
+T__31
+T__32
+T__33
+T__34
+T__35
+T__36
+T__37
+T__38
+T__39
+WS
+
+channel names:
+DEFAULT_TOKEN_CHANNEL
+HIDDEN
+
+mode names:
+DEFAULT_MODE
+
+atn:
+[3, 24715, 42794, 33075, 47597, 16764, 15335, 30598, 22884, 2, 43, 233, 8, 1, 4, 2, 9, 2, 4, 3, 9, 3, 4, 4, 9, 4, 4, 5, 9, 5, 4, 6, 9, 6, 4, 7, 9, 7, 4, 8, 9, 8, 4, 9, 9, 9, 4, 10, 9, 10, 4, 11, 9, 11, 4, 12, 9, 12, 4, 13, 9, 13, 4, 14, 9, 14, 4, 15, 9, 15, 4, 16, 9, 16, 4, 17, 9, 17, 4, 18, 9, 18, 4, 19, 9, 19, 4, 20, 9, 20, 4, 21, 9, 21, 4, 22, 9, 22, 4, 23, 9, 23, 4, 24, 9, 24, 4, 25, 9, 25, 4, 26, 9, 26, 4, 27, 9, 27, 4, 28, 9, 28, 4, 29, 9, 29, 4, 30, 9, 30, 4, 31, 9, 31, 4, 32, 9, 32, 4, 33, 9, 33, 4, 34, 9, 34, 4, 35, 9, 35, 4, 36, 9, 36, 4, 37, 9, 37, 4, 38, 9, 38, 4, 39, 9, 39, 4, 40, 9, 40, 4, 41, 9, 41, 4, 42, 9, 42, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 6, 3, 6, 3, 6, 3, 6, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 8, 3, 8, 3, 8, 3, 8, 3, 8, 3, 8, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3, 10, 3, 10, 3, 10, 3, 10, 3, 10, 3, 11, 3, 11, 3, 12, 3, 12, 3, 13, 3, 13, 3, 14, 3, 14, 3, 15, 3, 15, 3, 16, 3, 16, 3, 17, 3, 17, 3, 18, 3, 18, 3, 19, 3, 19, 3, 20, 3, 20, 3, 21, 3, 21, 3, 22, 3, 22, 3, 22, 3, 22, 3, 22, 3, 23, 3, 23, 3, 24, 3, 24, 3, 24, 3, 24, 3, 24, 3, 24, 3, 25, 3, 25, 3, 25, 3, 25, 3, 25, 3, 25, 3, 25, 3, 26, 3, 26, 3, 26, 3, 26, 3, 26, 3, 27, 3, 27, 3, 27, 3, 27, 3, 27, 3, 27, 3, 28, 3, 28, 3, 28, 3, 28, 3, 28, 3, 28, 3, 28, 3, 29, 3, 29, 3, 29, 3, 29, 3, 29, 3, 30, 3, 30, 3, 30, 3, 30, 3, 30, 3, 30, 3, 31, 3, 31, 3, 31, 3, 31, 3, 31, 3, 31, 3, 31, 3, 32, 3, 32, 3, 33, 3, 33, 3, 34, 3, 34, 3, 35, 3, 35, 3, 36, 3, 36, 3, 37, 3, 37, 3, 38, 3, 38, 3, 39, 3, 39, 3, 40, 3, 40, 3, 41, 3, 41, 3, 42, 6, 42, 228, 10, 42, 13, 42, 14, 42, 229, 3, 42, 3, 42, 2, 2, 43, 3, 3, 5, 4, 7, 5, 9, 6, 11, 7, 13, 8, 15, 9, 17, 10, 19, 11, 21, 12, 23, 13, 25, 14, 27, 15, 29, 16, 31, 17, 33, 18, 35, 19, 37, 20, 39, 21, 41, 22, 43, 23, 45, 24, 47, 25, 49, 26, 51, 27, 53, 28, 55, 29, 57, 30, 59, 31, 61, 32, 63, 33, 65, 34, 67, 35, 69, 36, 71, 37, 73, 38, 75, 39, 77, 40, 79, 41, 81, 42, 83, 43, 3, 2, 3, 5, 2, 11, 12, 15, 15, 34, 34, 2, 233, 2, 3, 3, 2, 2, 2, 2, 5, 3, 2, 2, 2, 2, 7, 3, 2, 2, 2, 2, 9, 3, 2, 2, 2, 2, 11, 3, 2, 2, 2, 2, 13, 3, 2, 2, 2, 2, 15, 3, 2, 2, 2, 2, 17, 3, 2, 2, 2, 2, 19, 3, 2, 2, 2, 2, 21, 3, 2, 2, 2, 2, 23, 3, 2, 2, 2, 2, 25, 3, 2, 2, 2, 2, 27, 3, 2, 2, 2, 2, 29, 3, 2, 2, 2, 2, 31, 3, 2, 2, 2, 2, 33, 3, 2, 2, 2, 2, 35, 3, 2, 2, 2, 2, 37, 3, 2, 2, 2, 2, 39, 3, 2, 2, 2, 2, 41, 3, 2, 2, 2, 2, 43, 3, 2, 2, 2, 2, 45, 3, 2, 2, 2, 2, 47, 3, 2, 2, 2, 2, 49, 3, 2, 2, 2, 2, 51, 3, 2, 2, 2, 2, 53, 3, 2, 2, 2, 2, 55, 3, 2, 2, 2, 2, 57, 3, 2, 2, 2, 2, 59, 3, 2, 2, 2, 2, 61, 3, 2, 2, 2, 2, 63, 3, 2, 2, 2, 2, 65, 3, 2, 2, 2, 2, 67, 3, 2, 2, 2, 2, 69, 3, 2, 2, 2, 2, 71, 3, 2, 2, 2, 2, 73, 3, 2, 2, 2, 2, 75, 3, 2, 2, 2, 2, 77, 3, 2, 2, 2, 2, 79, 3, 2, 2, 2, 2, 81, 3, 2, 2, 2, 2, 83, 3, 2, 2, 2, 3, 85, 3, 2, 2, 2, 5, 88, 3, 2, 2, 2, 7, 90, 3, 2, 2, 2, 9, 93, 3, 2, 2, 2, 11, 98, 3, 2, 2, 2, 13, 102, 3, 2, 2, 2, 15, 110, 3, 2, 2, 2, 17, 116, 3, 2, 2, 2, 19, 123, 3, 2, 2, 2, 21, 128, 3, 2, 2, 2, 23, 130, 3, 2, 2, 2, 25, 132, 3, 2, 2, 2, 27, 134, 3, 2, 2, 2, 29, 136, 3, 2, 2, 2, 31, 138, 3, 2, 2, 2, 33, 140, 3, 2, 2, 2, 35, 142, 3, 2, 2, 2, 37, 144, 3, 2, 2, 2, 39, 146, 3, 2, 2, 2, 41, 148, 3, 2, 2, 2, 43, 150, 3, 2, 2, 2, 45, 155, 3, 2, 2, 2, 47, 157, 3, 2, 2, 2, 49, 163, 3, 2, 2, 2, 51, 170, 3, 2, 2, 2, 53, 175, 3, 2, 2, 2, 55, 181, 3, 2, 2, 2, 57, 188, 3, 2, 2, 2, 59, 193, 3, 2, 2, 2, 61, 199, 3, 2, 2, 2, 63, 206, 3, 2, 2, 2, 65, 208, 3, 2, 2, 2, 67, 210, 3, 2, 2, 2, 69, 212, 3, 2, 2, 2, 71, 214, 3, 2, 2, 2, 73, 216, 3, 2, 2, 2, 75, 218, 3, 2, 2, 2, 77, 220, 3, 2, 2, 2, 79, 222, 3, 2, 2, 2, 81, 224, 3, 2, 2, 2, 83, 227, 3, 2, 2, 2, 85, 86, 7, 47, 2, 2, 86, 87, 7, 64, 2, 2, 87, 4, 3, 2, 2, 2, 88, 89, 7, 97, 2, 2, 89, 6, 3, 2, 2, 2, 90, 91, 7, 107, 2, 2, 91, 92, 7, 104, 2, 2, 92, 8, 3, 2, 2, 2, 93, 94, 7, 103, 2, 2, 94, 95, 7, 110, 2, 2, 95, 96, 7, 117, 2, 2, 96, 97, 7, 103, 2, 2, 97, 10, 3, 2, 2, 2, 98, 99, 7, 104, 2, 2, 99, 100, 7, 113, 2, 2, 100, 101, 7, 116, 2, 2, 101, 12, 3, 2, 2, 2, 102, 103, 7, 104, 2, 2, 103, 104, 7, 113, 2, 2, 104, 105, 7, 116, 2, 2, 105, 106, 7, 71, 2, 2, 106, 107, 7, 99, 2, 2, 107, 108, 7, 101, 2, 2, 108, 109, 7, 106, 2, 2, 109, 14, 3, 2, 2, 2, 110, 111, 7, 121, 2, 2, 111, 112, 7, 106, 2, 2, 112, 113, 7, 107, 2, 2, 113, 114, 7, 110, 2, 2, 114, 115, 7, 103, 2, 2, 115, 16, 3, 2, 2, 2, 116, 117, 7, 116, 2, 2, 117, 118, 7, 103, 2, 2, 118, 119, 7, 118, 2, 2, 119, 120, 7, 119, 2, 2, 120, 121, 7, 116, 2, 2, 121, 122, 7, 112, 2, 2, 122, 18, 3, 2, 2, 2, 123, 124, 7, 80, 2, 2, 124, 125, 7, 87, 2, 2, 125, 126, 7, 78, 2, 2, 126, 127, 7, 78, 2, 2, 127, 20, 3, 2, 2, 2, 128, 129, 7, 42, 2, 2, 129, 22, 3, 2, 2, 2, 130, 131, 7, 43, 2, 2, 131, 24, 3, 2, 2, 2, 132, 133, 7, 93, 2, 2, 133, 26, 3, 2, 2, 2, 134, 135, 7, 95, 2, 2, 135, 28, 3, 2, 2, 2, 136, 137, 7, 125, 2, 2, 137, 30, 3, 2, 2, 2, 138, 139, 7, 127, 2, 2, 139, 32, 3, 2, 2, 2, 140, 141, 7, 36, 2, 2, 141, 34, 3, 2, 2, 2, 142, 143, 7, 63, 2, 2, 143, 36, 3, 2, 2, 2, 144, 145, 7, 48, 2, 2, 145, 38, 3, 2, 2, 2, 146, 147, 7, 46, 2, 2, 147, 40, 3, 2, 2, 2, 148, 149, 7, 61, 2, 2, 149, 42, 3, 2, 2, 2, 150, 151, 7, 37, 2, 2, 151, 152, 7, 75, 2, 2, 152, 153, 7, 70, 2, 2, 153, 154, 7, 62, 2, 2, 154, 44, 3, 2, 2, 2, 155, 156, 7, 64, 2, 2, 156, 46, 3, 2, 2, 2, 157, 158, 7, 37, 2, 2, 158, 159, 7, 75, 2, 2, 159, 160, 7, 70, 2, 2, 160, 161, 7, 62, 2, 2, 161, 162, 7, 35, 2, 2, 162, 48, 3, 2, 2, 2, 163, 164, 7, 37, 2, 2, 164, 165, 7, 75, 2, 2, 165, 166, 7, 70, 2, 2, 166, 167, 7, 62, 2, 2, 167, 168, 7, 48, 2, 2, 168, 169, 7, 64, 2, 2, 169, 50, 3, 2, 2, 2, 170, 171, 7, 37, 2, 2, 171, 172, 7, 81, 2, 2, 172, 173, 7, 82, 2, 2, 173, 174, 7, 62, 2, 2, 174, 52, 3, 2, 2, 2, 175, 176, 7, 37, 2, 2, 176, 177, 7, 81, 2, 2, 177, 178, 7, 82, 2, 2, 178, 179, 7, 62, 2, 2, 179, 180, 7, 35, 2, 2, 180, 54, 3, 2, 2, 2, 181, 182, 7, 37, 2, 2, 182, 183, 7, 81, 2, 2, 183, 184, 7, 82, 2, 2, 184, 185, 7, 62, 2, 2, 185, 186, 7, 48, 2, 2, 186, 187, 7, 64, 2, 2, 187, 56, 3, 2, 2, 2, 188, 189, 7, 37, 2, 2, 189, 190, 7, 78, 2, 2, 190, 191, 7, 86, 2, 2, 191, 192, 7, 62, 2, 2, 192, 58, 3, 2, 2, 2, 193, 194, 7, 37, 2, 2, 194, 195, 7, 78, 2, 2, 195, 196, 7, 86, 2, 2, 196, 197, 7, 62, 2, 2, 197, 198, 7, 35, 2, 2, 198, 60, 3, 2, 2, 2, 199, 200, 7, 37, 2, 2, 200, 201, 7, 78, 2, 2, 201, 202, 7, 86, 2, 2, 202, 203, 7, 62, 2, 2, 203, 204, 7, 48, 2, 2, 204, 205, 7, 64, 2, 2, 205, 62, 3, 2, 2, 2, 206, 207, 7, 50, 2, 2, 207, 64, 3, 2, 2, 2, 208, 209, 7, 51, 2, 2, 209, 66, 3, 2, 2, 2, 210, 211, 7, 52, 2, 2, 211, 68, 3, 2, 2, 2, 212, 213, 7, 53, 2, 2, 213, 70, 3, 2, 2, 2, 214, 215, 7, 54, 2, 2, 215, 72, 3, 2, 2, 2, 216, 217, 7, 55, 2, 2, 217, 74, 3, 2, 2, 2, 218, 219, 7, 56, 2, 2, 219, 76, 3, 2, 2, 2, 220, 221, 7, 57, 2, 2, 221, 78, 3, 2, 2, 2, 222, 223, 7, 58, 2, 2, 223, 80, 3, 2, 2, 2, 224, 225, 7, 59, 2, 2, 225, 82, 3, 2, 2, 2, 226, 228, 9, 2, 2, 2, 227, 226, 3, 2, 2, 2, 228, 229, 3, 2, 2, 2, 229, 227, 3, 2, 2, 2, 229, 230, 3, 2, 2, 2, 230, 231, 3, 2, 2, 2, 231, 232, 8, 42, 2, 2, 232, 84, 3, 2, 2, 2, 4, 2, 229, 3, 8, 2, 2]
\ No newline at end of file
diff --git a/code/antlr4/.antlr/SearchLexer.java b/code/antlr4/.antlr/SearchLexer.java
new file mode 100644
index 0000000..fc4fc16
--- /dev/null
+++ b/code/antlr4/.antlr/SearchLexer.java
@@ -0,0 +1,188 @@
+// Generated from /home/luca/Desktop/Project/dSearch/code/antlr4/Search.g4 by ANTLR 4.7.1
+import org.antlr.v4.runtime.Lexer;
+import org.antlr.v4.runtime.CharStream;
+import org.antlr.v4.runtime.Token;
+import org.antlr.v4.runtime.TokenStream;
+import org.antlr.v4.runtime.*;
+import org.antlr.v4.runtime.atn.*;
+import org.antlr.v4.runtime.dfa.DFA;
+import org.antlr.v4.runtime.misc.*;
+
+@SuppressWarnings({"all", "warnings", "unchecked", "unused", "cast"})
+public class SearchLexer extends Lexer {
+	static { RuntimeMetaData.checkVersion("4.7.1", RuntimeMetaData.VERSION); }
+
+	protected static final DFA[] _decisionToDFA;
+	protected static final PredictionContextCache _sharedContextCache =
+		new PredictionContextCache();
+	public static final int
+		T__0=1, T__1=2, T__2=3, T__3=4, T__4=5, T__5=6, T__6=7, T__7=8, T__8=9, 
+		T__9=10, T__10=11, T__11=12, T__12=13, T__13=14, T__14=15, T__15=16, T__16=17, 
+		T__17=18, T__18=19, T__19=20, T__20=21, T__21=22, T__22=23, T__23=24, 
+		T__24=25, T__25=26, T__26=27, T__27=28, T__28=29, T__29=30, T__30=31, 
+		T__31=32, T__32=33, T__33=34, T__34=35, T__35=36, T__36=37, T__37=38, 
+		T__38=39, T__39=40, WS=41;
+	public static String[] channelNames = {
+		"DEFAULT_TOKEN_CHANNEL", "HIDDEN"
+	};
+
+	public static String[] modeNames = {
+		"DEFAULT_MODE"
+	};
+
+	public static final String[] ruleNames = {
+		"T__0", "T__1", "T__2", "T__3", "T__4", "T__5", "T__6", "T__7", "T__8", 
+		"T__9", "T__10", "T__11", "T__12", "T__13", "T__14", "T__15", "T__16", 
+		"T__17", "T__18", "T__19", "T__20", "T__21", "T__22", "T__23", "T__24", 
+		"T__25", "T__26", "T__27", "T__28", "T__29", "T__30", "T__31", "T__32", 
+		"T__33", "T__34", "T__35", "T__36", "T__37", "T__38", "T__39", "WS"
+	};
+
+	private static final String[] _LITERAL_NAMES = {
+		null, "'->'", "'_'", "'if'", "'else'", "'for'", "'forEach'", "'while'", 
+		"'return'", "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", 
+		"'='", "'.'", "','", "';'", "'#ID<'", "'>'", "'#ID<!'", "'#ID<.>'", "'#OP<'", 
+		"'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", "'#LT<.>'", "'0'", "'1'", 
+		"'2'", "'3'", "'4'", "'5'", "'6'", "'7'", "'8'", "'9'"
+	};
+	private static final String[] _SYMBOLIC_NAMES = {
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, "WS"
+	};
+	public static final Vocabulary VOCABULARY = new VocabularyImpl(_LITERAL_NAMES, _SYMBOLIC_NAMES);
+
+	/**
+	 * @deprecated Use {@link #VOCABULARY} instead.
+	 */
+	@Deprecated
+	public static final String[] tokenNames;
+	static {
+		tokenNames = new String[_SYMBOLIC_NAMES.length];
+		for (int i = 0; i < tokenNames.length; i++) {
+			tokenNames[i] = VOCABULARY.getLiteralName(i);
+			if (tokenNames[i] == null) {
+				tokenNames[i] = VOCABULARY.getSymbolicName(i);
+			}
+
+			if (tokenNames[i] == null) {
+				tokenNames[i] = "<INVALID>";
+			}
+		}
+	}
+
+	@Override
+	@Deprecated
+	public String[] getTokenNames() {
+		return tokenNames;
+	}
+
+	@Override
+
+	public Vocabulary getVocabulary() {
+		return VOCABULARY;
+	}
+
+
+	public SearchLexer(CharStream input) {
+		super(input);
+		_interp = new LexerATNSimulator(this,_ATN,_decisionToDFA,_sharedContextCache);
+	}
+
+	@Override
+	public String getGrammarFileName() { return "Search.g4"; }
+
+	@Override
+	public String[] getRuleNames() { return ruleNames; }
+
+	@Override
+	public String getSerializedATN() { return _serializedATN; }
+
+	@Override
+	public String[] getChannelNames() { return channelNames; }
+
+	@Override
+	public String[] getModeNames() { return modeNames; }
+
+	@Override
+	public ATN getATN() { return _ATN; }
+
+	public static final String _serializedATN =
+		"\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2+\u00e9\b\1\4\2\t"+
+		"\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13"+
+		"\t\13\4\f\t\f\4\r\t\r\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22"+
+		"\4\23\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30\4\31\t\31"+
+		"\4\32\t\32\4\33\t\33\4\34\t\34\4\35\t\35\4\36\t\36\4\37\t\37\4 \t \4!"+
+		"\t!\4\"\t\"\4#\t#\4$\t$\4%\t%\4&\t&\4\'\t\'\4(\t(\4)\t)\4*\t*\3\2\3\2"+
+		"\3\2\3\3\3\3\3\4\3\4\3\4\3\5\3\5\3\5\3\5\3\5\3\6\3\6\3\6\3\6\3\7\3\7\3"+
+		"\7\3\7\3\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\t\3\t\3\t\3\t\3\t\3\t"+
+		"\3\t\3\n\3\n\3\n\3\n\3\n\3\13\3\13\3\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17"+
+		"\3\20\3\20\3\21\3\21\3\22\3\22\3\23\3\23\3\24\3\24\3\25\3\25\3\26\3\26"+
+		"\3\26\3\26\3\26\3\27\3\27\3\30\3\30\3\30\3\30\3\30\3\30\3\31\3\31\3\31"+
+		"\3\31\3\31\3\31\3\31\3\32\3\32\3\32\3\32\3\32\3\33\3\33\3\33\3\33\3\33"+
+		"\3\33\3\34\3\34\3\34\3\34\3\34\3\34\3\34\3\35\3\35\3\35\3\35\3\35\3\36"+
+		"\3\36\3\36\3\36\3\36\3\36\3\37\3\37\3\37\3\37\3\37\3\37\3\37\3 \3 \3!"+
+		"\3!\3\"\3\"\3#\3#\3$\3$\3%\3%\3&\3&\3\'\3\'\3(\3(\3)\3)\3*\6*\u00e4\n"+
+		"*\r*\16*\u00e5\3*\3*\2\2+\3\3\5\4\7\5\t\6\13\7\r\b\17\t\21\n\23\13\25"+
+		"\f\27\r\31\16\33\17\35\20\37\21!\22#\23%\24\'\25)\26+\27-\30/\31\61\32"+
+		"\63\33\65\34\67\359\36;\37= ?!A\"C#E$G%I&K\'M(O)Q*S+\3\2\3\5\2\13\f\17"+
+		"\17\"\"\2\u00e9\2\3\3\2\2\2\2\5\3\2\2\2\2\7\3\2\2\2\2\t\3\2\2\2\2\13\3"+
+		"\2\2\2\2\r\3\2\2\2\2\17\3\2\2\2\2\21\3\2\2\2\2\23\3\2\2\2\2\25\3\2\2\2"+
+		"\2\27\3\2\2\2\2\31\3\2\2\2\2\33\3\2\2\2\2\35\3\2\2\2\2\37\3\2\2\2\2!\3"+
+		"\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2\'\3\2\2\2\2)\3\2\2\2\2+\3\2\2\2\2-\3\2"+
+		"\2\2\2/\3\2\2\2\2\61\3\2\2\2\2\63\3\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\2"+
+		"9\3\2\2\2\2;\3\2\2\2\2=\3\2\2\2\2?\3\2\2\2\2A\3\2\2\2\2C\3\2\2\2\2E\3"+
+		"\2\2\2\2G\3\2\2\2\2I\3\2\2\2\2K\3\2\2\2\2M\3\2\2\2\2O\3\2\2\2\2Q\3\2\2"+
+		"\2\2S\3\2\2\2\3U\3\2\2\2\5X\3\2\2\2\7Z\3\2\2\2\t]\3\2\2\2\13b\3\2\2\2"+
+		"\rf\3\2\2\2\17n\3\2\2\2\21t\3\2\2\2\23{\3\2\2\2\25\u0080\3\2\2\2\27\u0082"+
+		"\3\2\2\2\31\u0084\3\2\2\2\33\u0086\3\2\2\2\35\u0088\3\2\2\2\37\u008a\3"+
+		"\2\2\2!\u008c\3\2\2\2#\u008e\3\2\2\2%\u0090\3\2\2\2\'\u0092\3\2\2\2)\u0094"+
+		"\3\2\2\2+\u0096\3\2\2\2-\u009b\3\2\2\2/\u009d\3\2\2\2\61\u00a3\3\2\2\2"+
+		"\63\u00aa\3\2\2\2\65\u00af\3\2\2\2\67\u00b5\3\2\2\29\u00bc\3\2\2\2;\u00c1"+
+		"\3\2\2\2=\u00c7\3\2\2\2?\u00ce\3\2\2\2A\u00d0\3\2\2\2C\u00d2\3\2\2\2E"+
+		"\u00d4\3\2\2\2G\u00d6\3\2\2\2I\u00d8\3\2\2\2K\u00da\3\2\2\2M\u00dc\3\2"+
+		"\2\2O\u00de\3\2\2\2Q\u00e0\3\2\2\2S\u00e3\3\2\2\2UV\7/\2\2VW\7@\2\2W\4"+
+		"\3\2\2\2XY\7a\2\2Y\6\3\2\2\2Z[\7k\2\2[\\\7h\2\2\\\b\3\2\2\2]^\7g\2\2^"+
+		"_\7n\2\2_`\7u\2\2`a\7g\2\2a\n\3\2\2\2bc\7h\2\2cd\7q\2\2de\7t\2\2e\f\3"+
+		"\2\2\2fg\7h\2\2gh\7q\2\2hi\7t\2\2ij\7G\2\2jk\7c\2\2kl\7e\2\2lm\7j\2\2"+
+		"m\16\3\2\2\2no\7y\2\2op\7j\2\2pq\7k\2\2qr\7n\2\2rs\7g\2\2s\20\3\2\2\2"+
+		"tu\7t\2\2uv\7g\2\2vw\7v\2\2wx\7w\2\2xy\7t\2\2yz\7p\2\2z\22\3\2\2\2{|\7"+
+		"P\2\2|}\7W\2\2}~\7N\2\2~\177\7N\2\2\177\24\3\2\2\2\u0080\u0081\7*\2\2"+
+		"\u0081\26\3\2\2\2\u0082\u0083\7+\2\2\u0083\30\3\2\2\2\u0084\u0085\7]\2"+
+		"\2\u0085\32\3\2\2\2\u0086\u0087\7_\2\2\u0087\34\3\2\2\2\u0088\u0089\7"+
+		"}\2\2\u0089\36\3\2\2\2\u008a\u008b\7\177\2\2\u008b \3\2\2\2\u008c\u008d"+
+		"\7$\2\2\u008d\"\3\2\2\2\u008e\u008f\7?\2\2\u008f$\3\2\2\2\u0090\u0091"+
+		"\7\60\2\2\u0091&\3\2\2\2\u0092\u0093\7.\2\2\u0093(\3\2\2\2\u0094\u0095"+
+		"\7=\2\2\u0095*\3\2\2\2\u0096\u0097\7%\2\2\u0097\u0098\7K\2\2\u0098\u0099"+
+		"\7F\2\2\u0099\u009a\7>\2\2\u009a,\3\2\2\2\u009b\u009c\7@\2\2\u009c.\3"+
+		"\2\2\2\u009d\u009e\7%\2\2\u009e\u009f\7K\2\2\u009f\u00a0\7F\2\2\u00a0"+
+		"\u00a1\7>\2\2\u00a1\u00a2\7#\2\2\u00a2\60\3\2\2\2\u00a3\u00a4\7%\2\2\u00a4"+
+		"\u00a5\7K\2\2\u00a5\u00a6\7F\2\2\u00a6\u00a7\7>\2\2\u00a7\u00a8\7\60\2"+
+		"\2\u00a8\u00a9\7@\2\2\u00a9\62\3\2\2\2\u00aa\u00ab\7%\2\2\u00ab\u00ac"+
+		"\7Q\2\2\u00ac\u00ad\7R\2\2\u00ad\u00ae\7>\2\2\u00ae\64\3\2\2\2\u00af\u00b0"+
+		"\7%\2\2\u00b0\u00b1\7Q\2\2\u00b1\u00b2\7R\2\2\u00b2\u00b3\7>\2\2\u00b3"+
+		"\u00b4\7#\2\2\u00b4\66\3\2\2\2\u00b5\u00b6\7%\2\2\u00b6\u00b7\7Q\2\2\u00b7"+
+		"\u00b8\7R\2\2\u00b8\u00b9\7>\2\2\u00b9\u00ba\7\60\2\2\u00ba\u00bb\7@\2"+
+		"\2\u00bb8\3\2\2\2\u00bc\u00bd\7%\2\2\u00bd\u00be\7N\2\2\u00be\u00bf\7"+
+		"V\2\2\u00bf\u00c0\7>\2\2\u00c0:\3\2\2\2\u00c1\u00c2\7%\2\2\u00c2\u00c3"+
+		"\7N\2\2\u00c3\u00c4\7V\2\2\u00c4\u00c5\7>\2\2\u00c5\u00c6\7#\2\2\u00c6"+
+		"<\3\2\2\2\u00c7\u00c8\7%\2\2\u00c8\u00c9\7N\2\2\u00c9\u00ca\7V\2\2\u00ca"+
+		"\u00cb\7>\2\2\u00cb\u00cc\7\60\2\2\u00cc\u00cd\7@\2\2\u00cd>\3\2\2\2\u00ce"+
+		"\u00cf\7\62\2\2\u00cf@\3\2\2\2\u00d0\u00d1\7\63\2\2\u00d1B\3\2\2\2\u00d2"+
+		"\u00d3\7\64\2\2\u00d3D\3\2\2\2\u00d4\u00d5\7\65\2\2\u00d5F\3\2\2\2\u00d6"+
+		"\u00d7\7\66\2\2\u00d7H\3\2\2\2\u00d8\u00d9\7\67\2\2\u00d9J\3\2\2\2\u00da"+
+		"\u00db\78\2\2\u00dbL\3\2\2\2\u00dc\u00dd\79\2\2\u00ddN\3\2\2\2\u00de\u00df"+
+		"\7:\2\2\u00dfP\3\2\2\2\u00e0\u00e1\7;\2\2\u00e1R\3\2\2\2\u00e2\u00e4\t"+
+		"\2\2\2\u00e3\u00e2\3\2\2\2\u00e4\u00e5\3\2\2\2\u00e5\u00e3\3\2\2\2\u00e5"+
+		"\u00e6\3\2\2\2\u00e6\u00e7\3\2\2\2\u00e7\u00e8\b*\2\2\u00e8T\3\2\2\2\4"+
+		"\2\u00e5\3\b\2\2";
+	public static final ATN _ATN =
+		new ATNDeserializer().deserialize(_serializedATN.toCharArray());
+	static {
+		_decisionToDFA = new DFA[_ATN.getNumberOfDecisions()];
+		for (int i = 0; i < _ATN.getNumberOfDecisions(); i++) {
+			_decisionToDFA[i] = new DFA(_ATN.getDecisionState(i), i);
+		}
+	}
+}
\ No newline at end of file
diff --git a/code/antlr4/.antlr/SearchLexer.tokens b/code/antlr4/.antlr/SearchLexer.tokens
new file mode 100644
index 0000000..372bf0c
--- /dev/null
+++ b/code/antlr4/.antlr/SearchLexer.tokens
@@ -0,0 +1,81 @@
+T__0=1
+T__1=2
+T__2=3
+T__3=4
+T__4=5
+T__5=6
+T__6=7
+T__7=8
+T__8=9
+T__9=10
+T__10=11
+T__11=12
+T__12=13
+T__13=14
+T__14=15
+T__15=16
+T__16=17
+T__17=18
+T__18=19
+T__19=20
+T__20=21
+T__21=22
+T__22=23
+T__23=24
+T__24=25
+T__25=26
+T__26=27
+T__27=28
+T__28=29
+T__29=30
+T__30=31
+T__31=32
+T__32=33
+T__33=34
+T__34=35
+T__35=36
+T__36=37
+T__37=38
+T__38=39
+T__39=40
+WS=41
+'->'=1
+'_'=2
+'if'=3
+'else'=4
+'for'=5
+'forEach'=6
+'while'=7
+'return'=8
+'NULL'=9
+'('=10
+')'=11
+'['=12
+']'=13
+'{'=14
+'}'=15
+'"'=16
+'='=17
+'.'=18
+','=19
+';'=20
+'#ID<'=21
+'>'=22
+'#ID<!'=23
+'#ID<.>'=24
+'#OP<'=25
+'#OP<!'=26
+'#OP<.>'=27
+'#LT<'=28
+'#LT<!'=29
+'#LT<.>'=30
+'0'=31
+'1'=32
+'2'=33
+'3'=34
+'4'=35
+'5'=36
+'6'=37
+'7'=38
+'8'=39
+'9'=40
diff --git a/code/antlr4/.antlr/SearchParser.java b/code/antlr4/.antlr/SearchParser.java
new file mode 100644
index 0000000..139afe3
--- /dev/null
+++ b/code/antlr4/.antlr/SearchParser.java
@@ -0,0 +1,832 @@
+// Generated from /home/luca/Desktop/Project/dSearch/code/antlr4/Search.g4 by ANTLR 4.7.1
+import org.antlr.v4.runtime.atn.*;
+import org.antlr.v4.runtime.dfa.DFA;
+import org.antlr.v4.runtime.*;
+import org.antlr.v4.runtime.misc.*;
+import org.antlr.v4.runtime.tree.*;
+import java.util.List;
+import java.util.Iterator;
+import java.util.ArrayList;
+
+@SuppressWarnings({"all", "warnings", "unchecked", "unused", "cast"})
+public class SearchParser extends Parser {
+	static { RuntimeMetaData.checkVersion("4.7.1", RuntimeMetaData.VERSION); }
+
+	protected static final DFA[] _decisionToDFA;
+	protected static final PredictionContextCache _sharedContextCache =
+		new PredictionContextCache();
+	public static final int
+		T__0=1, T__1=2, T__2=3, T__3=4, T__4=5, T__5=6, T__6=7, T__7=8, T__8=9, 
+		T__9=10, T__10=11, T__11=12, T__12=13, T__13=14, T__14=15, T__15=16, T__16=17, 
+		T__17=18, T__18=19, T__19=20, T__20=21, T__21=22, T__22=23, T__23=24, 
+		T__24=25, T__25=26, T__26=27, T__27=28, T__28=29, T__29=30, T__30=31, 
+		T__31=32, T__32=33, T__33=34, T__34=35, T__35=36, T__36=37, T__37=38, 
+		T__38=39, T__39=40, WS=41;
+	public static final int
+		RULE_query = 0, RULE_code = 1, RULE_token = 2, RULE_keyword = 3, RULE_punctuator = 4, 
+		RULE_identifier = 5, RULE_operator = 6, RULE_literal = 7, RULE_digit = 8;
+	public static final String[] ruleNames = {
+		"query", "code", "token", "keyword", "punctuator", "identifier", "operator", 
+		"literal", "digit"
+	};
+
+	private static final String[] _LITERAL_NAMES = {
+		null, "'->'", "'_'", "'if'", "'else'", "'for'", "'forEach'", "'while'", 
+		"'return'", "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", 
+		"'='", "'.'", "','", "';'", "'#ID<'", "'>'", "'#ID<!'", "'#ID<.>'", "'#OP<'", 
+		"'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", "'#LT<.>'", "'0'", "'1'", 
+		"'2'", "'3'", "'4'", "'5'", "'6'", "'7'", "'8'", "'9'"
+	};
+	private static final String[] _SYMBOLIC_NAMES = {
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, "WS"
+	};
+	public static final Vocabulary VOCABULARY = new VocabularyImpl(_LITERAL_NAMES, _SYMBOLIC_NAMES);
+
+	/**
+	 * @deprecated Use {@link #VOCABULARY} instead.
+	 */
+	@Deprecated
+	public static final String[] tokenNames;
+	static {
+		tokenNames = new String[_SYMBOLIC_NAMES.length];
+		for (int i = 0; i < tokenNames.length; i++) {
+			tokenNames[i] = VOCABULARY.getLiteralName(i);
+			if (tokenNames[i] == null) {
+				tokenNames[i] = VOCABULARY.getSymbolicName(i);
+			}
+
+			if (tokenNames[i] == null) {
+				tokenNames[i] = "<INVALID>";
+			}
+		}
+	}
+
+	@Override
+	@Deprecated
+	public String[] getTokenNames() {
+		return tokenNames;
+	}
+
+	@Override
+
+	public Vocabulary getVocabulary() {
+		return VOCABULARY;
+	}
+
+	@Override
+	public String getGrammarFileName() { return "Search.g4"; }
+
+	@Override
+	public String[] getRuleNames() { return ruleNames; }
+
+	@Override
+	public String getSerializedATN() { return _serializedATN; }
+
+	@Override
+	public ATN getATN() { return _ATN; }
+
+	public SearchParser(TokenStream input) {
+		super(input);
+		_interp = new ParserATNSimulator(this,_ATN,_decisionToDFA,_sharedContextCache);
+	}
+	public static class QueryContext extends ParserRuleContext {
+		public List<CodeContext> code() {
+			return getRuleContexts(CodeContext.class);
+		}
+		public CodeContext code(int i) {
+			return getRuleContext(CodeContext.class,i);
+		}
+		public QueryContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_query; }
+	}
+
+	public final QueryContext query() throws RecognitionException {
+		QueryContext _localctx = new QueryContext(_ctx, getState());
+		enterRule(_localctx, 0, RULE_query);
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(18);
+			code();
+			setState(19);
+			match(T__0);
+			setState(20);
+			code();
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class CodeContext extends ParserRuleContext {
+		public List<TokenContext> token() {
+			return getRuleContexts(TokenContext.class);
+		}
+		public TokenContext token(int i) {
+			return getRuleContext(TokenContext.class,i);
+		}
+		public CodeContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_code; }
+	}
+
+	public final CodeContext code() throws RecognitionException {
+		CodeContext _localctx = new CodeContext(_ctx, getState());
+		enterRule(_localctx, 2, RULE_code);
+		int _la;
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(25);
+			_errHandler.sync(this);
+			_la = _input.LA(1);
+			while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+				{
+				{
+				setState(22);
+				token();
+				}
+				}
+				setState(27);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+			}
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class TokenContext extends ParserRuleContext {
+		public IdentifierContext identifier() {
+			return getRuleContext(IdentifierContext.class,0);
+		}
+		public KeywordContext keyword() {
+			return getRuleContext(KeywordContext.class,0);
+		}
+		public PunctuatorContext punctuator() {
+			return getRuleContext(PunctuatorContext.class,0);
+		}
+		public OperatorContext operator() {
+			return getRuleContext(OperatorContext.class,0);
+		}
+		public LiteralContext literal() {
+			return getRuleContext(LiteralContext.class,0);
+		}
+		public TokenContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_token; }
+	}
+
+	public final TokenContext token() throws RecognitionException {
+		TokenContext _localctx = new TokenContext(_ctx, getState());
+		enterRule(_localctx, 4, RULE_token);
+		try {
+			setState(34);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__20:
+			case T__22:
+			case T__23:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(28);
+				identifier();
+				}
+				break;
+			case T__2:
+			case T__3:
+			case T__4:
+			case T__5:
+			case T__6:
+			case T__7:
+			case T__8:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(29);
+				keyword();
+				}
+				break;
+			case T__9:
+			case T__11:
+			case T__13:
+			case T__15:
+			case T__16:
+			case T__17:
+			case T__18:
+			case T__19:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(30);
+				punctuator();
+				}
+				break;
+			case T__24:
+			case T__25:
+			case T__26:
+				enterOuterAlt(_localctx, 4);
+				{
+				setState(31);
+				operator();
+				}
+				break;
+			case T__27:
+			case T__28:
+			case T__29:
+				enterOuterAlt(_localctx, 5);
+				{
+				setState(32);
+				literal();
+				}
+				break;
+			case T__1:
+				enterOuterAlt(_localctx, 6);
+				{
+				setState(33);
+				match(T__1);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class KeywordContext extends ParserRuleContext {
+		public KeywordContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_keyword; }
+	}
+
+	public final KeywordContext keyword() throws RecognitionException {
+		KeywordContext _localctx = new KeywordContext(_ctx, getState());
+		enterRule(_localctx, 6, RULE_keyword);
+		int _la;
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(36);
+			_la = _input.LA(1);
+			if ( !((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8))) != 0)) ) {
+			_errHandler.recoverInline(this);
+			}
+			else {
+				if ( _input.LA(1)==Token.EOF ) matchedEOF = true;
+				_errHandler.reportMatch(this);
+				consume();
+			}
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class PunctuatorContext extends ParserRuleContext {
+		public List<TokenContext> token() {
+			return getRuleContexts(TokenContext.class);
+		}
+		public TokenContext token(int i) {
+			return getRuleContext(TokenContext.class,i);
+		}
+		public PunctuatorContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_punctuator; }
+	}
+
+	public final PunctuatorContext punctuator() throws RecognitionException {
+		PunctuatorContext _localctx = new PunctuatorContext(_ctx, getState());
+		enterRule(_localctx, 8, RULE_punctuator);
+		int _la;
+		try {
+			int _alt;
+			setState(74);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__9:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(38);
+				match(T__9);
+				setState(42);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+					{
+					{
+					setState(39);
+					token();
+					}
+					}
+					setState(44);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(45);
+				match(T__10);
+				}
+				break;
+			case T__11:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(46);
+				match(T__11);
+				setState(50);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+					{
+					{
+					setState(47);
+					token();
+					}
+					}
+					setState(52);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(53);
+				match(T__12);
+				}
+				break;
+			case T__13:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(54);
+				match(T__13);
+				setState(58);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+					{
+					{
+					setState(55);
+					token();
+					}
+					}
+					setState(60);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(61);
+				match(T__14);
+				}
+				break;
+			case T__15:
+				enterOuterAlt(_localctx, 4);
+				{
+				setState(62);
+				match(T__15);
+				setState(66);
+				_errHandler.sync(this);
+				_alt = getInterpreter().adaptivePredict(_input,5,_ctx);
+				while ( _alt!=2 && _alt!=org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER ) {
+					if ( _alt==1 ) {
+						{
+						{
+						setState(63);
+						token();
+						}
+						} 
+					}
+					setState(68);
+					_errHandler.sync(this);
+					_alt = getInterpreter().adaptivePredict(_input,5,_ctx);
+				}
+				setState(69);
+				match(T__15);
+				}
+				break;
+			case T__16:
+				enterOuterAlt(_localctx, 5);
+				{
+				setState(70);
+				match(T__16);
+				}
+				break;
+			case T__17:
+				enterOuterAlt(_localctx, 6);
+				{
+				setState(71);
+				match(T__17);
+				}
+				break;
+			case T__18:
+				enterOuterAlt(_localctx, 7);
+				{
+				setState(72);
+				match(T__18);
+				}
+				break;
+			case T__19:
+				enterOuterAlt(_localctx, 8);
+				{
+				setState(73);
+				match(T__19);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class IdentifierContext extends ParserRuleContext {
+		public List<DigitContext> digit() {
+			return getRuleContexts(DigitContext.class);
+		}
+		public DigitContext digit(int i) {
+			return getRuleContext(DigitContext.class,i);
+		}
+		public IdentifierContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_identifier; }
+	}
+
+	public final IdentifierContext identifier() throws RecognitionException {
+		IdentifierContext _localctx = new IdentifierContext(_ctx, getState());
+		enterRule(_localctx, 10, RULE_identifier);
+		int _la;
+		try {
+			setState(93);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__20:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(76);
+				match(T__20);
+				setState(80);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(77);
+					digit();
+					}
+					}
+					setState(82);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(83);
+				match(T__21);
+				}
+				break;
+			case T__22:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(84);
+				match(T__22);
+				setState(88);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(85);
+					digit();
+					}
+					}
+					setState(90);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(91);
+				match(T__21);
+				}
+				break;
+			case T__23:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(92);
+				match(T__23);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class OperatorContext extends ParserRuleContext {
+		public List<DigitContext> digit() {
+			return getRuleContexts(DigitContext.class);
+		}
+		public DigitContext digit(int i) {
+			return getRuleContext(DigitContext.class,i);
+		}
+		public OperatorContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_operator; }
+	}
+
+	public final OperatorContext operator() throws RecognitionException {
+		OperatorContext _localctx = new OperatorContext(_ctx, getState());
+		enterRule(_localctx, 12, RULE_operator);
+		int _la;
+		try {
+			setState(112);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__24:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(95);
+				match(T__24);
+				setState(99);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(96);
+					digit();
+					}
+					}
+					setState(101);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(102);
+				match(T__21);
+				}
+				break;
+			case T__25:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(103);
+				match(T__25);
+				setState(107);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(104);
+					digit();
+					}
+					}
+					setState(109);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(110);
+				match(T__21);
+				}
+				break;
+			case T__26:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(111);
+				match(T__26);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class LiteralContext extends ParserRuleContext {
+		public List<DigitContext> digit() {
+			return getRuleContexts(DigitContext.class);
+		}
+		public DigitContext digit(int i) {
+			return getRuleContext(DigitContext.class,i);
+		}
+		public LiteralContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_literal; }
+	}
+
+	public final LiteralContext literal() throws RecognitionException {
+		LiteralContext _localctx = new LiteralContext(_ctx, getState());
+		enterRule(_localctx, 14, RULE_literal);
+		int _la;
+		try {
+			setState(131);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__27:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(114);
+				match(T__27);
+				setState(118);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(115);
+					digit();
+					}
+					}
+					setState(120);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(121);
+				match(T__21);
+				}
+				break;
+			case T__28:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(122);
+				match(T__28);
+				setState(126);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(123);
+					digit();
+					}
+					}
+					setState(128);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(129);
+				match(T__21);
+				}
+				break;
+			case T__29:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(130);
+				match(T__29);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class DigitContext extends ParserRuleContext {
+		public DigitContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_digit; }
+	}
+
+	public final DigitContext digit() throws RecognitionException {
+		DigitContext _localctx = new DigitContext(_ctx, getState());
+		enterRule(_localctx, 16, RULE_digit);
+		int _la;
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(133);
+			_la = _input.LA(1);
+			if ( !((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) ) {
+			_errHandler.recoverInline(this);
+			}
+			else {
+				if ( _input.LA(1)==Token.EOF ) matchedEOF = true;
+				_errHandler.reportMatch(this);
+				consume();
+			}
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static final String _serializedATN =
+		"\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3+\u008a\4\2\t\2\4"+
+		"\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7\4\b\t\b\4\t\t\t\4\n\t\n\3\2\3\2"+
+		"\3\2\3\2\3\3\7\3\32\n\3\f\3\16\3\35\13\3\3\4\3\4\3\4\3\4\3\4\3\4\5\4%"+
+		"\n\4\3\5\3\5\3\6\3\6\7\6+\n\6\f\6\16\6.\13\6\3\6\3\6\3\6\7\6\63\n\6\f"+
+		"\6\16\6\66\13\6\3\6\3\6\3\6\7\6;\n\6\f\6\16\6>\13\6\3\6\3\6\3\6\7\6C\n"+
+		"\6\f\6\16\6F\13\6\3\6\3\6\3\6\3\6\3\6\5\6M\n\6\3\7\3\7\7\7Q\n\7\f\7\16"+
+		"\7T\13\7\3\7\3\7\3\7\7\7Y\n\7\f\7\16\7\\\13\7\3\7\3\7\5\7`\n\7\3\b\3\b"+
+		"\7\bd\n\b\f\b\16\bg\13\b\3\b\3\b\3\b\7\bl\n\b\f\b\16\bo\13\b\3\b\3\b\5"+
+		"\bs\n\b\3\t\3\t\7\tw\n\t\f\t\16\tz\13\t\3\t\3\t\3\t\7\t\177\n\t\f\t\16"+
+		"\t\u0082\13\t\3\t\3\t\5\t\u0086\n\t\3\n\3\n\3\n\2\2\13\2\4\6\b\n\f\16"+
+		"\20\22\2\4\3\2\5\13\3\2!*\2\u009d\2\24\3\2\2\2\4\33\3\2\2\2\6$\3\2\2\2"+
+		"\b&\3\2\2\2\nL\3\2\2\2\f_\3\2\2\2\16r\3\2\2\2\20\u0085\3\2\2\2\22\u0087"+
+		"\3\2\2\2\24\25\5\4\3\2\25\26\7\3\2\2\26\27\5\4\3\2\27\3\3\2\2\2\30\32"+
+		"\5\6\4\2\31\30\3\2\2\2\32\35\3\2\2\2\33\31\3\2\2\2\33\34\3\2\2\2\34\5"+
+		"\3\2\2\2\35\33\3\2\2\2\36%\5\f\7\2\37%\5\b\5\2 %\5\n\6\2!%\5\16\b\2\""+
+		"%\5\20\t\2#%\7\4\2\2$\36\3\2\2\2$\37\3\2\2\2$ \3\2\2\2$!\3\2\2\2$\"\3"+
+		"\2\2\2$#\3\2\2\2%\7\3\2\2\2&\'\t\2\2\2\'\t\3\2\2\2(,\7\f\2\2)+\5\6\4\2"+
+		"*)\3\2\2\2+.\3\2\2\2,*\3\2\2\2,-\3\2\2\2-/\3\2\2\2.,\3\2\2\2/M\7\r\2\2"+
+		"\60\64\7\16\2\2\61\63\5\6\4\2\62\61\3\2\2\2\63\66\3\2\2\2\64\62\3\2\2"+
+		"\2\64\65\3\2\2\2\65\67\3\2\2\2\66\64\3\2\2\2\67M\7\17\2\28<\7\20\2\29"+
+		";\5\6\4\2:9\3\2\2\2;>\3\2\2\2<:\3\2\2\2<=\3\2\2\2=?\3\2\2\2><\3\2\2\2"+
+		"?M\7\21\2\2@D\7\22\2\2AC\5\6\4\2BA\3\2\2\2CF\3\2\2\2DB\3\2\2\2DE\3\2\2"+
+		"\2EG\3\2\2\2FD\3\2\2\2GM\7\22\2\2HM\7\23\2\2IM\7\24\2\2JM\7\25\2\2KM\7"+
+		"\26\2\2L(\3\2\2\2L\60\3\2\2\2L8\3\2\2\2L@\3\2\2\2LH\3\2\2\2LI\3\2\2\2"+
+		"LJ\3\2\2\2LK\3\2\2\2M\13\3\2\2\2NR\7\27\2\2OQ\5\22\n\2PO\3\2\2\2QT\3\2"+
+		"\2\2RP\3\2\2\2RS\3\2\2\2SU\3\2\2\2TR\3\2\2\2U`\7\30\2\2VZ\7\31\2\2WY\5"+
+		"\22\n\2XW\3\2\2\2Y\\\3\2\2\2ZX\3\2\2\2Z[\3\2\2\2[]\3\2\2\2\\Z\3\2\2\2"+
+		"]`\7\30\2\2^`\7\32\2\2_N\3\2\2\2_V\3\2\2\2_^\3\2\2\2`\r\3\2\2\2ae\7\33"+
+		"\2\2bd\5\22\n\2cb\3\2\2\2dg\3\2\2\2ec\3\2\2\2ef\3\2\2\2fh\3\2\2\2ge\3"+
+		"\2\2\2hs\7\30\2\2im\7\34\2\2jl\5\22\n\2kj\3\2\2\2lo\3\2\2\2mk\3\2\2\2"+
+		"mn\3\2\2\2np\3\2\2\2om\3\2\2\2ps\7\30\2\2qs\7\35\2\2ra\3\2\2\2ri\3\2\2"+
+		"\2rq\3\2\2\2s\17\3\2\2\2tx\7\36\2\2uw\5\22\n\2vu\3\2\2\2wz\3\2\2\2xv\3"+
+		"\2\2\2xy\3\2\2\2y{\3\2\2\2zx\3\2\2\2{\u0086\7\30\2\2|\u0080\7\37\2\2}"+
+		"\177\5\22\n\2~}\3\2\2\2\177\u0082\3\2\2\2\u0080~\3\2\2\2\u0080\u0081\3"+
+		"\2\2\2\u0081\u0083\3\2\2\2\u0082\u0080\3\2\2\2\u0083\u0086\7\30\2\2\u0084"+
+		"\u0086\7 \2\2\u0085t\3\2\2\2\u0085|\3\2\2\2\u0085\u0084\3\2\2\2\u0086"+
+		"\21\3\2\2\2\u0087\u0088\t\3\2\2\u0088\23\3\2\2\2\22\33$,\64<DLRZ_emrx"+
+		"\u0080\u0085";
+	public static final ATN _ATN =
+		new ATNDeserializer().deserialize(_serializedATN.toCharArray());
+	static {
+		_decisionToDFA = new DFA[_ATN.getNumberOfDecisions()];
+		for (int i = 0; i < _ATN.getNumberOfDecisions(); i++) {
+			_decisionToDFA[i] = new DFA(_ATN.getDecisionState(i), i);
+		}
+	}
+}
\ No newline at end of file
diff --git a/code/antlr4/Search.g4 b/code/antlr4/Search.g4
index 1f7fd42..dfdb50c 100644
--- a/code/antlr4/Search.g4
+++ b/code/antlr4/Search.g4
@@ -1,58 +1,22 @@
 grammar Search;
 
-query: expr '->' expr;
-
-expr: token*;
-
-token: identifier 
-	| keyword 
-	| punctuator 
-	| op
-	| '_';
-
-identifier: '#ID<' digit* '>' | '#N<' digit* '>' | '#ID<.>' | '#N<.>' ;
-
-digit:  '0'
-	|'1'
-	|'2'
-	|'3'
-	|'4'
-	|'5'
-	|'6'
-	|'7'
-	|'8'
-	|'9';
-
-keyword: 'if' 
-	| 'else' 
-	| 'for' 
-	| 'forEach' 
-	| 'while' 
-	| 'return' 
-	| 'NULL';
-
-punctuator: '('token*')'
-	| '['token*']'
-	| '{'token*'}'
-	| '"'token*'"'
-	| '='
-	| '.'
-	| ','
-	| ';';
-
-op:     '+' 
-	| '−' 
-	| '*' 
-	| '/'
-	| '==' 
-	| '<' 
-	| '>' 
-	| '<='
-	| '>='
-	| '==' 
-	| '!=' 
-	| '&&'
-	| '||'
-	| '#OP<' digit* '>' ;
-
-WS:     [ \t\r\n]+ -> skip ;
+query: code '->' code;
+
+code: token*;
+
+token: identifier | keyword | punctuator | operator| literal| '_';
+
+keyword: 'if' | 'else' | 'for' | 'forEach' | 'while' | 'return' | 'NULL';
+
+punctuator: '('token*')' | '['token*']' | '{'token*'}'| '"'token*'"'| '='| '.'| ',' | ';';
+
+identifier: '#ID<' digit* '>' | '#ID<!' digit* '>' | '#ID<.>';
+
+operator: '#OP<' digit* '>' | '#OP<!' digit* '>' | '#OP<.>';
+
+literal: '#LT<' digit* '>' | '#LT<!' digit* '>' | '#LT<.>';
+
+digit:  '0' | '1' | '2' | '3' | '4' | '5' | '6' |'7' | '8' | '9';
+
+
+WS:     [ \t\r\n]+ -> skip ;
\ No newline at end of file
diff --git a/code/antlr4/SearchLexer.py b/code/antlr4/SearchLexer.py
index d1ff21d..440f5f6 100644
--- a/code/antlr4/SearchLexer.py
+++ b/code/antlr4/SearchLexer.py
@@ -7,101 +7,94 @@ import sys
 
 def serializedATN():
     with StringIO() as buf:
-        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2\62")
-        buf.write("\u00f8\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
+        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2+")
+        buf.write("\u00e9\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
         buf.write("\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r")
         buf.write("\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23")
         buf.write("\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30")
         buf.write("\4\31\t\31\4\32\t\32\4\33\t\33\4\34\t\34\4\35\t\35\4\36")
         buf.write("\t\36\4\37\t\37\4 \t \4!\t!\4\"\t\"\4#\t#\4$\t$\4%\t%")
-        buf.write("\4&\t&\4\'\t\'\4(\t(\4)\t)\4*\t*\4+\t+\4,\t,\4-\t-\4.")
-        buf.write("\t.\4/\t/\4\60\t\60\4\61\t\61\3\2\3\2\3\2\3\3\3\3\3\4")
-        buf.write("\3\4\3\4\3\4\3\4\3\5\3\5\3\6\3\6\3\6\3\6\3\7\3\7\3\7\3")
-        buf.write("\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\t\3\t\3\n\3\n")
-        buf.write("\3\13\3\13\3\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17\3\20\3")
-        buf.write("\20\3\21\3\21\3\22\3\22\3\23\3\23\3\23\3\24\3\24\3\24")
-        buf.write("\3\24\3\24\3\25\3\25\3\25\3\25\3\26\3\26\3\26\3\26\3\26")
-        buf.write("\3\26\3\26\3\26\3\27\3\27\3\27\3\27\3\27\3\27\3\30\3\30")
-        buf.write("\3\30\3\30\3\30\3\30\3\30\3\31\3\31\3\31\3\31\3\31\3\32")
-        buf.write("\3\32\3\33\3\33\3\34\3\34\3\35\3\35\3\36\3\36\3\37\3\37")
-        buf.write("\3 \3 \3!\3!\3\"\3\"\3#\3#\3$\3$\3%\3%\3&\3&\3\'\3\'\3")
-        buf.write("(\3(\3)\3)\3)\3*\3*\3+\3+\3+\3,\3,\3,\3-\3-\3-\3.\3.\3")
-        buf.write(".\3/\3/\3/\3\60\3\60\3\60\3\60\3\60\3\61\6\61\u00f3\n")
-        buf.write("\61\r\61\16\61\u00f4\3\61\3\61\2\2\62\3\3\5\4\7\5\t\6")
-        buf.write("\13\7\r\b\17\t\21\n\23\13\25\f\27\r\31\16\33\17\35\20")
-        buf.write("\37\21!\22#\23%\24\'\25)\26+\27-\30/\31\61\32\63\33\65")
-        buf.write("\34\67\359\36;\37= ?!A\"C#E$G%I&K\'M(O)Q*S+U,W-Y.[/]\60")
-        buf.write("_\61a\62\3\2\3\5\2\13\f\17\17\"\"\2\u00f8\2\3\3\2\2\2")
-        buf.write("\2\5\3\2\2\2\2\7\3\2\2\2\2\t\3\2\2\2\2\13\3\2\2\2\2\r")
-        buf.write("\3\2\2\2\2\17\3\2\2\2\2\21\3\2\2\2\2\23\3\2\2\2\2\25\3")
-        buf.write("\2\2\2\2\27\3\2\2\2\2\31\3\2\2\2\2\33\3\2\2\2\2\35\3\2")
-        buf.write("\2\2\2\37\3\2\2\2\2!\3\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2\'")
-        buf.write("\3\2\2\2\2)\3\2\2\2\2+\3\2\2\2\2-\3\2\2\2\2/\3\2\2\2\2")
-        buf.write("\61\3\2\2\2\2\63\3\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\29")
-        buf.write("\3\2\2\2\2;\3\2\2\2\2=\3\2\2\2\2?\3\2\2\2\2A\3\2\2\2\2")
-        buf.write("C\3\2\2\2\2E\3\2\2\2\2G\3\2\2\2\2I\3\2\2\2\2K\3\2\2\2")
-        buf.write("\2M\3\2\2\2\2O\3\2\2\2\2Q\3\2\2\2\2S\3\2\2\2\2U\3\2\2")
-        buf.write("\2\2W\3\2\2\2\2Y\3\2\2\2\2[\3\2\2\2\2]\3\2\2\2\2_\3\2")
-        buf.write("\2\2\2a\3\2\2\2\3c\3\2\2\2\5f\3\2\2\2\7h\3\2\2\2\tm\3")
-        buf.write("\2\2\2\13o\3\2\2\2\rs\3\2\2\2\17z\3\2\2\2\21\u0080\3\2")
-        buf.write("\2\2\23\u0082\3\2\2\2\25\u0084\3\2\2\2\27\u0086\3\2\2")
-        buf.write("\2\31\u0088\3\2\2\2\33\u008a\3\2\2\2\35\u008c\3\2\2\2")
-        buf.write("\37\u008e\3\2\2\2!\u0090\3\2\2\2#\u0092\3\2\2\2%\u0094")
-        buf.write("\3\2\2\2\'\u0097\3\2\2\2)\u009c\3\2\2\2+\u00a0\3\2\2\2")
-        buf.write("-\u00a8\3\2\2\2/\u00ae\3\2\2\2\61\u00b5\3\2\2\2\63\u00ba")
-        buf.write("\3\2\2\2\65\u00bc\3\2\2\2\67\u00be\3\2\2\29\u00c0\3\2")
-        buf.write("\2\2;\u00c2\3\2\2\2=\u00c4\3\2\2\2?\u00c6\3\2\2\2A\u00c8")
-        buf.write("\3\2\2\2C\u00ca\3\2\2\2E\u00cc\3\2\2\2G\u00ce\3\2\2\2")
-        buf.write("I\u00d0\3\2\2\2K\u00d2\3\2\2\2M\u00d4\3\2\2\2O\u00d6\3")
-        buf.write("\2\2\2Q\u00d8\3\2\2\2S\u00db\3\2\2\2U\u00dd\3\2\2\2W\u00e0")
-        buf.write("\3\2\2\2Y\u00e3\3\2\2\2[\u00e6\3\2\2\2]\u00e9\3\2\2\2")
-        buf.write("_\u00ec\3\2\2\2a\u00f2\3\2\2\2cd\7/\2\2de\7@\2\2e\4\3")
-        buf.write("\2\2\2fg\7a\2\2g\6\3\2\2\2hi\7%\2\2ij\7K\2\2jk\7F\2\2")
-        buf.write("kl\7>\2\2l\b\3\2\2\2mn\7@\2\2n\n\3\2\2\2op\7%\2\2pq\7")
-        buf.write("P\2\2qr\7>\2\2r\f\3\2\2\2st\7%\2\2tu\7K\2\2uv\7F\2\2v")
-        buf.write("w\7>\2\2wx\7\60\2\2xy\7@\2\2y\16\3\2\2\2z{\7%\2\2{|\7")
-        buf.write("P\2\2|}\7>\2\2}~\7\60\2\2~\177\7@\2\2\177\20\3\2\2\2\u0080")
-        buf.write("\u0081\7\62\2\2\u0081\22\3\2\2\2\u0082\u0083\7\63\2\2")
-        buf.write("\u0083\24\3\2\2\2\u0084\u0085\7\64\2\2\u0085\26\3\2\2")
-        buf.write("\2\u0086\u0087\7\65\2\2\u0087\30\3\2\2\2\u0088\u0089\7")
-        buf.write("\66\2\2\u0089\32\3\2\2\2\u008a\u008b\7\67\2\2\u008b\34")
-        buf.write("\3\2\2\2\u008c\u008d\78\2\2\u008d\36\3\2\2\2\u008e\u008f")
-        buf.write("\79\2\2\u008f \3\2\2\2\u0090\u0091\7:\2\2\u0091\"\3\2")
-        buf.write("\2\2\u0092\u0093\7;\2\2\u0093$\3\2\2\2\u0094\u0095\7k")
-        buf.write("\2\2\u0095\u0096\7h\2\2\u0096&\3\2\2\2\u0097\u0098\7g")
-        buf.write("\2\2\u0098\u0099\7n\2\2\u0099\u009a\7u\2\2\u009a\u009b")
-        buf.write("\7g\2\2\u009b(\3\2\2\2\u009c\u009d\7h\2\2\u009d\u009e")
-        buf.write("\7q\2\2\u009e\u009f\7t\2\2\u009f*\3\2\2\2\u00a0\u00a1")
-        buf.write("\7h\2\2\u00a1\u00a2\7q\2\2\u00a2\u00a3\7t\2\2\u00a3\u00a4")
-        buf.write("\7G\2\2\u00a4\u00a5\7c\2\2\u00a5\u00a6\7e\2\2\u00a6\u00a7")
-        buf.write("\7j\2\2\u00a7,\3\2\2\2\u00a8\u00a9\7y\2\2\u00a9\u00aa")
-        buf.write("\7j\2\2\u00aa\u00ab\7k\2\2\u00ab\u00ac\7n\2\2\u00ac\u00ad")
-        buf.write("\7g\2\2\u00ad.\3\2\2\2\u00ae\u00af\7t\2\2\u00af\u00b0")
-        buf.write("\7g\2\2\u00b0\u00b1\7v\2\2\u00b1\u00b2\7w\2\2\u00b2\u00b3")
-        buf.write("\7t\2\2\u00b3\u00b4\7p\2\2\u00b4\60\3\2\2\2\u00b5\u00b6")
-        buf.write("\7P\2\2\u00b6\u00b7\7W\2\2\u00b7\u00b8\7N\2\2\u00b8\u00b9")
-        buf.write("\7N\2\2\u00b9\62\3\2\2\2\u00ba\u00bb\7*\2\2\u00bb\64\3")
-        buf.write("\2\2\2\u00bc\u00bd\7+\2\2\u00bd\66\3\2\2\2\u00be\u00bf")
-        buf.write("\7]\2\2\u00bf8\3\2\2\2\u00c0\u00c1\7_\2\2\u00c1:\3\2\2")
-        buf.write("\2\u00c2\u00c3\7}\2\2\u00c3<\3\2\2\2\u00c4\u00c5\7\177")
-        buf.write("\2\2\u00c5>\3\2\2\2\u00c6\u00c7\7$\2\2\u00c7@\3\2\2\2")
-        buf.write("\u00c8\u00c9\7?\2\2\u00c9B\3\2\2\2\u00ca\u00cb\7\60\2")
-        buf.write("\2\u00cbD\3\2\2\2\u00cc\u00cd\7.\2\2\u00cdF\3\2\2\2\u00ce")
-        buf.write("\u00cf\7=\2\2\u00cfH\3\2\2\2\u00d0\u00d1\7-\2\2\u00d1")
-        buf.write("J\3\2\2\2\u00d2\u00d3\7\u2214\2\2\u00d3L\3\2\2\2\u00d4")
-        buf.write("\u00d5\7,\2\2\u00d5N\3\2\2\2\u00d6\u00d7\7\61\2\2\u00d7")
-        buf.write("P\3\2\2\2\u00d8\u00d9\7?\2\2\u00d9\u00da\7?\2\2\u00da")
-        buf.write("R\3\2\2\2\u00db\u00dc\7>\2\2\u00dcT\3\2\2\2\u00dd\u00de")
-        buf.write("\7>\2\2\u00de\u00df\7?\2\2\u00dfV\3\2\2\2\u00e0\u00e1")
-        buf.write("\7@\2\2\u00e1\u00e2\7?\2\2\u00e2X\3\2\2\2\u00e3\u00e4")
-        buf.write("\7#\2\2\u00e4\u00e5\7?\2\2\u00e5Z\3\2\2\2\u00e6\u00e7")
-        buf.write("\7(\2\2\u00e7\u00e8\7(\2\2\u00e8\\\3\2\2\2\u00e9\u00ea")
-        buf.write("\7~\2\2\u00ea\u00eb\7~\2\2\u00eb^\3\2\2\2\u00ec\u00ed")
-        buf.write("\7%\2\2\u00ed\u00ee\7Q\2\2\u00ee\u00ef\7R\2\2\u00ef\u00f0")
-        buf.write("\7>\2\2\u00f0`\3\2\2\2\u00f1\u00f3\t\2\2\2\u00f2\u00f1")
-        buf.write("\3\2\2\2\u00f3\u00f4\3\2\2\2\u00f4\u00f2\3\2\2\2\u00f4")
-        buf.write("\u00f5\3\2\2\2\u00f5\u00f6\3\2\2\2\u00f6\u00f7\b\61\2")
-        buf.write("\2\u00f7b\3\2\2\2\4\2\u00f4\3\b\2\2")
+        buf.write("\4&\t&\4\'\t\'\4(\t(\4)\t)\4*\t*\3\2\3\2\3\2\3\3\3\3\3")
+        buf.write("\4\3\4\3\4\3\5\3\5\3\5\3\5\3\5\3\6\3\6\3\6\3\6\3\7\3\7")
+        buf.write("\3\7\3\7\3\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\t\3")
+        buf.write("\t\3\t\3\t\3\t\3\t\3\t\3\n\3\n\3\n\3\n\3\n\3\13\3\13\3")
+        buf.write("\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17\3\20\3\20\3\21\3\21")
+        buf.write("\3\22\3\22\3\23\3\23\3\24\3\24\3\25\3\25\3\26\3\26\3\26")
+        buf.write("\3\26\3\26\3\27\3\27\3\30\3\30\3\30\3\30\3\30\3\30\3\31")
+        buf.write("\3\31\3\31\3\31\3\31\3\31\3\31\3\32\3\32\3\32\3\32\3\32")
+        buf.write("\3\33\3\33\3\33\3\33\3\33\3\33\3\34\3\34\3\34\3\34\3\34")
+        buf.write("\3\34\3\34\3\35\3\35\3\35\3\35\3\35\3\36\3\36\3\36\3\36")
+        buf.write("\3\36\3\36\3\37\3\37\3\37\3\37\3\37\3\37\3\37\3 \3 \3")
+        buf.write("!\3!\3\"\3\"\3#\3#\3$\3$\3%\3%\3&\3&\3\'\3\'\3(\3(\3)")
+        buf.write("\3)\3*\6*\u00e4\n*\r*\16*\u00e5\3*\3*\2\2+\3\3\5\4\7\5")
+        buf.write("\t\6\13\7\r\b\17\t\21\n\23\13\25\f\27\r\31\16\33\17\35")
+        buf.write("\20\37\21!\22#\23%\24\'\25)\26+\27-\30/\31\61\32\63\33")
+        buf.write("\65\34\67\359\36;\37= ?!A\"C#E$G%I&K\'M(O)Q*S+\3\2\3\5")
+        buf.write("\2\13\f\17\17\"\"\2\u00e9\2\3\3\2\2\2\2\5\3\2\2\2\2\7")
+        buf.write("\3\2\2\2\2\t\3\2\2\2\2\13\3\2\2\2\2\r\3\2\2\2\2\17\3\2")
+        buf.write("\2\2\2\21\3\2\2\2\2\23\3\2\2\2\2\25\3\2\2\2\2\27\3\2\2")
+        buf.write("\2\2\31\3\2\2\2\2\33\3\2\2\2\2\35\3\2\2\2\2\37\3\2\2\2")
+        buf.write("\2!\3\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2\'\3\2\2\2\2)\3\2\2")
+        buf.write("\2\2+\3\2\2\2\2-\3\2\2\2\2/\3\2\2\2\2\61\3\2\2\2\2\63")
+        buf.write("\3\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\29\3\2\2\2\2;\3\2\2")
+        buf.write("\2\2=\3\2\2\2\2?\3\2\2\2\2A\3\2\2\2\2C\3\2\2\2\2E\3\2")
+        buf.write("\2\2\2G\3\2\2\2\2I\3\2\2\2\2K\3\2\2\2\2M\3\2\2\2\2O\3")
+        buf.write("\2\2\2\2Q\3\2\2\2\2S\3\2\2\2\3U\3\2\2\2\5X\3\2\2\2\7Z")
+        buf.write("\3\2\2\2\t]\3\2\2\2\13b\3\2\2\2\rf\3\2\2\2\17n\3\2\2\2")
+        buf.write("\21t\3\2\2\2\23{\3\2\2\2\25\u0080\3\2\2\2\27\u0082\3\2")
+        buf.write("\2\2\31\u0084\3\2\2\2\33\u0086\3\2\2\2\35\u0088\3\2\2")
+        buf.write("\2\37\u008a\3\2\2\2!\u008c\3\2\2\2#\u008e\3\2\2\2%\u0090")
+        buf.write("\3\2\2\2\'\u0092\3\2\2\2)\u0094\3\2\2\2+\u0096\3\2\2\2")
+        buf.write("-\u009b\3\2\2\2/\u009d\3\2\2\2\61\u00a3\3\2\2\2\63\u00aa")
+        buf.write("\3\2\2\2\65\u00af\3\2\2\2\67\u00b5\3\2\2\29\u00bc\3\2")
+        buf.write("\2\2;\u00c1\3\2\2\2=\u00c7\3\2\2\2?\u00ce\3\2\2\2A\u00d0")
+        buf.write("\3\2\2\2C\u00d2\3\2\2\2E\u00d4\3\2\2\2G\u00d6\3\2\2\2")
+        buf.write("I\u00d8\3\2\2\2K\u00da\3\2\2\2M\u00dc\3\2\2\2O\u00de\3")
+        buf.write("\2\2\2Q\u00e0\3\2\2\2S\u00e3\3\2\2\2UV\7/\2\2VW\7@\2\2")
+        buf.write("W\4\3\2\2\2XY\7a\2\2Y\6\3\2\2\2Z[\7k\2\2[\\\7h\2\2\\\b")
+        buf.write("\3\2\2\2]^\7g\2\2^_\7n\2\2_`\7u\2\2`a\7g\2\2a\n\3\2\2")
+        buf.write("\2bc\7h\2\2cd\7q\2\2de\7t\2\2e\f\3\2\2\2fg\7h\2\2gh\7")
+        buf.write("q\2\2hi\7t\2\2ij\7G\2\2jk\7c\2\2kl\7e\2\2lm\7j\2\2m\16")
+        buf.write("\3\2\2\2no\7y\2\2op\7j\2\2pq\7k\2\2qr\7n\2\2rs\7g\2\2")
+        buf.write("s\20\3\2\2\2tu\7t\2\2uv\7g\2\2vw\7v\2\2wx\7w\2\2xy\7t")
+        buf.write("\2\2yz\7p\2\2z\22\3\2\2\2{|\7P\2\2|}\7W\2\2}~\7N\2\2~")
+        buf.write("\177\7N\2\2\177\24\3\2\2\2\u0080\u0081\7*\2\2\u0081\26")
+        buf.write("\3\2\2\2\u0082\u0083\7+\2\2\u0083\30\3\2\2\2\u0084\u0085")
+        buf.write("\7]\2\2\u0085\32\3\2\2\2\u0086\u0087\7_\2\2\u0087\34\3")
+        buf.write("\2\2\2\u0088\u0089\7}\2\2\u0089\36\3\2\2\2\u008a\u008b")
+        buf.write("\7\177\2\2\u008b \3\2\2\2\u008c\u008d\7$\2\2\u008d\"\3")
+        buf.write("\2\2\2\u008e\u008f\7?\2\2\u008f$\3\2\2\2\u0090\u0091\7")
+        buf.write("\60\2\2\u0091&\3\2\2\2\u0092\u0093\7.\2\2\u0093(\3\2\2")
+        buf.write("\2\u0094\u0095\7=\2\2\u0095*\3\2\2\2\u0096\u0097\7%\2")
+        buf.write("\2\u0097\u0098\7K\2\2\u0098\u0099\7F\2\2\u0099\u009a\7")
+        buf.write(">\2\2\u009a,\3\2\2\2\u009b\u009c\7@\2\2\u009c.\3\2\2\2")
+        buf.write("\u009d\u009e\7%\2\2\u009e\u009f\7K\2\2\u009f\u00a0\7F")
+        buf.write("\2\2\u00a0\u00a1\7>\2\2\u00a1\u00a2\7#\2\2\u00a2\60\3")
+        buf.write("\2\2\2\u00a3\u00a4\7%\2\2\u00a4\u00a5\7K\2\2\u00a5\u00a6")
+        buf.write("\7F\2\2\u00a6\u00a7\7>\2\2\u00a7\u00a8\7\60\2\2\u00a8")
+        buf.write("\u00a9\7@\2\2\u00a9\62\3\2\2\2\u00aa\u00ab\7%\2\2\u00ab")
+        buf.write("\u00ac\7Q\2\2\u00ac\u00ad\7R\2\2\u00ad\u00ae\7>\2\2\u00ae")
+        buf.write("\64\3\2\2\2\u00af\u00b0\7%\2\2\u00b0\u00b1\7Q\2\2\u00b1")
+        buf.write("\u00b2\7R\2\2\u00b2\u00b3\7>\2\2\u00b3\u00b4\7#\2\2\u00b4")
+        buf.write("\66\3\2\2\2\u00b5\u00b6\7%\2\2\u00b6\u00b7\7Q\2\2\u00b7")
+        buf.write("\u00b8\7R\2\2\u00b8\u00b9\7>\2\2\u00b9\u00ba\7\60\2\2")
+        buf.write("\u00ba\u00bb\7@\2\2\u00bb8\3\2\2\2\u00bc\u00bd\7%\2\2")
+        buf.write("\u00bd\u00be\7N\2\2\u00be\u00bf\7V\2\2\u00bf\u00c0\7>")
+        buf.write("\2\2\u00c0:\3\2\2\2\u00c1\u00c2\7%\2\2\u00c2\u00c3\7N")
+        buf.write("\2\2\u00c3\u00c4\7V\2\2\u00c4\u00c5\7>\2\2\u00c5\u00c6")
+        buf.write("\7#\2\2\u00c6<\3\2\2\2\u00c7\u00c8\7%\2\2\u00c8\u00c9")
+        buf.write("\7N\2\2\u00c9\u00ca\7V\2\2\u00ca\u00cb\7>\2\2\u00cb\u00cc")
+        buf.write("\7\60\2\2\u00cc\u00cd\7@\2\2\u00cd>\3\2\2\2\u00ce\u00cf")
+        buf.write("\7\62\2\2\u00cf@\3\2\2\2\u00d0\u00d1\7\63\2\2\u00d1B\3")
+        buf.write("\2\2\2\u00d2\u00d3\7\64\2\2\u00d3D\3\2\2\2\u00d4\u00d5")
+        buf.write("\7\65\2\2\u00d5F\3\2\2\2\u00d6\u00d7\7\66\2\2\u00d7H\3")
+        buf.write("\2\2\2\u00d8\u00d9\7\67\2\2\u00d9J\3\2\2\2\u00da\u00db")
+        buf.write("\78\2\2\u00dbL\3\2\2\2\u00dc\u00dd\79\2\2\u00ddN\3\2\2")
+        buf.write("\2\u00de\u00df\7:\2\2\u00dfP\3\2\2\2\u00e0\u00e1\7;\2")
+        buf.write("\2\u00e1R\3\2\2\2\u00e2\u00e4\t\2\2\2\u00e3\u00e2\3\2")
+        buf.write("\2\2\u00e4\u00e5\3\2\2\2\u00e5\u00e3\3\2\2\2\u00e5\u00e6")
+        buf.write("\3\2\2\2\u00e6\u00e7\3\2\2\2\u00e7\u00e8\b*\2\2\u00e8")
+        buf.write("T\3\2\2\2\4\2\u00e5\3\b\2\2")
         return buf.getvalue()
 
 
@@ -151,26 +144,19 @@ class SearchLexer(Lexer):
     T__37 = 38
     T__38 = 39
     T__39 = 40
-    T__40 = 41
-    T__41 = 42
-    T__42 = 43
-    T__43 = 44
-    T__44 = 45
-    T__45 = 46
-    T__46 = 47
-    WS = 48
+    WS = 41
 
     channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]
 
     modeNames = [ "DEFAULT_MODE" ]
 
     literalNames = [ "<INVALID>",
-            "'->'", "'_'", "'#ID<'", "'>'", "'#N<'", "'#ID<.>'", "'#N<.>'", 
-            "'0'", "'1'", "'2'", "'3'", "'4'", "'5'", "'6'", "'7'", "'8'", 
-            "'9'", "'if'", "'else'", "'for'", "'forEach'", "'while'", "'return'", 
-            "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", 
-            "'='", "'.'", "','", "';'", "'+'", "'\u2212'", "'*'", "'/'", 
-            "'=='", "'<'", "'<='", "'>='", "'!='", "'&&'", "'||'", "'#OP<'" ]
+            "'->'", "'_'", "'if'", "'else'", "'for'", "'forEach'", "'while'", 
+            "'return'", "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", 
+            "'\"'", "'='", "'.'", "','", "';'", "'#ID<'", "'>'", "'#ID<!'", 
+            "'#ID<.>'", "'#OP<'", "'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", 
+            "'#LT<.>'", "'0'", "'1'", "'2'", "'3'", "'4'", "'5'", "'6'", 
+            "'7'", "'8'", "'9'" ]
 
     symbolicNames = [ "<INVALID>",
             "WS" ]
@@ -181,8 +167,7 @@ class SearchLexer(Lexer):
                   "T__20", "T__21", "T__22", "T__23", "T__24", "T__25", 
                   "T__26", "T__27", "T__28", "T__29", "T__30", "T__31", 
                   "T__32", "T__33", "T__34", "T__35", "T__36", "T__37", 
-                  "T__38", "T__39", "T__40", "T__41", "T__42", "T__43", 
-                  "T__44", "T__45", "T__46", "WS" ]
+                  "T__38", "T__39", "WS" ]
 
     grammarFileName = "Search.g4"
 
diff --git a/code/antlr4/SearchListener.py b/code/antlr4/SearchListener.py
index 1879435..41f83c2 100644
--- a/code/antlr4/SearchListener.py
+++ b/code/antlr4/SearchListener.py
@@ -17,12 +17,12 @@ class SearchListener(ParseTreeListener):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#expr.
-    def enterExpr(self, ctx:SearchParser.ExprContext):
+    # Enter a parse tree produced by SearchParser#code.
+    def enterCode(self, ctx:SearchParser.CodeContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#expr.
-    def exitExpr(self, ctx:SearchParser.ExprContext):
+    # Exit a parse tree produced by SearchParser#code.
+    def exitCode(self, ctx:SearchParser.CodeContext):
         pass
 
 
@@ -35,48 +35,57 @@ class SearchListener(ParseTreeListener):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#identifier.
-    def enterIdentifier(self, ctx:SearchParser.IdentifierContext):
+    # Enter a parse tree produced by SearchParser#keyword.
+    def enterKeyword(self, ctx:SearchParser.KeywordContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#identifier.
-    def exitIdentifier(self, ctx:SearchParser.IdentifierContext):
+    # Exit a parse tree produced by SearchParser#keyword.
+    def exitKeyword(self, ctx:SearchParser.KeywordContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#digit.
-    def enterDigit(self, ctx:SearchParser.DigitContext):
+    # Enter a parse tree produced by SearchParser#punctuator.
+    def enterPunctuator(self, ctx:SearchParser.PunctuatorContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#digit.
-    def exitDigit(self, ctx:SearchParser.DigitContext):
+    # Exit a parse tree produced by SearchParser#punctuator.
+    def exitPunctuator(self, ctx:SearchParser.PunctuatorContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#keyword.
-    def enterKeyword(self, ctx:SearchParser.KeywordContext):
+    # Enter a parse tree produced by SearchParser#identifier.
+    def enterIdentifier(self, ctx:SearchParser.IdentifierContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#keyword.
-    def exitKeyword(self, ctx:SearchParser.KeywordContext):
+    # Exit a parse tree produced by SearchParser#identifier.
+    def exitIdentifier(self, ctx:SearchParser.IdentifierContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#punctuator.
-    def enterPunctuator(self, ctx:SearchParser.PunctuatorContext):
+    # Enter a parse tree produced by SearchParser#operator.
+    def enterOperator(self, ctx:SearchParser.OperatorContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#punctuator.
-    def exitPunctuator(self, ctx:SearchParser.PunctuatorContext):
+    # Exit a parse tree produced by SearchParser#operator.
+    def exitOperator(self, ctx:SearchParser.OperatorContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#op.
-    def enterOp(self, ctx:SearchParser.OpContext):
+    # Enter a parse tree produced by SearchParser#literal.
+    def enterLiteral(self, ctx:SearchParser.LiteralContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#op.
-    def exitOp(self, ctx:SearchParser.OpContext):
+    # Exit a parse tree produced by SearchParser#literal.
+    def exitLiteral(self, ctx:SearchParser.LiteralContext):
+        pass
+
+
+    # Enter a parse tree produced by SearchParser#digit.
+    def enterDigit(self, ctx:SearchParser.DigitContext):
+        pass
+
+    # Exit a parse tree produced by SearchParser#digit.
+    def exitDigit(self, ctx:SearchParser.DigitContext):
         pass
 
 
diff --git a/code/antlr4/SearchParser.py b/code/antlr4/SearchParser.py
index 64b4fa5..800cb84 100644
--- a/code/antlr4/SearchParser.py
+++ b/code/antlr4/SearchParser.py
@@ -7,48 +7,54 @@ import sys
 
 def serializedATN():
     with StringIO() as buf:
-        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3\62")
-        buf.write("y\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7\4\b")
-        buf.write("\t\b\4\t\t\t\3\2\3\2\3\2\3\2\3\3\7\3\30\n\3\f\3\16\3\33")
-        buf.write("\13\3\3\4\3\4\3\4\3\4\3\4\5\4\"\n\4\3\5\3\5\7\5&\n\5\f")
-        buf.write("\5\16\5)\13\5\3\5\3\5\3\5\7\5.\n\5\f\5\16\5\61\13\5\3")
-        buf.write("\5\3\5\3\5\5\5\66\n\5\3\6\3\6\3\7\3\7\3\b\3\b\7\b>\n\b")
-        buf.write("\f\b\16\bA\13\b\3\b\3\b\3\b\7\bF\n\b\f\b\16\bI\13\b\3")
-        buf.write("\b\3\b\3\b\7\bN\n\b\f\b\16\bQ\13\b\3\b\3\b\3\b\7\bV\n")
-        buf.write("\b\f\b\16\bY\13\b\3\b\3\b\3\b\3\b\3\b\5\b`\n\b\3\t\3\t")
-        buf.write("\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\7")
-        buf.write("\tq\n\t\f\t\16\tt\13\t\3\t\5\tw\n\t\3\t\2\2\n\2\4\6\b")
-        buf.write("\n\f\16\20\2\4\3\2\n\23\3\2\24\32\2\u0093\2\22\3\2\2\2")
-        buf.write("\4\31\3\2\2\2\6!\3\2\2\2\b\65\3\2\2\2\n\67\3\2\2\2\f9")
-        buf.write("\3\2\2\2\16_\3\2\2\2\20v\3\2\2\2\22\23\5\4\3\2\23\24\7")
-        buf.write("\3\2\2\24\25\5\4\3\2\25\3\3\2\2\2\26\30\5\6\4\2\27\26")
-        buf.write("\3\2\2\2\30\33\3\2\2\2\31\27\3\2\2\2\31\32\3\2\2\2\32")
-        buf.write("\5\3\2\2\2\33\31\3\2\2\2\34\"\5\b\5\2\35\"\5\f\7\2\36")
-        buf.write("\"\5\16\b\2\37\"\5\20\t\2 \"\7\4\2\2!\34\3\2\2\2!\35\3")
-        buf.write("\2\2\2!\36\3\2\2\2!\37\3\2\2\2! \3\2\2\2\"\7\3\2\2\2#")
-        buf.write("\'\7\5\2\2$&\5\n\6\2%$\3\2\2\2&)\3\2\2\2\'%\3\2\2\2\'")
-        buf.write("(\3\2\2\2(*\3\2\2\2)\'\3\2\2\2*\66\7\6\2\2+/\7\7\2\2,")
-        buf.write(".\5\n\6\2-,\3\2\2\2.\61\3\2\2\2/-\3\2\2\2/\60\3\2\2\2")
-        buf.write("\60\62\3\2\2\2\61/\3\2\2\2\62\66\7\6\2\2\63\66\7\b\2\2")
-        buf.write("\64\66\7\t\2\2\65#\3\2\2\2\65+\3\2\2\2\65\63\3\2\2\2\65")
-        buf.write("\64\3\2\2\2\66\t\3\2\2\2\678\t\2\2\28\13\3\2\2\29:\t\3")
-        buf.write("\2\2:\r\3\2\2\2;?\7\33\2\2<>\5\6\4\2=<\3\2\2\2>A\3\2\2")
-        buf.write("\2?=\3\2\2\2?@\3\2\2\2@B\3\2\2\2A?\3\2\2\2B`\7\34\2\2")
-        buf.write("CG\7\35\2\2DF\5\6\4\2ED\3\2\2\2FI\3\2\2\2GE\3\2\2\2GH")
-        buf.write("\3\2\2\2HJ\3\2\2\2IG\3\2\2\2J`\7\36\2\2KO\7\37\2\2LN\5")
-        buf.write("\6\4\2ML\3\2\2\2NQ\3\2\2\2OM\3\2\2\2OP\3\2\2\2PR\3\2\2")
-        buf.write("\2QO\3\2\2\2R`\7 \2\2SW\7!\2\2TV\5\6\4\2UT\3\2\2\2VY\3")
-        buf.write("\2\2\2WU\3\2\2\2WX\3\2\2\2XZ\3\2\2\2YW\3\2\2\2Z`\7!\2")
-        buf.write("\2[`\7\"\2\2\\`\7#\2\2]`\7$\2\2^`\7%\2\2_;\3\2\2\2_C\3")
-        buf.write("\2\2\2_K\3\2\2\2_S\3\2\2\2_[\3\2\2\2_\\\3\2\2\2_]\3\2")
-        buf.write("\2\2_^\3\2\2\2`\17\3\2\2\2aw\7&\2\2bw\7\'\2\2cw\7(\2\2")
-        buf.write("dw\7)\2\2ew\7*\2\2fw\7+\2\2gw\7\6\2\2hw\7,\2\2iw\7-\2")
-        buf.write("\2jw\7*\2\2kw\7.\2\2lw\7/\2\2mw\7\60\2\2nr\7\61\2\2oq")
-        buf.write("\5\n\6\2po\3\2\2\2qt\3\2\2\2rp\3\2\2\2rs\3\2\2\2su\3\2")
-        buf.write("\2\2tr\3\2\2\2uw\7\6\2\2va\3\2\2\2vb\3\2\2\2vc\3\2\2\2")
-        buf.write("vd\3\2\2\2ve\3\2\2\2vf\3\2\2\2vg\3\2\2\2vh\3\2\2\2vi\3")
-        buf.write("\2\2\2vj\3\2\2\2vk\3\2\2\2vl\3\2\2\2vm\3\2\2\2vn\3\2\2")
-        buf.write("\2w\21\3\2\2\2\16\31!\'/\65?GOW_rv")
+        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3+")
+        buf.write("\u008a\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7")
+        buf.write("\4\b\t\b\4\t\t\t\4\n\t\n\3\2\3\2\3\2\3\2\3\3\7\3\32\n")
+        buf.write("\3\f\3\16\3\35\13\3\3\4\3\4\3\4\3\4\3\4\3\4\5\4%\n\4\3")
+        buf.write("\5\3\5\3\6\3\6\7\6+\n\6\f\6\16\6.\13\6\3\6\3\6\3\6\7\6")
+        buf.write("\63\n\6\f\6\16\6\66\13\6\3\6\3\6\3\6\7\6;\n\6\f\6\16\6")
+        buf.write(">\13\6\3\6\3\6\3\6\7\6C\n\6\f\6\16\6F\13\6\3\6\3\6\3\6")
+        buf.write("\3\6\3\6\5\6M\n\6\3\7\3\7\7\7Q\n\7\f\7\16\7T\13\7\3\7")
+        buf.write("\3\7\3\7\7\7Y\n\7\f\7\16\7\\\13\7\3\7\3\7\5\7`\n\7\3\b")
+        buf.write("\3\b\7\bd\n\b\f\b\16\bg\13\b\3\b\3\b\3\b\7\bl\n\b\f\b")
+        buf.write("\16\bo\13\b\3\b\3\b\5\bs\n\b\3\t\3\t\7\tw\n\t\f\t\16\t")
+        buf.write("z\13\t\3\t\3\t\3\t\7\t\177\n\t\f\t\16\t\u0082\13\t\3\t")
+        buf.write("\3\t\5\t\u0086\n\t\3\n\3\n\3\n\2\2\13\2\4\6\b\n\f\16\20")
+        buf.write("\22\2\4\3\2\5\13\3\2!*\2\u009d\2\24\3\2\2\2\4\33\3\2\2")
+        buf.write("\2\6$\3\2\2\2\b&\3\2\2\2\nL\3\2\2\2\f_\3\2\2\2\16r\3\2")
+        buf.write("\2\2\20\u0085\3\2\2\2\22\u0087\3\2\2\2\24\25\5\4\3\2\25")
+        buf.write("\26\7\3\2\2\26\27\5\4\3\2\27\3\3\2\2\2\30\32\5\6\4\2\31")
+        buf.write("\30\3\2\2\2\32\35\3\2\2\2\33\31\3\2\2\2\33\34\3\2\2\2")
+        buf.write("\34\5\3\2\2\2\35\33\3\2\2\2\36%\5\f\7\2\37%\5\b\5\2 %")
+        buf.write("\5\n\6\2!%\5\16\b\2\"%\5\20\t\2#%\7\4\2\2$\36\3\2\2\2")
+        buf.write("$\37\3\2\2\2$ \3\2\2\2$!\3\2\2\2$\"\3\2\2\2$#\3\2\2\2")
+        buf.write("%\7\3\2\2\2&\'\t\2\2\2\'\t\3\2\2\2(,\7\f\2\2)+\5\6\4\2")
+        buf.write("*)\3\2\2\2+.\3\2\2\2,*\3\2\2\2,-\3\2\2\2-/\3\2\2\2.,\3")
+        buf.write("\2\2\2/M\7\r\2\2\60\64\7\16\2\2\61\63\5\6\4\2\62\61\3")
+        buf.write("\2\2\2\63\66\3\2\2\2\64\62\3\2\2\2\64\65\3\2\2\2\65\67")
+        buf.write("\3\2\2\2\66\64\3\2\2\2\67M\7\17\2\28<\7\20\2\29;\5\6\4")
+        buf.write("\2:9\3\2\2\2;>\3\2\2\2<:\3\2\2\2<=\3\2\2\2=?\3\2\2\2>")
+        buf.write("<\3\2\2\2?M\7\21\2\2@D\7\22\2\2AC\5\6\4\2BA\3\2\2\2CF")
+        buf.write("\3\2\2\2DB\3\2\2\2DE\3\2\2\2EG\3\2\2\2FD\3\2\2\2GM\7\22")
+        buf.write("\2\2HM\7\23\2\2IM\7\24\2\2JM\7\25\2\2KM\7\26\2\2L(\3\2")
+        buf.write("\2\2L\60\3\2\2\2L8\3\2\2\2L@\3\2\2\2LH\3\2\2\2LI\3\2\2")
+        buf.write("\2LJ\3\2\2\2LK\3\2\2\2M\13\3\2\2\2NR\7\27\2\2OQ\5\22\n")
+        buf.write("\2PO\3\2\2\2QT\3\2\2\2RP\3\2\2\2RS\3\2\2\2SU\3\2\2\2T")
+        buf.write("R\3\2\2\2U`\7\30\2\2VZ\7\31\2\2WY\5\22\n\2XW\3\2\2\2Y")
+        buf.write("\\\3\2\2\2ZX\3\2\2\2Z[\3\2\2\2[]\3\2\2\2\\Z\3\2\2\2]`")
+        buf.write("\7\30\2\2^`\7\32\2\2_N\3\2\2\2_V\3\2\2\2_^\3\2\2\2`\r")
+        buf.write("\3\2\2\2ae\7\33\2\2bd\5\22\n\2cb\3\2\2\2dg\3\2\2\2ec\3")
+        buf.write("\2\2\2ef\3\2\2\2fh\3\2\2\2ge\3\2\2\2hs\7\30\2\2im\7\34")
+        buf.write("\2\2jl\5\22\n\2kj\3\2\2\2lo\3\2\2\2mk\3\2\2\2mn\3\2\2")
+        buf.write("\2np\3\2\2\2om\3\2\2\2ps\7\30\2\2qs\7\35\2\2ra\3\2\2\2")
+        buf.write("ri\3\2\2\2rq\3\2\2\2s\17\3\2\2\2tx\7\36\2\2uw\5\22\n\2")
+        buf.write("vu\3\2\2\2wz\3\2\2\2xv\3\2\2\2xy\3\2\2\2y{\3\2\2\2zx\3")
+        buf.write("\2\2\2{\u0086\7\30\2\2|\u0080\7\37\2\2}\177\5\22\n\2~")
+        buf.write("}\3\2\2\2\177\u0082\3\2\2\2\u0080~\3\2\2\2\u0080\u0081")
+        buf.write("\3\2\2\2\u0081\u0083\3\2\2\2\u0082\u0080\3\2\2\2\u0083")
+        buf.write("\u0086\7\30\2\2\u0084\u0086\7 \2\2\u0085t\3\2\2\2\u0085")
+        buf.write("|\3\2\2\2\u0085\u0084\3\2\2\2\u0086\21\3\2\2\2\u0087\u0088")
+        buf.write("\t\3\2\2\u0088\23\3\2\2\2\22\33$,\64<DLRZ_emrx\u0080\u0085")
         return buf.getvalue()
 
 
@@ -62,14 +68,13 @@ class SearchParser ( Parser ):
 
     sharedContextCache = PredictionContextCache()
 
-    literalNames = [ "<INVALID>", "'->'", "'_'", "'#ID<'", "'>'", "'#N<'", 
-                     "'#ID<.>'", "'#N<.>'", "'0'", "'1'", "'2'", "'3'", 
-                     "'4'", "'5'", "'6'", "'7'", "'8'", "'9'", "'if'", "'else'", 
-                     "'for'", "'forEach'", "'while'", "'return'", "'NULL'", 
-                     "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", "'='", 
-                     "'.'", "','", "';'", "'+'", "'\u2212'", "'*'", "'/'", 
-                     "'=='", "'<'", "'<='", "'>='", "'!='", "'&&'", "'||'", 
-                     "'#OP<'" ]
+    literalNames = [ "<INVALID>", "'->'", "'_'", "'if'", "'else'", "'for'", 
+                     "'forEach'", "'while'", "'return'", "'NULL'", "'('", 
+                     "')'", "'['", "']'", "'{'", "'}'", "'\"'", "'='", "'.'", 
+                     "','", "';'", "'#ID<'", "'>'", "'#ID<!'", "'#ID<.>'", 
+                     "'#OP<'", "'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", 
+                     "'#LT<.>'", "'0'", "'1'", "'2'", "'3'", "'4'", "'5'", 
+                     "'6'", "'7'", "'8'", "'9'" ]
 
     symbolicNames = [ "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
@@ -81,21 +86,20 @@ class SearchParser ( Parser ):
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
-                      "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
-                      "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
-                      "WS" ]
+                      "<INVALID>", "WS" ]
 
     RULE_query = 0
-    RULE_expr = 1
+    RULE_code = 1
     RULE_token = 2
-    RULE_identifier = 3
-    RULE_digit = 4
-    RULE_keyword = 5
-    RULE_punctuator = 6
-    RULE_op = 7
+    RULE_keyword = 3
+    RULE_punctuator = 4
+    RULE_identifier = 5
+    RULE_operator = 6
+    RULE_literal = 7
+    RULE_digit = 8
 
-    ruleNames =  [ "query", "expr", "token", "identifier", "digit", "keyword", 
-                   "punctuator", "op" ]
+    ruleNames =  [ "query", "code", "token", "keyword", "punctuator", "identifier", 
+                   "operator", "literal", "digit" ]
 
     EOF = Token.EOF
     T__0=1
@@ -138,14 +142,7 @@ class SearchParser ( Parser ):
     T__37=38
     T__38=39
     T__39=40
-    T__40=41
-    T__41=42
-    T__42=43
-    T__43=44
-    T__44=45
-    T__45=46
-    T__46=47
-    WS=48
+    WS=41
 
     def __init__(self, input:TokenStream, output:TextIO = sys.stdout):
         super().__init__(input, output)
@@ -161,11 +158,11 @@ class SearchParser ( Parser ):
             super().__init__(parent, invokingState)
             self.parser = parser
 
-        def expr(self, i:int=None):
+        def code(self, i:int=None):
             if i is None:
-                return self.getTypedRuleContexts(SearchParser.ExprContext)
+                return self.getTypedRuleContexts(SearchParser.CodeContext)
             else:
-                return self.getTypedRuleContext(SearchParser.ExprContext,i)
+                return self.getTypedRuleContext(SearchParser.CodeContext,i)
 
 
         def getRuleIndex(self):
@@ -188,12 +185,12 @@ class SearchParser ( Parser ):
         self.enterRule(localctx, 0, self.RULE_query)
         try:
             self.enterOuterAlt(localctx, 1)
-            self.state = 16
-            self.expr()
-            self.state = 17
-            self.match(SearchParser.T__0)
             self.state = 18
-            self.expr()
+            self.code()
+            self.state = 19
+            self.match(SearchParser.T__0)
+            self.state = 20
+            self.code()
         except RecognitionException as re:
             localctx.exception = re
             self._errHandler.reportError(self, re)
@@ -202,7 +199,7 @@ class SearchParser ( Parser ):
             self.exitRule()
         return localctx
 
-    class ExprContext(ParserRuleContext):
+    class CodeContext(ParserRuleContext):
 
         def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
             super().__init__(parent, invokingState)
@@ -216,33 +213,33 @@ class SearchParser ( Parser ):
 
 
         def getRuleIndex(self):
-            return SearchParser.RULE_expr
+            return SearchParser.RULE_code
 
         def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterExpr" ):
-                listener.enterExpr(self)
+            if hasattr( listener, "enterCode" ):
+                listener.enterCode(self)
 
         def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitExpr" ):
-                listener.exitExpr(self)
+            if hasattr( listener, "exitCode" ):
+                listener.exitCode(self)
 
 
 
 
-    def expr(self):
+    def code(self):
 
-        localctx = SearchParser.ExprContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 2, self.RULE_expr)
+        localctx = SearchParser.CodeContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 2, self.RULE_code)
         self._la = 0 # Token type
         try:
             self.enterOuterAlt(localctx, 1)
-            self.state = 23
+            self.state = 25
             self._errHandler.sync(self)
             _la = self._input.LA(1)
-            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                self.state = 20
+            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                self.state = 22
                 self.token()
-                self.state = 25
+                self.state = 27
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
 
@@ -272,8 +269,12 @@ class SearchParser ( Parser ):
             return self.getTypedRuleContext(SearchParser.PunctuatorContext,0)
 
 
-        def op(self):
-            return self.getTypedRuleContext(SearchParser.OpContext,0)
+        def operator(self):
+            return self.getTypedRuleContext(SearchParser.OperatorContext,0)
+
+
+        def literal(self):
+            return self.getTypedRuleContext(SearchParser.LiteralContext,0)
 
 
         def getRuleIndex(self):
@@ -295,124 +296,38 @@ class SearchParser ( Parser ):
         localctx = SearchParser.TokenContext(self, self._ctx, self.state)
         self.enterRule(localctx, 4, self.RULE_token)
         try:
-            self.state = 31
+            self.state = 34
             self._errHandler.sync(self)
             token = self._input.LA(1)
-            if token in [SearchParser.T__2, SearchParser.T__4, SearchParser.T__5, SearchParser.T__6]:
+            if token in [SearchParser.T__20, SearchParser.T__22, SearchParser.T__23]:
                 self.enterOuterAlt(localctx, 1)
-                self.state = 26
+                self.state = 28
                 self.identifier()
                 pass
-            elif token in [SearchParser.T__17, SearchParser.T__18, SearchParser.T__19, SearchParser.T__20, SearchParser.T__21, SearchParser.T__22, SearchParser.T__23]:
+            elif token in [SearchParser.T__2, SearchParser.T__3, SearchParser.T__4, SearchParser.T__5, SearchParser.T__6, SearchParser.T__7, SearchParser.T__8]:
                 self.enterOuterAlt(localctx, 2)
-                self.state = 27
+                self.state = 29
                 self.keyword()
                 pass
-            elif token in [SearchParser.T__24, SearchParser.T__26, SearchParser.T__28, SearchParser.T__30, SearchParser.T__31, SearchParser.T__32, SearchParser.T__33, SearchParser.T__34]:
+            elif token in [SearchParser.T__9, SearchParser.T__11, SearchParser.T__13, SearchParser.T__15, SearchParser.T__16, SearchParser.T__17, SearchParser.T__18, SearchParser.T__19]:
                 self.enterOuterAlt(localctx, 3)
-                self.state = 28
+                self.state = 30
                 self.punctuator()
                 pass
-            elif token in [SearchParser.T__3, SearchParser.T__35, SearchParser.T__36, SearchParser.T__37, SearchParser.T__38, SearchParser.T__39, SearchParser.T__40, SearchParser.T__41, SearchParser.T__42, SearchParser.T__43, SearchParser.T__44, SearchParser.T__45, SearchParser.T__46]:
+            elif token in [SearchParser.T__24, SearchParser.T__25, SearchParser.T__26]:
                 self.enterOuterAlt(localctx, 4)
-                self.state = 29
-                self.op()
+                self.state = 31
+                self.operator()
                 pass
-            elif token in [SearchParser.T__1]:
+            elif token in [SearchParser.T__27, SearchParser.T__28, SearchParser.T__29]:
                 self.enterOuterAlt(localctx, 5)
-                self.state = 30
-                self.match(SearchParser.T__1)
+                self.state = 32
+                self.literal()
                 pass
-            else:
-                raise NoViableAltException(self)
-
-        except RecognitionException as re:
-            localctx.exception = re
-            self._errHandler.reportError(self, re)
-            self._errHandler.recover(self, re)
-        finally:
-            self.exitRule()
-        return localctx
-
-    class IdentifierContext(ParserRuleContext):
-
-        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
-            super().__init__(parent, invokingState)
-            self.parser = parser
-
-        def digit(self, i:int=None):
-            if i is None:
-                return self.getTypedRuleContexts(SearchParser.DigitContext)
-            else:
-                return self.getTypedRuleContext(SearchParser.DigitContext,i)
-
-
-        def getRuleIndex(self):
-            return SearchParser.RULE_identifier
-
-        def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterIdentifier" ):
-                listener.enterIdentifier(self)
-
-        def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitIdentifier" ):
-                listener.exitIdentifier(self)
-
-
-
-
-    def identifier(self):
-
-        localctx = SearchParser.IdentifierContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 6, self.RULE_identifier)
-        self._la = 0 # Token type
-        try:
-            self.state = 51
-            self._errHandler.sync(self)
-            token = self._input.LA(1)
-            if token in [SearchParser.T__2]:
-                self.enterOuterAlt(localctx, 1)
+            elif token in [SearchParser.T__1]:
+                self.enterOuterAlt(localctx, 6)
                 self.state = 33
-                self.match(SearchParser.T__2)
-                self.state = 37
-                self._errHandler.sync(self)
-                _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0):
-                    self.state = 34
-                    self.digit()
-                    self.state = 39
-                    self._errHandler.sync(self)
-                    _la = self._input.LA(1)
-
-                self.state = 40
-                self.match(SearchParser.T__3)
-                pass
-            elif token in [SearchParser.T__4]:
-                self.enterOuterAlt(localctx, 2)
-                self.state = 41
-                self.match(SearchParser.T__4)
-                self.state = 45
-                self._errHandler.sync(self)
-                _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0):
-                    self.state = 42
-                    self.digit()
-                    self.state = 47
-                    self._errHandler.sync(self)
-                    _la = self._input.LA(1)
-
-                self.state = 48
-                self.match(SearchParser.T__3)
-                pass
-            elif token in [SearchParser.T__5]:
-                self.enterOuterAlt(localctx, 3)
-                self.state = 49
-                self.match(SearchParser.T__5)
-                pass
-            elif token in [SearchParser.T__6]:
-                self.enterOuterAlt(localctx, 4)
-                self.state = 50
-                self.match(SearchParser.T__6)
+                self.match(SearchParser.T__1)
                 pass
             else:
                 raise NoViableAltException(self)
@@ -425,49 +340,6 @@ class SearchParser ( Parser ):
             self.exitRule()
         return localctx
 
-    class DigitContext(ParserRuleContext):
-
-        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
-            super().__init__(parent, invokingState)
-            self.parser = parser
-
-
-        def getRuleIndex(self):
-            return SearchParser.RULE_digit
-
-        def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterDigit" ):
-                listener.enterDigit(self)
-
-        def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitDigit" ):
-                listener.exitDigit(self)
-
-
-
-
-    def digit(self):
-
-        localctx = SearchParser.DigitContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 8, self.RULE_digit)
-        self._la = 0 # Token type
-        try:
-            self.enterOuterAlt(localctx, 1)
-            self.state = 53
-            _la = self._input.LA(1)
-            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0)):
-                self._errHandler.recoverInline(self)
-            else:
-                self._errHandler.reportMatch(self)
-                self.consume()
-        except RecognitionException as re:
-            localctx.exception = re
-            self._errHandler.reportError(self, re)
-            self._errHandler.recover(self, re)
-        finally:
-            self.exitRule()
-        return localctx
-
     class KeywordContext(ParserRuleContext):
 
         def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
@@ -492,13 +364,13 @@ class SearchParser ( Parser ):
     def keyword(self):
 
         localctx = SearchParser.KeywordContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 10, self.RULE_keyword)
+        self.enterRule(localctx, 6, self.RULE_keyword)
         self._la = 0 # Token type
         try:
             self.enterOuterAlt(localctx, 1)
-            self.state = 55
+            self.state = 36
             _la = self._input.LA(1)
-            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23))) != 0)):
+            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8))) != 0)):
                 self._errHandler.recoverInline(self)
             else:
                 self._errHandler.reportMatch(self)
@@ -541,100 +413,100 @@ class SearchParser ( Parser ):
     def punctuator(self):
 
         localctx = SearchParser.PunctuatorContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 12, self.RULE_punctuator)
+        self.enterRule(localctx, 8, self.RULE_punctuator)
         self._la = 0 # Token type
         try:
-            self.state = 93
+            self.state = 74
             self._errHandler.sync(self)
             token = self._input.LA(1)
-            if token in [SearchParser.T__24]:
+            if token in [SearchParser.T__9]:
                 self.enterOuterAlt(localctx, 1)
-                self.state = 57
-                self.match(SearchParser.T__24)
-                self.state = 61
+                self.state = 38
+                self.match(SearchParser.T__9)
+                self.state = 42
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                    self.state = 58
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                    self.state = 39
                     self.token()
-                    self.state = 63
+                    self.state = 44
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 64
-                self.match(SearchParser.T__25)
+                self.state = 45
+                self.match(SearchParser.T__10)
                 pass
-            elif token in [SearchParser.T__26]:
+            elif token in [SearchParser.T__11]:
                 self.enterOuterAlt(localctx, 2)
-                self.state = 65
-                self.match(SearchParser.T__26)
-                self.state = 69
+                self.state = 46
+                self.match(SearchParser.T__11)
+                self.state = 50
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                    self.state = 66
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                    self.state = 47
                     self.token()
-                    self.state = 71
+                    self.state = 52
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 72
-                self.match(SearchParser.T__27)
+                self.state = 53
+                self.match(SearchParser.T__12)
                 pass
-            elif token in [SearchParser.T__28]:
+            elif token in [SearchParser.T__13]:
                 self.enterOuterAlt(localctx, 3)
-                self.state = 73
-                self.match(SearchParser.T__28)
-                self.state = 77
+                self.state = 54
+                self.match(SearchParser.T__13)
+                self.state = 58
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                    self.state = 74
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                    self.state = 55
                     self.token()
-                    self.state = 79
+                    self.state = 60
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 80
-                self.match(SearchParser.T__29)
+                self.state = 61
+                self.match(SearchParser.T__14)
                 pass
-            elif token in [SearchParser.T__30]:
+            elif token in [SearchParser.T__15]:
                 self.enterOuterAlt(localctx, 4)
-                self.state = 81
-                self.match(SearchParser.T__30)
-                self.state = 85
+                self.state = 62
+                self.match(SearchParser.T__15)
+                self.state = 66
                 self._errHandler.sync(self)
-                _alt = self._interp.adaptivePredict(self._input,8,self._ctx)
+                _alt = self._interp.adaptivePredict(self._input,5,self._ctx)
                 while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                     if _alt==1:
-                        self.state = 82
+                        self.state = 63
                         self.token() 
-                    self.state = 87
+                    self.state = 68
                     self._errHandler.sync(self)
-                    _alt = self._interp.adaptivePredict(self._input,8,self._ctx)
+                    _alt = self._interp.adaptivePredict(self._input,5,self._ctx)
 
-                self.state = 88
-                self.match(SearchParser.T__30)
+                self.state = 69
+                self.match(SearchParser.T__15)
                 pass
-            elif token in [SearchParser.T__31]:
+            elif token in [SearchParser.T__16]:
                 self.enterOuterAlt(localctx, 5)
-                self.state = 89
-                self.match(SearchParser.T__31)
+                self.state = 70
+                self.match(SearchParser.T__16)
                 pass
-            elif token in [SearchParser.T__32]:
+            elif token in [SearchParser.T__17]:
                 self.enterOuterAlt(localctx, 6)
-                self.state = 90
-                self.match(SearchParser.T__32)
+                self.state = 71
+                self.match(SearchParser.T__17)
                 pass
-            elif token in [SearchParser.T__33]:
+            elif token in [SearchParser.T__18]:
                 self.enterOuterAlt(localctx, 7)
-                self.state = 91
-                self.match(SearchParser.T__33)
+                self.state = 72
+                self.match(SearchParser.T__18)
                 pass
-            elif token in [SearchParser.T__34]:
+            elif token in [SearchParser.T__19]:
                 self.enterOuterAlt(localctx, 8)
-                self.state = 92
-                self.match(SearchParser.T__34)
+                self.state = 73
+                self.match(SearchParser.T__19)
                 pass
             else:
                 raise NoViableAltException(self)
@@ -647,7 +519,7 @@ class SearchParser ( Parser ):
             self.exitRule()
         return localctx
 
-    class OpContext(ParserRuleContext):
+    class IdentifierContext(ParserRuleContext):
 
         def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
             super().__init__(parent, invokingState)
@@ -661,125 +533,285 @@ class SearchParser ( Parser ):
 
 
         def getRuleIndex(self):
-            return SearchParser.RULE_op
+            return SearchParser.RULE_identifier
 
         def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterOp" ):
-                listener.enterOp(self)
+            if hasattr( listener, "enterIdentifier" ):
+                listener.enterIdentifier(self)
 
         def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitOp" ):
-                listener.exitOp(self)
+            if hasattr( listener, "exitIdentifier" ):
+                listener.exitIdentifier(self)
 
 
 
 
-    def op(self):
+    def identifier(self):
 
-        localctx = SearchParser.OpContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 14, self.RULE_op)
+        localctx = SearchParser.IdentifierContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 10, self.RULE_identifier)
         self._la = 0 # Token type
         try:
-            self.state = 116
+            self.state = 93
             self._errHandler.sync(self)
-            la_ = self._interp.adaptivePredict(self._input,11,self._ctx)
-            if la_ == 1:
+            token = self._input.LA(1)
+            if token in [SearchParser.T__20]:
                 self.enterOuterAlt(localctx, 1)
-                self.state = 95
-                self.match(SearchParser.T__35)
-                pass
+                self.state = 76
+                self.match(SearchParser.T__20)
+                self.state = 80
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 77
+                    self.digit()
+                    self.state = 82
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 2:
-                self.enterOuterAlt(localctx, 2)
-                self.state = 96
-                self.match(SearchParser.T__36)
+                self.state = 83
+                self.match(SearchParser.T__21)
                 pass
+            elif token in [SearchParser.T__22]:
+                self.enterOuterAlt(localctx, 2)
+                self.state = 84
+                self.match(SearchParser.T__22)
+                self.state = 88
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 85
+                    self.digit()
+                    self.state = 90
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 3:
+                self.state = 91
+                self.match(SearchParser.T__21)
+                pass
+            elif token in [SearchParser.T__23]:
                 self.enterOuterAlt(localctx, 3)
-                self.state = 97
-                self.match(SearchParser.T__37)
+                self.state = 92
+                self.match(SearchParser.T__23)
                 pass
+            else:
+                raise NoViableAltException(self)
 
-            elif la_ == 4:
-                self.enterOuterAlt(localctx, 4)
-                self.state = 98
-                self.match(SearchParser.T__38)
-                pass
+        except RecognitionException as re:
+            localctx.exception = re
+            self._errHandler.reportError(self, re)
+            self._errHandler.recover(self, re)
+        finally:
+            self.exitRule()
+        return localctx
 
-            elif la_ == 5:
-                self.enterOuterAlt(localctx, 5)
-                self.state = 99
-                self.match(SearchParser.T__39)
-                pass
+    class OperatorContext(ParserRuleContext):
 
-            elif la_ == 6:
-                self.enterOuterAlt(localctx, 6)
-                self.state = 100
-                self.match(SearchParser.T__40)
-                pass
+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
+            super().__init__(parent, invokingState)
+            self.parser = parser
 
-            elif la_ == 7:
-                self.enterOuterAlt(localctx, 7)
-                self.state = 101
-                self.match(SearchParser.T__3)
-                pass
+        def digit(self, i:int=None):
+            if i is None:
+                return self.getTypedRuleContexts(SearchParser.DigitContext)
+            else:
+                return self.getTypedRuleContext(SearchParser.DigitContext,i)
+
+
+        def getRuleIndex(self):
+            return SearchParser.RULE_operator
+
+        def enterRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "enterOperator" ):
+                listener.enterOperator(self)
+
+        def exitRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "exitOperator" ):
+                listener.exitOperator(self)
+
+
+
+
+    def operator(self):
+
+        localctx = SearchParser.OperatorContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 12, self.RULE_operator)
+        self._la = 0 # Token type
+        try:
+            self.state = 112
+            self._errHandler.sync(self)
+            token = self._input.LA(1)
+            if token in [SearchParser.T__24]:
+                self.enterOuterAlt(localctx, 1)
+                self.state = 95
+                self.match(SearchParser.T__24)
+                self.state = 99
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 96
+                    self.digit()
+                    self.state = 101
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 8:
-                self.enterOuterAlt(localctx, 8)
                 self.state = 102
-                self.match(SearchParser.T__41)
+                self.match(SearchParser.T__21)
                 pass
-
-            elif la_ == 9:
-                self.enterOuterAlt(localctx, 9)
+            elif token in [SearchParser.T__25]:
+                self.enterOuterAlt(localctx, 2)
                 self.state = 103
-                self.match(SearchParser.T__42)
-                pass
+                self.match(SearchParser.T__25)
+                self.state = 107
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 104
+                    self.digit()
+                    self.state = 109
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 10:
-                self.enterOuterAlt(localctx, 10)
-                self.state = 104
-                self.match(SearchParser.T__39)
+                self.state = 110
+                self.match(SearchParser.T__21)
                 pass
-
-            elif la_ == 11:
-                self.enterOuterAlt(localctx, 11)
-                self.state = 105
-                self.match(SearchParser.T__43)
+            elif token in [SearchParser.T__26]:
+                self.enterOuterAlt(localctx, 3)
+                self.state = 111
+                self.match(SearchParser.T__26)
                 pass
+            else:
+                raise NoViableAltException(self)
 
-            elif la_ == 12:
-                self.enterOuterAlt(localctx, 12)
-                self.state = 106
-                self.match(SearchParser.T__44)
-                pass
+        except RecognitionException as re:
+            localctx.exception = re
+            self._errHandler.reportError(self, re)
+            self._errHandler.recover(self, re)
+        finally:
+            self.exitRule()
+        return localctx
+
+    class LiteralContext(ParserRuleContext):
+
+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
+            super().__init__(parent, invokingState)
+            self.parser = parser
+
+        def digit(self, i:int=None):
+            if i is None:
+                return self.getTypedRuleContexts(SearchParser.DigitContext)
+            else:
+                return self.getTypedRuleContext(SearchParser.DigitContext,i)
+
+
+        def getRuleIndex(self):
+            return SearchParser.RULE_literal
+
+        def enterRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "enterLiteral" ):
+                listener.enterLiteral(self)
+
+        def exitRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "exitLiteral" ):
+                listener.exitLiteral(self)
 
-            elif la_ == 13:
-                self.enterOuterAlt(localctx, 13)
-                self.state = 107
-                self.match(SearchParser.T__45)
-                pass
 
-            elif la_ == 14:
-                self.enterOuterAlt(localctx, 14)
-                self.state = 108
-                self.match(SearchParser.T__46)
-                self.state = 112
+
+
+    def literal(self):
+
+        localctx = SearchParser.LiteralContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 14, self.RULE_literal)
+        self._la = 0 # Token type
+        try:
+            self.state = 131
+            self._errHandler.sync(self)
+            token = self._input.LA(1)
+            if token in [SearchParser.T__27]:
+                self.enterOuterAlt(localctx, 1)
+                self.state = 114
+                self.match(SearchParser.T__27)
+                self.state = 118
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0):
-                    self.state = 109
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 115
                     self.digit()
-                    self.state = 114
+                    self.state = 120
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 115
-                self.match(SearchParser.T__3)
+                self.state = 121
+                self.match(SearchParser.T__21)
+                pass
+            elif token in [SearchParser.T__28]:
+                self.enterOuterAlt(localctx, 2)
+                self.state = 122
+                self.match(SearchParser.T__28)
+                self.state = 126
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 123
+                    self.digit()
+                    self.state = 128
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
+
+                self.state = 129
+                self.match(SearchParser.T__21)
+                pass
+            elif token in [SearchParser.T__29]:
+                self.enterOuterAlt(localctx, 3)
+                self.state = 130
+                self.match(SearchParser.T__29)
                 pass
+            else:
+                raise NoViableAltException(self)
+
+        except RecognitionException as re:
+            localctx.exception = re
+            self._errHandler.reportError(self, re)
+            self._errHandler.recover(self, re)
+        finally:
+            self.exitRule()
+        return localctx
+
+    class DigitContext(ParserRuleContext):
 
+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
+            super().__init__(parent, invokingState)
+            self.parser = parser
 
+
+        def getRuleIndex(self):
+            return SearchParser.RULE_digit
+
+        def enterRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "enterDigit" ):
+                listener.enterDigit(self)
+
+        def exitRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "exitDigit" ):
+                listener.exitDigit(self)
+
+
+
+
+    def digit(self):
+
+        localctx = SearchParser.DigitContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 16, self.RULE_digit)
+        self._la = 0 # Token type
+        try:
+            self.enterOuterAlt(localctx, 1)
+            self.state = 133
+            _la = self._input.LA(1)
+            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0)):
+                self._errHandler.recoverInline(self)
+            else:
+                self._errHandler.reportMatch(self)
+                self.consume()
         except RecognitionException as re:
             localctx.exception = re
             self._errHandler.reportError(self, re)
diff --git a/code/example.txt b/code/example.txt
index 56c4c47..a8ab280 100644
--- a/code/example.txt
+++ b/code/example.txt
@@ -1,21 +1,23 @@
-9for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<0>;#ID<.>#OP<.>){->for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<1>;#ID<.>#OP<.>){
-#ID<.>.#ID<.>(#N<0>,#N<1>);->#ID<.>.#ID<.>(#N<2>,#N<3>);
-#ID<.>.#ID<.>(#N<.>);->_
+for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<0>;#ID<.>#OP<.>){->for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<1>;#ID<.>#OP<.>){
+#ID<.>.#ID<.>(#LT<0>,#LT<1>);->#ID<.>.#ID<.>(#LT<!0>,#LT<!1>);
+#ID<.>.#ID<.>(#LT<.>);->_
 _->#ID<.>.#ID<.>();
-for(#ID<.>=#N<.>;#ID<.>#OP<0>#N<0>;#ID<.>#OP<.>){->for(#ID<.>=#N<.>;#ID<.>#OP<1>#N<1>;#ID<.>#OP<.>){
-for(#ID<.>=#N<.>;#ID<.>#OP<0>#N<0>;#ID<0>#OP<1>){->for(#ID<.>=#N<.>;#ID<.>#OP<2>#N<1>;#ID<1>#OP<3>){
-if(#ID<.>#OP<0>#N<.>){->if(#ID<.>#OP<1>#N<.>){
-if(#ID<.>#OP<.>#N<0>){->if(#ID<.>#OP<.>#N<1>){
-if(#ID<.>#OP<0>#N<.>){->if(#ID<.>#OP<1>#N<.>){
-#ID<.>.#ID<.>(#N<0>,#N<1>);->#ID<.>.#ID<.>(#N<2>,#N<3>);
-#ID<.>.#ID<.>(#N<.>);->_
-if(#ID<.>#OP<.>#N<0>){->if(#ID<.>#OP<.>#N<1>){
+for(#ID<.>=#LT<.>;#ID<.>#OP<0>#LT<0>;#ID<.>#OP<.>){->for(#ID<.>=#LT<.>;#ID<.>#OP<1>#LT<1>;#ID<.>#OP<.>){
+for(#ID<.>=#LT<.>;#ID<.>#OP<0>#LT<0>;#ID<0>#OP<1>){->for(#ID<.>=#LT<.>;#ID<.>#OP<2>#LT<1>;#ID<1>#OP<3>){
+if(#ID<.>#OP<0>#LT<.>){->if(#ID<.>#OP<1>#LT<.>){
+if(#ID<.>#OP<.>#LT<0>){->if(#ID<.>#OP<.>#LT<1>){
+if(#ID<.>#OP<0>#LT<.>){->if(#ID<.>#OP<1>#LT<.>){
+#ID<.>.#ID<.>(#LT<0>,#LT<1>);->#ID<.>.#ID<.>(#LT<2>,#LT<3>);
 
-if(#ID<.>#OP<0>#N<.>) -> if(#ID<.>#OP<1>#N<.>)
-if(#ID<.>#OP<.>#N<0>) -> if(#ID<.>#OP<.>#N<1>)
+if(#ID<.>#OP<.>#LT<0>){->if(#ID<.>#OP<.>#LT<1>){
 
-#ID<.>.#ID<.>(#N<100>,#N<21321>)->#ID<.>.#ID<.>(#N<23222>,,#N<2312313>
+if(#ID<.>#OP<0>#LT<.>) -> if(#ID<.>#OP<!0>#LT<.>)
+if(#ID<.>#OP<1>#LT<.>) -> if(#ID<.>#OP<1>#LT<.>)
+if(#ID<.>#OP<1>#LT<.>){ -> if(#ID<.>#OP<1>#LT<.>){
 
-if(#ID<.>#OP<0>#N<.>){ -> if(#ID<.>#OP<3>#N<.>){
-if(#ID<.>#OP<1>#N<.>) -> if(#ID<.>#OP<2>#N<.>)
-for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<1>;#ID<.>#OP<.>)->for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<2>;#ID<.>#OP<.>)
\ No newline at end of file
+#ID<.>.#ID<.>(#LT<100>,#LT<21321>)->#ID<.>.#ID<.>(#LT<23222>,,#LT<2312313>
+
+if(#ID<.>#OP<0>#LT<.>){ -> if(#ID<.>#OP<3>#LT<.>){
+if(#ID<.>#OP<1>#LT<.>) -> if(#ID<.>#OP<2>#LT<.>)
+for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<1>;#ID<.>#OP<.>)->for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<2>;#ID<.>#OP<.>)
+_ ->#ID<.>.#ID<.>(#LT<.>,#LT<.>);
diff --git a/code/git_changes.txt b/code/git_changes.txt
index b106a2d..3276ed5 100644
--- a/code/git_changes.txt
+++ b/code/git_changes.txt
@@ -7,12 +7,15 @@ index d58db74..f1c27f0 100644
  
     public static void main(String[] args) {
 
--        for(j=0;j<2;j++){
-+        for(j=0;j<3;j++){
+-              if(y>0){
++              if(y>5){
+
+-              if(y==0){
++              if(y!=0){
 
          Scanner s= new Scanner(System.in);
 
-         System.out.println("Geometry Area:\n1)Circle\n2)Rectangle\n3)Triangle\n");
+         System.out.println("Geometry Area:\n");
 
          switch(i) {
             case 1:
@@ -30,45 +33,27 @@ index d58db74..f1c27f0 100644
         }
 
 
-diff --git a/Area.java b/Area.java
+diff --git a/main.cpp b/main.cpp
 index d58db74..f1c27f0 100644
---- a/Area.java
-+++ b/Area.java
-@@ -3,24 +3,23 @@ import java.util.Scanner;
- public class Area {
+--- a/main.cpp
++++ b/maoin.cpp
+@@ -16,10 +16,10 @@ int main()
  
-    public static void main(String[] args) {
+    //add a call method
 
--        for(j=0;j>0;j++){
-+        for(j=0;j<1;j++){
+-    if(n>2)
++    if(n<2)
+      myfile << n;
 
--        for(j=0;j>0;i--){
-+        for(j=0;j<1;j++){
+-    while(i<1){
++    while(i>1){
+        cout << "The result is: " << sub(x2,x1) << endl; //swap arguments DONE
+        i++;
+    }
+@@ -32,7 +32,7 @@ int main()
 
-         Scanner s= new Scanner(System.in);
-
-         System.out.println("Geometry Area:\n1)Circle\n2)Rectangle\n3)Triangle\n");
 
--              if(x>0){
-+              if(x<0){
 
--              if(y>0){
-+              if(y>5){
-
--              if(y==0){
-+              if(y!=0){
-
-         switch(i) {
-            case 1:
--              Area.circle(6,7);
-+              Area.circle(5,5);
-              break;
-            case 2:
--              Area.rectangle(3);
-               Area.rectangle(2,1);
-              break;
-            default:
--              if(y>9){
-+              if(y>1){
-          }
-        }
+-    return 0;
++    return -1;
+}
diff --git a/code/git_functions.py b/code/git_functions.py
index 059745e..36e35a4 100644
--- a/code/git_functions.py
+++ b/code/git_functions.py
@@ -25,9 +25,9 @@ def git_clone():
 def git_log(repository):
     commit_log = []
 
-    command = "cd " + repository + "&& git log > git_log.txt"
+    command = "git log > ./test-changes/git_log.txt"
     os.system(command)
-    filename = repository + "/git_log.txt"
+    filename ="test-changes/git_log.txt"
 
     with open(filename) as fp:
         for line in fp:
@@ -45,9 +45,9 @@ def git_log(repository):
 #Compute the git diff
 def git_diff(commit_log, repository):
 
-    command = "echo '' > git_changes.txt"
+    command = "echo '' > ./test_changes/git_changes.txt"
     os.system(command)
 
     for i in commit_log:
-        command = "cd " + repository + "&& git diff " + i + " HEAD >> git_changes.txt"
+        command = "cd ./test-changes && git diff " + i + " HEAD >> git_changes.txt"
         os.system(command)
\ No newline at end of file
diff --git a/code/main.py b/code/main.py
index 639436a..c95c46d 100644
--- a/code/main.py
+++ b/code/main.py
@@ -29,13 +29,26 @@ def main():
     #Computation of similarity in different ways(cosine distance and jaccard index)
     position = 0
     ngrams = 3
+
     #[0] cosine distance threshold [1] jaccard distance threshold
-    thresholds = [0.1, 0.1]
+    thresholds = [0.83, 0.8]
+    ranked_list = []
+
+    query_tokens, query_ngrams = my_functions.query_normalization(query,ngrams)
 
+    my_functions.dataset_csv(changes_list_real, changes_list_abstract)
+    
     for change in changes_list_abstract:
-        my_functions.similarity(query.replace(' ', '').replace('\n', ''), change, position, ngrams, thresholds, changes_list_real)
+        my_functions.similarity(query_tokens, query_ngrams, change, position, ngrams, thresholds, changes_list_real, ranked_list)
         position += 1
 
+    # sort list with key
+    ranked_list.sort(reverse=True, key=my_functions.takeSecond)
+
+    print("\nThe changes found are:\n ")
+    for i in ranked_list:
+        print(i[0] + ' cosine: ' + i[1] + ' jaccard: ' +  i[2])
+
     #Programs ends
     end = time.time()
     print("\nThe program ends in:", round(end - start_time,1), "seconds. Total changes in the repository: ", position) 
diff --git a/code/my_functions.py b/code/my_functions.py
index 513c03d..1d55af1 100644
--- a/code/my_functions.py
+++ b/code/my_functions.py
@@ -7,6 +7,8 @@ from math import*
 from decimal import Decimal
 import copy
 from collections import Counter
+import csv
+from itertools import zip_longest
 import antlr4 
 
 import sys
@@ -22,6 +24,10 @@ def diff(first, second):
     else:
         return [i for i in range(len(first)) if first[i] != second[i]]
 
+#Take second element for list sorting key
+def takeSecond(elem):
+    return elem[1]
+    
 #Compute ngram of a string
 def ngram(change, ngrams):
     ngrams_list = {}
@@ -64,7 +70,7 @@ def antlr4_AbstractGrammar_Tokenizer(query):
 
     return list_abstract_token
 
-#Exacrt the changes from the git diff file
+#Extract the changes from the git diff file
 def analyze_diff_file(filename):
     temporary_array = []
     changes_list = []
@@ -149,10 +155,10 @@ def scanner(changes_list):
                     else:
                         if token.isdigit():
                             if(count in diff1 and bool == False):
-                                old[count] = '#N<' + str(n_num) + '>'
+                                old[count] = '#LT<' + str(n_num) + '>'
                                 n_num = n_num + 1 
                             else:    
-                                old[count] = '#N<.>'
+                                old[count] = '#LT<.>'
                         else: 
                             if(count in diff1 and bool == False):
                                 old[count] = '#ID<' + str(n_id) + '>'
@@ -178,20 +184,20 @@ def scanner(changes_list):
                         
                     if token == '+' or token =='-' or token =='*' or token == '--' or token == '++' or token =='/' or token =='<' or token =='>' or token =='<=' or token =='>=' or token =='==' or token =='!=' or token =='&&' or token =='||':
                         if(count in diff1 and bool == False):
-                            new[count] = '#OP<!' + str(n_op) + '>'
+                            new[count] = '#OP<' + str(n_op) + '>'
                             n_op = n_op + 1
                         else:
                             new[count] = '#OP<.>'
                     else:
                         if token.isdigit():
                             if(count in diff1 and bool == False):
-                                new[count] = '#N<!' + str(n_num) + '>'
+                                new[count] = '#LT<' + str(n_num) + '>'
                                 n_num = n_num + 1 
                             else:    
-                                new[count] = '#N<.>'
+                                new[count] = '#LT<.>'
                         else: 
                             if(count in diff1 and bool == False):
-                                new[count] = '#ID<!' + str(n_id) + '>'
+                                new[count] = '#ID<' + str(n_id) + '>'
                                 n_id = n_id + 1 
                             else:  
                                 new[count] = '#ID<.>'
@@ -222,15 +228,13 @@ def scanner(changes_list):
 #Compute cosine similarity
 def cosine_similarity_ngrams(a, b):
 
-    vec1 = Counter(a)
-    vec2 = Counter(b)
+    v1 = Counter(a)
+    v2 = Counter(b)
     
-    intersection = set(vec1.keys()) & set(vec2.keys())
-    numerator = sum([vec1[x] * vec2[x] for x in intersection])
+    intersection = set(v1.keys()) & set(v2.keys())
 
-    sum1 = sum([vec1[x]**2 for x in vec1.keys()])
-    sum2 = sum([vec2[x]**2 for x in vec2.keys()])
-    denominator = math.sqrt(sum1) * math.sqrt(sum2)
+    numerator = sum([v1[x] * v2[x] for x in intersection])
+    denominator = math.sqrt(sum([v1[x]**2 for x in v1.keys()])) * math.sqrt(sum([v2[x]**2 for x in v2.keys()]))
 
     if not denominator:
         return 0.0
@@ -243,22 +247,76 @@ def getNgrams(string, n):
 #Compute Jaccard index similarity
 def jaccard_similarity(x,y):
  
- intersection_cardinality = len(set.intersection(*[set(x), set(y)]))
- union_cardinality = len(set.union(*[set(x), set(y)]))
+    intersection = len(set.intersection(*[set(x), set(y)]))
+    union = len(set.union(*[set(x), set(y)]))
  
- return intersection_cardinality/float(union_cardinality)
+    return intersection/float(union)
 
 #Compute the similarity between query and one change using different similarity algorithm. Print the change if over thresholds 
-def similarity(query, change, position, ngram, thresholds, changes_list_real):
+def similarity(query_tokens, query_ngrams, change, position, ngram, thresholds, changes_list_real, ranked_list):
+
+    temporary_list = []
 
-    ngrams_list1 = getNgrams(query, ngram)
+    #ngrams_list1 = getNgrams(query, ngram)
     ngrams_list2 = getNgrams(change, ngram)
 
-    abstract_tokens1 = antlr4_AbstractGrammar_Tokenizer(query)
+    #abstract_tokens1 = antlr4_AbstractGrammar_Tokenizer(query)
     abstract_tokens2 = antlr4_AbstractGrammar_Tokenizer(change)
 
-    cosine_score = cosine_similarity_ngrams(ngrams_list1,ngrams_list2)
-    jaccard_score = jaccard_similarity(abstract_tokens1, abstract_tokens2)
+    cosine_score = cosine_similarity_ngrams(query_ngrams,ngrams_list2)
+    jaccard_score = jaccard_similarity(query_tokens, abstract_tokens2)
    
     if cosine_score > thresholds[0] and jaccard_score > thresholds[1] :
-        print(changes_list_real[position] + ' cosine: ' + str(round(cosine_score,2)) + ' jaccard: ' + str(round(jaccard_score,2)))#+ ' eucledian: ' + str(round(eucledian_score,2)))
+        
+        temporary_list.append(changes_list_real[position])
+        temporary_list.append(str(round(cosine_score,2)))
+        temporary_list.append(str(round(jaccard_score,2)))
+
+        ranked_list.append(temporary_list)
+
+#Query digits normalization and n-grams and tokens computation
+def query_normalization(query, ngrams):
+    query_normalize = []
+
+    id = 0
+    op = 0
+    lt = 0
+    n = 0
+    l = len(str(query))
+
+    for n in range(0, l):
+        if(query[n] == '-'):
+                id = 0
+                op = 0
+                lt = 0
+
+                query_normalize.append(query[n])
+        else:
+            if query[n].isdigit():
+                if(n > 1):
+                    if(query[n-2] == 'D'):
+                        query_normalize.append(str(id))
+                        id += 1
+                    else:
+                        if(query[n-2] == 'P'):
+                            query_normalize.append(str(op))
+                            op += 1
+                        else:
+                           # if(query[n-2] == 'T'):
+                                query_normalize.append(str(lt))
+                                lt += 1
+                else: 
+                    query_normalize.append(query[n])
+            else: 
+                    query_normalize.append(query[n])
+
+        
+        n += 1
+
+    query_n = ''.join(query_normalize).replace(' ', '').replace('\n', '')
+
+    query_tokens = antlr4_AbstractGrammar_Tokenizer(query_n)
+    query_ngrams = getNgrams(query_n, ngrams)
+    
+
+    return query_tokens, query_ngrams
diff --git a/code/tests.py b/code/tests.py
index 6e72061..9b25953 100644
--- a/code/tests.py
+++ b/code/tests.py
@@ -1,41 +1,32 @@
+ #  stream = antlr4.CommonTokenStream(lexer)
+   # parser = SearchParser(stream)
+   # tree = parser.query()
+    #printer = SearchPrintListener()
+   # walker = antlr4.ParseTreeWalker()
+    #walker.walk(printer, tree)
+  #  print(tree.toStringTree())
+    
 import antlr4 
 
 import sys
-# insert at 1, 0 is the script path (or '' in REPL)
-sys.path.insert(1, './antlr4')
-
+sys.path.insert(1, './code/antlr4')
 from SearchLexer import SearchLexer
 from SearchListener import SearchListener
 from SearchParser import SearchParser
 
-#echo "3 * 3 - 2 + 2 * 2" | python main.py
-
 class SearchPrintListener(SearchListener):
-    def enterSearch(self, ctx):
-        print("Search: %s" % ctx.ID())
+    def enterHi(self, ctx):
+        print("Hello: %s" % ctx.ID())
 
-def antlr4_AbstractGrammar_Tokenizer(query):
+def main(query):
     lexer = SearchLexer(antlr4.InputStream(query))
-    list_abstract_token = []
-    while(1):
-        token = lexer.nextToken()
-        if(token.text == '<EOF>'):
-            break
-        list_abstract_token.append(token.text)
-
-    
-    for i in list_abstract_token:
-       print(i)
-
-    return list_abstract_token
-  #  stream = antlr4.CommonTokenStream(lexer)
-   # parser = SearchParser(stream)
-   # tree = parser.query()
-    #printer = SearchPrintListener()
-   # walker = antlr4.ParseTreeWalker()
-    #walker.walk(printer, tree)
-  #  print(tree.toStringTree())
-    
+    stream = antlr4.CommonTokenStream(lexer)
+    parser = SearchParser(stream)
+    tree = parser.query()
+    printer = SearchPrintListener()
+    walker = antlr4.ParseTreeWalker()
+    walker.walk(printer, tree)
+    #print(tree.toStringTree())
 
 if __name__ == '__main__':
-    antlr4_AbstractGrammar_Tokenizer('if(#ID<.>#OP<0>#N<.>) -> if(#ID<.>#OP<3>#N<.>)')
+    main('if(#ID<.>#OP<1>#LT<.>){ -> if(#ID<.>#OP<1>#LT<.>){<')
diff --git a/code/antlr4/.antlr/Search.interp b/code/antlr4/.antlr/Search.interp
new file mode 100644
index 0000000..b739ec4
--- /dev/null
+++ b/code/antlr4/.antlr/Search.interp
@@ -0,0 +1,102 @@
+token literal names:
+null
+'->'
+'_'
+'if'
+'else'
+'for'
+'forEach'
+'while'
+'return'
+'NULL'
+'('
+')'
+'['
+']'
+'{'
+'}'
+'"'
+'='
+'.'
+','
+';'
+'#ID<'
+'>'
+'#ID<!'
+'#ID<.>'
+'#OP<'
+'#OP<!'
+'#OP<.>'
+'#LT<'
+'#LT<!'
+'#LT<.>'
+'0'
+'1'
+'2'
+'3'
+'4'
+'5'
+'6'
+'7'
+'8'
+'9'
+null
+
+token symbolic names:
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+WS
+
+rule names:
+query
+code
+token
+keyword
+punctuator
+identifier
+operator
+literal
+digit
+
+
+atn:
+[3, 24715, 42794, 33075, 47597, 16764, 15335, 30598, 22884, 3, 43, 138, 4, 2, 9, 2, 4, 3, 9, 3, 4, 4, 9, 4, 4, 5, 9, 5, 4, 6, 9, 6, 4, 7, 9, 7, 4, 8, 9, 8, 4, 9, 9, 9, 4, 10, 9, 10, 3, 2, 3, 2, 3, 2, 3, 2, 3, 3, 7, 3, 26, 10, 3, 12, 3, 14, 3, 29, 11, 3, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 5, 4, 37, 10, 4, 3, 5, 3, 5, 3, 6, 3, 6, 7, 6, 43, 10, 6, 12, 6, 14, 6, 46, 11, 6, 3, 6, 3, 6, 3, 6, 7, 6, 51, 10, 6, 12, 6, 14, 6, 54, 11, 6, 3, 6, 3, 6, 3, 6, 7, 6, 59, 10, 6, 12, 6, 14, 6, 62, 11, 6, 3, 6, 3, 6, 3, 6, 7, 6, 67, 10, 6, 12, 6, 14, 6, 70, 11, 6, 3, 6, 3, 6, 3, 6, 3, 6, 3, 6, 5, 6, 77, 10, 6, 3, 7, 3, 7, 7, 7, 81, 10, 7, 12, 7, 14, 7, 84, 11, 7, 3, 7, 3, 7, 3, 7, 7, 7, 89, 10, 7, 12, 7, 14, 7, 92, 11, 7, 3, 7, 3, 7, 5, 7, 96, 10, 7, 3, 8, 3, 8, 7, 8, 100, 10, 8, 12, 8, 14, 8, 103, 11, 8, 3, 8, 3, 8, 3, 8, 7, 8, 108, 10, 8, 12, 8, 14, 8, 111, 11, 8, 3, 8, 3, 8, 5, 8, 115, 10, 8, 3, 9, 3, 9, 7, 9, 119, 10, 9, 12, 9, 14, 9, 122, 11, 9, 3, 9, 3, 9, 3, 9, 7, 9, 127, 10, 9, 12, 9, 14, 9, 130, 11, 9, 3, 9, 3, 9, 5, 9, 134, 10, 9, 3, 10, 3, 10, 3, 10, 2, 2, 11, 2, 4, 6, 8, 10, 12, 14, 16, 18, 2, 4, 3, 2, 5, 11, 3, 2, 33, 42, 2, 157, 2, 20, 3, 2, 2, 2, 4, 27, 3, 2, 2, 2, 6, 36, 3, 2, 2, 2, 8, 38, 3, 2, 2, 2, 10, 76, 3, 2, 2, 2, 12, 95, 3, 2, 2, 2, 14, 114, 3, 2, 2, 2, 16, 133, 3, 2, 2, 2, 18, 135, 3, 2, 2, 2, 20, 21, 5, 4, 3, 2, 21, 22, 7, 3, 2, 2, 22, 23, 5, 4, 3, 2, 23, 3, 3, 2, 2, 2, 24, 26, 5, 6, 4, 2, 25, 24, 3, 2, 2, 2, 26, 29, 3, 2, 2, 2, 27, 25, 3, 2, 2, 2, 27, 28, 3, 2, 2, 2, 28, 5, 3, 2, 2, 2, 29, 27, 3, 2, 2, 2, 30, 37, 5, 12, 7, 2, 31, 37, 5, 8, 5, 2, 32, 37, 5, 10, 6, 2, 33, 37, 5, 14, 8, 2, 34, 37, 5, 16, 9, 2, 35, 37, 7, 4, 2, 2, 36, 30, 3, 2, 2, 2, 36, 31, 3, 2, 2, 2, 36, 32, 3, 2, 2, 2, 36, 33, 3, 2, 2, 2, 36, 34, 3, 2, 2, 2, 36, 35, 3, 2, 2, 2, 37, 7, 3, 2, 2, 2, 38, 39, 9, 2, 2, 2, 39, 9, 3, 2, 2, 2, 40, 44, 7, 12, 2, 2, 41, 43, 5, 6, 4, 2, 42, 41, 3, 2, 2, 2, 43, 46, 3, 2, 2, 2, 44, 42, 3, 2, 2, 2, 44, 45, 3, 2, 2, 2, 45, 47, 3, 2, 2, 2, 46, 44, 3, 2, 2, 2, 47, 77, 7, 13, 2, 2, 48, 52, 7, 14, 2, 2, 49, 51, 5, 6, 4, 2, 50, 49, 3, 2, 2, 2, 51, 54, 3, 2, 2, 2, 52, 50, 3, 2, 2, 2, 52, 53, 3, 2, 2, 2, 53, 55, 3, 2, 2, 2, 54, 52, 3, 2, 2, 2, 55, 77, 7, 15, 2, 2, 56, 60, 7, 16, 2, 2, 57, 59, 5, 6, 4, 2, 58, 57, 3, 2, 2, 2, 59, 62, 3, 2, 2, 2, 60, 58, 3, 2, 2, 2, 60, 61, 3, 2, 2, 2, 61, 63, 3, 2, 2, 2, 62, 60, 3, 2, 2, 2, 63, 77, 7, 17, 2, 2, 64, 68, 7, 18, 2, 2, 65, 67, 5, 6, 4, 2, 66, 65, 3, 2, 2, 2, 67, 70, 3, 2, 2, 2, 68, 66, 3, 2, 2, 2, 68, 69, 3, 2, 2, 2, 69, 71, 3, 2, 2, 2, 70, 68, 3, 2, 2, 2, 71, 77, 7, 18, 2, 2, 72, 77, 7, 19, 2, 2, 73, 77, 7, 20, 2, 2, 74, 77, 7, 21, 2, 2, 75, 77, 7, 22, 2, 2, 76, 40, 3, 2, 2, 2, 76, 48, 3, 2, 2, 2, 76, 56, 3, 2, 2, 2, 76, 64, 3, 2, 2, 2, 76, 72, 3, 2, 2, 2, 76, 73, 3, 2, 2, 2, 76, 74, 3, 2, 2, 2, 76, 75, 3, 2, 2, 2, 77, 11, 3, 2, 2, 2, 78, 82, 7, 23, 2, 2, 79, 81, 5, 18, 10, 2, 80, 79, 3, 2, 2, 2, 81, 84, 3, 2, 2, 2, 82, 80, 3, 2, 2, 2, 82, 83, 3, 2, 2, 2, 83, 85, 3, 2, 2, 2, 84, 82, 3, 2, 2, 2, 85, 96, 7, 24, 2, 2, 86, 90, 7, 25, 2, 2, 87, 89, 5, 18, 10, 2, 88, 87, 3, 2, 2, 2, 89, 92, 3, 2, 2, 2, 90, 88, 3, 2, 2, 2, 90, 91, 3, 2, 2, 2, 91, 93, 3, 2, 2, 2, 92, 90, 3, 2, 2, 2, 93, 96, 7, 24, 2, 2, 94, 96, 7, 26, 2, 2, 95, 78, 3, 2, 2, 2, 95, 86, 3, 2, 2, 2, 95, 94, 3, 2, 2, 2, 96, 13, 3, 2, 2, 2, 97, 101, 7, 27, 2, 2, 98, 100, 5, 18, 10, 2, 99, 98, 3, 2, 2, 2, 100, 103, 3, 2, 2, 2, 101, 99, 3, 2, 2, 2, 101, 102, 3, 2, 2, 2, 102, 104, 3, 2, 2, 2, 103, 101, 3, 2, 2, 2, 104, 115, 7, 24, 2, 2, 105, 109, 7, 28, 2, 2, 106, 108, 5, 18, 10, 2, 107, 106, 3, 2, 2, 2, 108, 111, 3, 2, 2, 2, 109, 107, 3, 2, 2, 2, 109, 110, 3, 2, 2, 2, 110, 112, 3, 2, 2, 2, 111, 109, 3, 2, 2, 2, 112, 115, 7, 24, 2, 2, 113, 115, 7, 29, 2, 2, 114, 97, 3, 2, 2, 2, 114, 105, 3, 2, 2, 2, 114, 113, 3, 2, 2, 2, 115, 15, 3, 2, 2, 2, 116, 120, 7, 30, 2, 2, 117, 119, 5, 18, 10, 2, 118, 117, 3, 2, 2, 2, 119, 122, 3, 2, 2, 2, 120, 118, 3, 2, 2, 2, 120, 121, 3, 2, 2, 2, 121, 123, 3, 2, 2, 2, 122, 120, 3, 2, 2, 2, 123, 134, 7, 24, 2, 2, 124, 128, 7, 31, 2, 2, 125, 127, 5, 18, 10, 2, 126, 125, 3, 2, 2, 2, 127, 130, 3, 2, 2, 2, 128, 126, 3, 2, 2, 2, 128, 129, 3, 2, 2, 2, 129, 131, 3, 2, 2, 2, 130, 128, 3, 2, 2, 2, 131, 134, 7, 24, 2, 2, 132, 134, 7, 32, 2, 2, 133, 116, 3, 2, 2, 2, 133, 124, 3, 2, 2, 2, 133, 132, 3, 2, 2, 2, 134, 17, 3, 2, 2, 2, 135, 136, 9, 3, 2, 2, 136, 19, 3, 2, 2, 2, 18, 27, 36, 44, 52, 60, 68, 76, 82, 90, 95, 101, 109, 114, 120, 128, 133]
\ No newline at end of file
diff --git a/code/antlr4/.antlr/Search.tokens b/code/antlr4/.antlr/Search.tokens
new file mode 100644
index 0000000..372bf0c
--- /dev/null
+++ b/code/antlr4/.antlr/Search.tokens
@@ -0,0 +1,81 @@
+T__0=1
+T__1=2
+T__2=3
+T__3=4
+T__4=5
+T__5=6
+T__6=7
+T__7=8
+T__8=9
+T__9=10
+T__10=11
+T__11=12
+T__12=13
+T__13=14
+T__14=15
+T__15=16
+T__16=17
+T__17=18
+T__18=19
+T__19=20
+T__20=21
+T__21=22
+T__22=23
+T__23=24
+T__24=25
+T__25=26
+T__26=27
+T__27=28
+T__28=29
+T__29=30
+T__30=31
+T__31=32
+T__32=33
+T__33=34
+T__34=35
+T__35=36
+T__36=37
+T__37=38
+T__38=39
+T__39=40
+WS=41
+'->'=1
+'_'=2
+'if'=3
+'else'=4
+'for'=5
+'forEach'=6
+'while'=7
+'return'=8
+'NULL'=9
+'('=10
+')'=11
+'['=12
+']'=13
+'{'=14
+'}'=15
+'"'=16
+'='=17
+'.'=18
+','=19
+';'=20
+'#ID<'=21
+'>'=22
+'#ID<!'=23
+'#ID<.>'=24
+'#OP<'=25
+'#OP<!'=26
+'#OP<.>'=27
+'#LT<'=28
+'#LT<!'=29
+'#LT<.>'=30
+'0'=31
+'1'=32
+'2'=33
+'3'=34
+'4'=35
+'5'=36
+'6'=37
+'7'=38
+'8'=39
+'9'=40
diff --git a/code/antlr4/.antlr/SearchLexer.interp b/code/antlr4/.antlr/SearchLexer.interp
new file mode 100644
index 0000000..062f29e
--- /dev/null
+++ b/code/antlr4/.antlr/SearchLexer.interp
@@ -0,0 +1,140 @@
+token literal names:
+null
+'->'
+'_'
+'if'
+'else'
+'for'
+'forEach'
+'while'
+'return'
+'NULL'
+'('
+')'
+'['
+']'
+'{'
+'}'
+'"'
+'='
+'.'
+','
+';'
+'#ID<'
+'>'
+'#ID<!'
+'#ID<.>'
+'#OP<'
+'#OP<!'
+'#OP<.>'
+'#LT<'
+'#LT<!'
+'#LT<.>'
+'0'
+'1'
+'2'
+'3'
+'4'
+'5'
+'6'
+'7'
+'8'
+'9'
+null
+
+token symbolic names:
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+WS
+
+rule names:
+T__0
+T__1
+T__2
+T__3
+T__4
+T__5
+T__6
+T__7
+T__8
+T__9
+T__10
+T__11
+T__12
+T__13
+T__14
+T__15
+T__16
+T__17
+T__18
+T__19
+T__20
+T__21
+T__22
+T__23
+T__24
+T__25
+T__26
+T__27
+T__28
+T__29
+T__30
+T__31
+T__32
+T__33
+T__34
+T__35
+T__36
+T__37
+T__38
+T__39
+WS
+
+channel names:
+DEFAULT_TOKEN_CHANNEL
+HIDDEN
+
+mode names:
+DEFAULT_MODE
+
+atn:
+[3, 24715, 42794, 33075, 47597, 16764, 15335, 30598, 22884, 2, 43, 233, 8, 1, 4, 2, 9, 2, 4, 3, 9, 3, 4, 4, 9, 4, 4, 5, 9, 5, 4, 6, 9, 6, 4, 7, 9, 7, 4, 8, 9, 8, 4, 9, 9, 9, 4, 10, 9, 10, 4, 11, 9, 11, 4, 12, 9, 12, 4, 13, 9, 13, 4, 14, 9, 14, 4, 15, 9, 15, 4, 16, 9, 16, 4, 17, 9, 17, 4, 18, 9, 18, 4, 19, 9, 19, 4, 20, 9, 20, 4, 21, 9, 21, 4, 22, 9, 22, 4, 23, 9, 23, 4, 24, 9, 24, 4, 25, 9, 25, 4, 26, 9, 26, 4, 27, 9, 27, 4, 28, 9, 28, 4, 29, 9, 29, 4, 30, 9, 30, 4, 31, 9, 31, 4, 32, 9, 32, 4, 33, 9, 33, 4, 34, 9, 34, 4, 35, 9, 35, 4, 36, 9, 36, 4, 37, 9, 37, 4, 38, 9, 38, 4, 39, 9, 39, 4, 40, 9, 40, 4, 41, 9, 41, 4, 42, 9, 42, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 6, 3, 6, 3, 6, 3, 6, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 8, 3, 8, 3, 8, 3, 8, 3, 8, 3, 8, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3, 10, 3, 10, 3, 10, 3, 10, 3, 10, 3, 11, 3, 11, 3, 12, 3, 12, 3, 13, 3, 13, 3, 14, 3, 14, 3, 15, 3, 15, 3, 16, 3, 16, 3, 17, 3, 17, 3, 18, 3, 18, 3, 19, 3, 19, 3, 20, 3, 20, 3, 21, 3, 21, 3, 22, 3, 22, 3, 22, 3, 22, 3, 22, 3, 23, 3, 23, 3, 24, 3, 24, 3, 24, 3, 24, 3, 24, 3, 24, 3, 25, 3, 25, 3, 25, 3, 25, 3, 25, 3, 25, 3, 25, 3, 26, 3, 26, 3, 26, 3, 26, 3, 26, 3, 27, 3, 27, 3, 27, 3, 27, 3, 27, 3, 27, 3, 28, 3, 28, 3, 28, 3, 28, 3, 28, 3, 28, 3, 28, 3, 29, 3, 29, 3, 29, 3, 29, 3, 29, 3, 30, 3, 30, 3, 30, 3, 30, 3, 30, 3, 30, 3, 31, 3, 31, 3, 31, 3, 31, 3, 31, 3, 31, 3, 31, 3, 32, 3, 32, 3, 33, 3, 33, 3, 34, 3, 34, 3, 35, 3, 35, 3, 36, 3, 36, 3, 37, 3, 37, 3, 38, 3, 38, 3, 39, 3, 39, 3, 40, 3, 40, 3, 41, 3, 41, 3, 42, 6, 42, 228, 10, 42, 13, 42, 14, 42, 229, 3, 42, 3, 42, 2, 2, 43, 3, 3, 5, 4, 7, 5, 9, 6, 11, 7, 13, 8, 15, 9, 17, 10, 19, 11, 21, 12, 23, 13, 25, 14, 27, 15, 29, 16, 31, 17, 33, 18, 35, 19, 37, 20, 39, 21, 41, 22, 43, 23, 45, 24, 47, 25, 49, 26, 51, 27, 53, 28, 55, 29, 57, 30, 59, 31, 61, 32, 63, 33, 65, 34, 67, 35, 69, 36, 71, 37, 73, 38, 75, 39, 77, 40, 79, 41, 81, 42, 83, 43, 3, 2, 3, 5, 2, 11, 12, 15, 15, 34, 34, 2, 233, 2, 3, 3, 2, 2, 2, 2, 5, 3, 2, 2, 2, 2, 7, 3, 2, 2, 2, 2, 9, 3, 2, 2, 2, 2, 11, 3, 2, 2, 2, 2, 13, 3, 2, 2, 2, 2, 15, 3, 2, 2, 2, 2, 17, 3, 2, 2, 2, 2, 19, 3, 2, 2, 2, 2, 21, 3, 2, 2, 2, 2, 23, 3, 2, 2, 2, 2, 25, 3, 2, 2, 2, 2, 27, 3, 2, 2, 2, 2, 29, 3, 2, 2, 2, 2, 31, 3, 2, 2, 2, 2, 33, 3, 2, 2, 2, 2, 35, 3, 2, 2, 2, 2, 37, 3, 2, 2, 2, 2, 39, 3, 2, 2, 2, 2, 41, 3, 2, 2, 2, 2, 43, 3, 2, 2, 2, 2, 45, 3, 2, 2, 2, 2, 47, 3, 2, 2, 2, 2, 49, 3, 2, 2, 2, 2, 51, 3, 2, 2, 2, 2, 53, 3, 2, 2, 2, 2, 55, 3, 2, 2, 2, 2, 57, 3, 2, 2, 2, 2, 59, 3, 2, 2, 2, 2, 61, 3, 2, 2, 2, 2, 63, 3, 2, 2, 2, 2, 65, 3, 2, 2, 2, 2, 67, 3, 2, 2, 2, 2, 69, 3, 2, 2, 2, 2, 71, 3, 2, 2, 2, 2, 73, 3, 2, 2, 2, 2, 75, 3, 2, 2, 2, 2, 77, 3, 2, 2, 2, 2, 79, 3, 2, 2, 2, 2, 81, 3, 2, 2, 2, 2, 83, 3, 2, 2, 2, 3, 85, 3, 2, 2, 2, 5, 88, 3, 2, 2, 2, 7, 90, 3, 2, 2, 2, 9, 93, 3, 2, 2, 2, 11, 98, 3, 2, 2, 2, 13, 102, 3, 2, 2, 2, 15, 110, 3, 2, 2, 2, 17, 116, 3, 2, 2, 2, 19, 123, 3, 2, 2, 2, 21, 128, 3, 2, 2, 2, 23, 130, 3, 2, 2, 2, 25, 132, 3, 2, 2, 2, 27, 134, 3, 2, 2, 2, 29, 136, 3, 2, 2, 2, 31, 138, 3, 2, 2, 2, 33, 140, 3, 2, 2, 2, 35, 142, 3, 2, 2, 2, 37, 144, 3, 2, 2, 2, 39, 146, 3, 2, 2, 2, 41, 148, 3, 2, 2, 2, 43, 150, 3, 2, 2, 2, 45, 155, 3, 2, 2, 2, 47, 157, 3, 2, 2, 2, 49, 163, 3, 2, 2, 2, 51, 170, 3, 2, 2, 2, 53, 175, 3, 2, 2, 2, 55, 181, 3, 2, 2, 2, 57, 188, 3, 2, 2, 2, 59, 193, 3, 2, 2, 2, 61, 199, 3, 2, 2, 2, 63, 206, 3, 2, 2, 2, 65, 208, 3, 2, 2, 2, 67, 210, 3, 2, 2, 2, 69, 212, 3, 2, 2, 2, 71, 214, 3, 2, 2, 2, 73, 216, 3, 2, 2, 2, 75, 218, 3, 2, 2, 2, 77, 220, 3, 2, 2, 2, 79, 222, 3, 2, 2, 2, 81, 224, 3, 2, 2, 2, 83, 227, 3, 2, 2, 2, 85, 86, 7, 47, 2, 2, 86, 87, 7, 64, 2, 2, 87, 4, 3, 2, 2, 2, 88, 89, 7, 97, 2, 2, 89, 6, 3, 2, 2, 2, 90, 91, 7, 107, 2, 2, 91, 92, 7, 104, 2, 2, 92, 8, 3, 2, 2, 2, 93, 94, 7, 103, 2, 2, 94, 95, 7, 110, 2, 2, 95, 96, 7, 117, 2, 2, 96, 97, 7, 103, 2, 2, 97, 10, 3, 2, 2, 2, 98, 99, 7, 104, 2, 2, 99, 100, 7, 113, 2, 2, 100, 101, 7, 116, 2, 2, 101, 12, 3, 2, 2, 2, 102, 103, 7, 104, 2, 2, 103, 104, 7, 113, 2, 2, 104, 105, 7, 116, 2, 2, 105, 106, 7, 71, 2, 2, 106, 107, 7, 99, 2, 2, 107, 108, 7, 101, 2, 2, 108, 109, 7, 106, 2, 2, 109, 14, 3, 2, 2, 2, 110, 111, 7, 121, 2, 2, 111, 112, 7, 106, 2, 2, 112, 113, 7, 107, 2, 2, 113, 114, 7, 110, 2, 2, 114, 115, 7, 103, 2, 2, 115, 16, 3, 2, 2, 2, 116, 117, 7, 116, 2, 2, 117, 118, 7, 103, 2, 2, 118, 119, 7, 118, 2, 2, 119, 120, 7, 119, 2, 2, 120, 121, 7, 116, 2, 2, 121, 122, 7, 112, 2, 2, 122, 18, 3, 2, 2, 2, 123, 124, 7, 80, 2, 2, 124, 125, 7, 87, 2, 2, 125, 126, 7, 78, 2, 2, 126, 127, 7, 78, 2, 2, 127, 20, 3, 2, 2, 2, 128, 129, 7, 42, 2, 2, 129, 22, 3, 2, 2, 2, 130, 131, 7, 43, 2, 2, 131, 24, 3, 2, 2, 2, 132, 133, 7, 93, 2, 2, 133, 26, 3, 2, 2, 2, 134, 135, 7, 95, 2, 2, 135, 28, 3, 2, 2, 2, 136, 137, 7, 125, 2, 2, 137, 30, 3, 2, 2, 2, 138, 139, 7, 127, 2, 2, 139, 32, 3, 2, 2, 2, 140, 141, 7, 36, 2, 2, 141, 34, 3, 2, 2, 2, 142, 143, 7, 63, 2, 2, 143, 36, 3, 2, 2, 2, 144, 145, 7, 48, 2, 2, 145, 38, 3, 2, 2, 2, 146, 147, 7, 46, 2, 2, 147, 40, 3, 2, 2, 2, 148, 149, 7, 61, 2, 2, 149, 42, 3, 2, 2, 2, 150, 151, 7, 37, 2, 2, 151, 152, 7, 75, 2, 2, 152, 153, 7, 70, 2, 2, 153, 154, 7, 62, 2, 2, 154, 44, 3, 2, 2, 2, 155, 156, 7, 64, 2, 2, 156, 46, 3, 2, 2, 2, 157, 158, 7, 37, 2, 2, 158, 159, 7, 75, 2, 2, 159, 160, 7, 70, 2, 2, 160, 161, 7, 62, 2, 2, 161, 162, 7, 35, 2, 2, 162, 48, 3, 2, 2, 2, 163, 164, 7, 37, 2, 2, 164, 165, 7, 75, 2, 2, 165, 166, 7, 70, 2, 2, 166, 167, 7, 62, 2, 2, 167, 168, 7, 48, 2, 2, 168, 169, 7, 64, 2, 2, 169, 50, 3, 2, 2, 2, 170, 171, 7, 37, 2, 2, 171, 172, 7, 81, 2, 2, 172, 173, 7, 82, 2, 2, 173, 174, 7, 62, 2, 2, 174, 52, 3, 2, 2, 2, 175, 176, 7, 37, 2, 2, 176, 177, 7, 81, 2, 2, 177, 178, 7, 82, 2, 2, 178, 179, 7, 62, 2, 2, 179, 180, 7, 35, 2, 2, 180, 54, 3, 2, 2, 2, 181, 182, 7, 37, 2, 2, 182, 183, 7, 81, 2, 2, 183, 184, 7, 82, 2, 2, 184, 185, 7, 62, 2, 2, 185, 186, 7, 48, 2, 2, 186, 187, 7, 64, 2, 2, 187, 56, 3, 2, 2, 2, 188, 189, 7, 37, 2, 2, 189, 190, 7, 78, 2, 2, 190, 191, 7, 86, 2, 2, 191, 192, 7, 62, 2, 2, 192, 58, 3, 2, 2, 2, 193, 194, 7, 37, 2, 2, 194, 195, 7, 78, 2, 2, 195, 196, 7, 86, 2, 2, 196, 197, 7, 62, 2, 2, 197, 198, 7, 35, 2, 2, 198, 60, 3, 2, 2, 2, 199, 200, 7, 37, 2, 2, 200, 201, 7, 78, 2, 2, 201, 202, 7, 86, 2, 2, 202, 203, 7, 62, 2, 2, 203, 204, 7, 48, 2, 2, 204, 205, 7, 64, 2, 2, 205, 62, 3, 2, 2, 2, 206, 207, 7, 50, 2, 2, 207, 64, 3, 2, 2, 2, 208, 209, 7, 51, 2, 2, 209, 66, 3, 2, 2, 2, 210, 211, 7, 52, 2, 2, 211, 68, 3, 2, 2, 2, 212, 213, 7, 53, 2, 2, 213, 70, 3, 2, 2, 2, 214, 215, 7, 54, 2, 2, 215, 72, 3, 2, 2, 2, 216, 217, 7, 55, 2, 2, 217, 74, 3, 2, 2, 2, 218, 219, 7, 56, 2, 2, 219, 76, 3, 2, 2, 2, 220, 221, 7, 57, 2, 2, 221, 78, 3, 2, 2, 2, 222, 223, 7, 58, 2, 2, 223, 80, 3, 2, 2, 2, 224, 225, 7, 59, 2, 2, 225, 82, 3, 2, 2, 2, 226, 228, 9, 2, 2, 2, 227, 226, 3, 2, 2, 2, 228, 229, 3, 2, 2, 2, 229, 227, 3, 2, 2, 2, 229, 230, 3, 2, 2, 2, 230, 231, 3, 2, 2, 2, 231, 232, 8, 42, 2, 2, 232, 84, 3, 2, 2, 2, 4, 2, 229, 3, 8, 2, 2]
\ No newline at end of file
diff --git a/code/antlr4/.antlr/SearchLexer.java b/code/antlr4/.antlr/SearchLexer.java
new file mode 100644
index 0000000..fc4fc16
--- /dev/null
+++ b/code/antlr4/.antlr/SearchLexer.java
@@ -0,0 +1,188 @@
+// Generated from /home/luca/Desktop/Project/dSearch/code/antlr4/Search.g4 by ANTLR 4.7.1
+import org.antlr.v4.runtime.Lexer;
+import org.antlr.v4.runtime.CharStream;
+import org.antlr.v4.runtime.Token;
+import org.antlr.v4.runtime.TokenStream;
+import org.antlr.v4.runtime.*;
+import org.antlr.v4.runtime.atn.*;
+import org.antlr.v4.runtime.dfa.DFA;
+import org.antlr.v4.runtime.misc.*;
+
+@SuppressWarnings({"all", "warnings", "unchecked", "unused", "cast"})
+public class SearchLexer extends Lexer {
+	static { RuntimeMetaData.checkVersion("4.7.1", RuntimeMetaData.VERSION); }
+
+	protected static final DFA[] _decisionToDFA;
+	protected static final PredictionContextCache _sharedContextCache =
+		new PredictionContextCache();
+	public static final int
+		T__0=1, T__1=2, T__2=3, T__3=4, T__4=5, T__5=6, T__6=7, T__7=8, T__8=9, 
+		T__9=10, T__10=11, T__11=12, T__12=13, T__13=14, T__14=15, T__15=16, T__16=17, 
+		T__17=18, T__18=19, T__19=20, T__20=21, T__21=22, T__22=23, T__23=24, 
+		T__24=25, T__25=26, T__26=27, T__27=28, T__28=29, T__29=30, T__30=31, 
+		T__31=32, T__32=33, T__33=34, T__34=35, T__35=36, T__36=37, T__37=38, 
+		T__38=39, T__39=40, WS=41;
+	public static String[] channelNames = {
+		"DEFAULT_TOKEN_CHANNEL", "HIDDEN"
+	};
+
+	public static String[] modeNames = {
+		"DEFAULT_MODE"
+	};
+
+	public static final String[] ruleNames = {
+		"T__0", "T__1", "T__2", "T__3", "T__4", "T__5", "T__6", "T__7", "T__8", 
+		"T__9", "T__10", "T__11", "T__12", "T__13", "T__14", "T__15", "T__16", 
+		"T__17", "T__18", "T__19", "T__20", "T__21", "T__22", "T__23", "T__24", 
+		"T__25", "T__26", "T__27", "T__28", "T__29", "T__30", "T__31", "T__32", 
+		"T__33", "T__34", "T__35", "T__36", "T__37", "T__38", "T__39", "WS"
+	};
+
+	private static final String[] _LITERAL_NAMES = {
+		null, "'->'", "'_'", "'if'", "'else'", "'for'", "'forEach'", "'while'", 
+		"'return'", "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", 
+		"'='", "'.'", "','", "';'", "'#ID<'", "'>'", "'#ID<!'", "'#ID<.>'", "'#OP<'", 
+		"'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", "'#LT<.>'", "'0'", "'1'", 
+		"'2'", "'3'", "'4'", "'5'", "'6'", "'7'", "'8'", "'9'"
+	};
+	private static final String[] _SYMBOLIC_NAMES = {
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, "WS"
+	};
+	public static final Vocabulary VOCABULARY = new VocabularyImpl(_LITERAL_NAMES, _SYMBOLIC_NAMES);
+
+	/**
+	 * @deprecated Use {@link #VOCABULARY} instead.
+	 */
+	@Deprecated
+	public static final String[] tokenNames;
+	static {
+		tokenNames = new String[_SYMBOLIC_NAMES.length];
+		for (int i = 0; i < tokenNames.length; i++) {
+			tokenNames[i] = VOCABULARY.getLiteralName(i);
+			if (tokenNames[i] == null) {
+				tokenNames[i] = VOCABULARY.getSymbolicName(i);
+			}
+
+			if (tokenNames[i] == null) {
+				tokenNames[i] = "<INVALID>";
+			}
+		}
+	}
+
+	@Override
+	@Deprecated
+	public String[] getTokenNames() {
+		return tokenNames;
+	}
+
+	@Override
+
+	public Vocabulary getVocabulary() {
+		return VOCABULARY;
+	}
+
+
+	public SearchLexer(CharStream input) {
+		super(input);
+		_interp = new LexerATNSimulator(this,_ATN,_decisionToDFA,_sharedContextCache);
+	}
+
+	@Override
+	public String getGrammarFileName() { return "Search.g4"; }
+
+	@Override
+	public String[] getRuleNames() { return ruleNames; }
+
+	@Override
+	public String getSerializedATN() { return _serializedATN; }
+
+	@Override
+	public String[] getChannelNames() { return channelNames; }
+
+	@Override
+	public String[] getModeNames() { return modeNames; }
+
+	@Override
+	public ATN getATN() { return _ATN; }
+
+	public static final String _serializedATN =
+		"\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2+\u00e9\b\1\4\2\t"+
+		"\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13"+
+		"\t\13\4\f\t\f\4\r\t\r\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22"+
+		"\4\23\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30\4\31\t\31"+
+		"\4\32\t\32\4\33\t\33\4\34\t\34\4\35\t\35\4\36\t\36\4\37\t\37\4 \t \4!"+
+		"\t!\4\"\t\"\4#\t#\4$\t$\4%\t%\4&\t&\4\'\t\'\4(\t(\4)\t)\4*\t*\3\2\3\2"+
+		"\3\2\3\3\3\3\3\4\3\4\3\4\3\5\3\5\3\5\3\5\3\5\3\6\3\6\3\6\3\6\3\7\3\7\3"+
+		"\7\3\7\3\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\t\3\t\3\t\3\t\3\t\3\t"+
+		"\3\t\3\n\3\n\3\n\3\n\3\n\3\13\3\13\3\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17"+
+		"\3\20\3\20\3\21\3\21\3\22\3\22\3\23\3\23\3\24\3\24\3\25\3\25\3\26\3\26"+
+		"\3\26\3\26\3\26\3\27\3\27\3\30\3\30\3\30\3\30\3\30\3\30\3\31\3\31\3\31"+
+		"\3\31\3\31\3\31\3\31\3\32\3\32\3\32\3\32\3\32\3\33\3\33\3\33\3\33\3\33"+
+		"\3\33\3\34\3\34\3\34\3\34\3\34\3\34\3\34\3\35\3\35\3\35\3\35\3\35\3\36"+
+		"\3\36\3\36\3\36\3\36\3\36\3\37\3\37\3\37\3\37\3\37\3\37\3\37\3 \3 \3!"+
+		"\3!\3\"\3\"\3#\3#\3$\3$\3%\3%\3&\3&\3\'\3\'\3(\3(\3)\3)\3*\6*\u00e4\n"+
+		"*\r*\16*\u00e5\3*\3*\2\2+\3\3\5\4\7\5\t\6\13\7\r\b\17\t\21\n\23\13\25"+
+		"\f\27\r\31\16\33\17\35\20\37\21!\22#\23%\24\'\25)\26+\27-\30/\31\61\32"+
+		"\63\33\65\34\67\359\36;\37= ?!A\"C#E$G%I&K\'M(O)Q*S+\3\2\3\5\2\13\f\17"+
+		"\17\"\"\2\u00e9\2\3\3\2\2\2\2\5\3\2\2\2\2\7\3\2\2\2\2\t\3\2\2\2\2\13\3"+
+		"\2\2\2\2\r\3\2\2\2\2\17\3\2\2\2\2\21\3\2\2\2\2\23\3\2\2\2\2\25\3\2\2\2"+
+		"\2\27\3\2\2\2\2\31\3\2\2\2\2\33\3\2\2\2\2\35\3\2\2\2\2\37\3\2\2\2\2!\3"+
+		"\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2\'\3\2\2\2\2)\3\2\2\2\2+\3\2\2\2\2-\3\2"+
+		"\2\2\2/\3\2\2\2\2\61\3\2\2\2\2\63\3\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\2"+
+		"9\3\2\2\2\2;\3\2\2\2\2=\3\2\2\2\2?\3\2\2\2\2A\3\2\2\2\2C\3\2\2\2\2E\3"+
+		"\2\2\2\2G\3\2\2\2\2I\3\2\2\2\2K\3\2\2\2\2M\3\2\2\2\2O\3\2\2\2\2Q\3\2\2"+
+		"\2\2S\3\2\2\2\3U\3\2\2\2\5X\3\2\2\2\7Z\3\2\2\2\t]\3\2\2\2\13b\3\2\2\2"+
+		"\rf\3\2\2\2\17n\3\2\2\2\21t\3\2\2\2\23{\3\2\2\2\25\u0080\3\2\2\2\27\u0082"+
+		"\3\2\2\2\31\u0084\3\2\2\2\33\u0086\3\2\2\2\35\u0088\3\2\2\2\37\u008a\3"+
+		"\2\2\2!\u008c\3\2\2\2#\u008e\3\2\2\2%\u0090\3\2\2\2\'\u0092\3\2\2\2)\u0094"+
+		"\3\2\2\2+\u0096\3\2\2\2-\u009b\3\2\2\2/\u009d\3\2\2\2\61\u00a3\3\2\2\2"+
+		"\63\u00aa\3\2\2\2\65\u00af\3\2\2\2\67\u00b5\3\2\2\29\u00bc\3\2\2\2;\u00c1"+
+		"\3\2\2\2=\u00c7\3\2\2\2?\u00ce\3\2\2\2A\u00d0\3\2\2\2C\u00d2\3\2\2\2E"+
+		"\u00d4\3\2\2\2G\u00d6\3\2\2\2I\u00d8\3\2\2\2K\u00da\3\2\2\2M\u00dc\3\2"+
+		"\2\2O\u00de\3\2\2\2Q\u00e0\3\2\2\2S\u00e3\3\2\2\2UV\7/\2\2VW\7@\2\2W\4"+
+		"\3\2\2\2XY\7a\2\2Y\6\3\2\2\2Z[\7k\2\2[\\\7h\2\2\\\b\3\2\2\2]^\7g\2\2^"+
+		"_\7n\2\2_`\7u\2\2`a\7g\2\2a\n\3\2\2\2bc\7h\2\2cd\7q\2\2de\7t\2\2e\f\3"+
+		"\2\2\2fg\7h\2\2gh\7q\2\2hi\7t\2\2ij\7G\2\2jk\7c\2\2kl\7e\2\2lm\7j\2\2"+
+		"m\16\3\2\2\2no\7y\2\2op\7j\2\2pq\7k\2\2qr\7n\2\2rs\7g\2\2s\20\3\2\2\2"+
+		"tu\7t\2\2uv\7g\2\2vw\7v\2\2wx\7w\2\2xy\7t\2\2yz\7p\2\2z\22\3\2\2\2{|\7"+
+		"P\2\2|}\7W\2\2}~\7N\2\2~\177\7N\2\2\177\24\3\2\2\2\u0080\u0081\7*\2\2"+
+		"\u0081\26\3\2\2\2\u0082\u0083\7+\2\2\u0083\30\3\2\2\2\u0084\u0085\7]\2"+
+		"\2\u0085\32\3\2\2\2\u0086\u0087\7_\2\2\u0087\34\3\2\2\2\u0088\u0089\7"+
+		"}\2\2\u0089\36\3\2\2\2\u008a\u008b\7\177\2\2\u008b \3\2\2\2\u008c\u008d"+
+		"\7$\2\2\u008d\"\3\2\2\2\u008e\u008f\7?\2\2\u008f$\3\2\2\2\u0090\u0091"+
+		"\7\60\2\2\u0091&\3\2\2\2\u0092\u0093\7.\2\2\u0093(\3\2\2\2\u0094\u0095"+
+		"\7=\2\2\u0095*\3\2\2\2\u0096\u0097\7%\2\2\u0097\u0098\7K\2\2\u0098\u0099"+
+		"\7F\2\2\u0099\u009a\7>\2\2\u009a,\3\2\2\2\u009b\u009c\7@\2\2\u009c.\3"+
+		"\2\2\2\u009d\u009e\7%\2\2\u009e\u009f\7K\2\2\u009f\u00a0\7F\2\2\u00a0"+
+		"\u00a1\7>\2\2\u00a1\u00a2\7#\2\2\u00a2\60\3\2\2\2\u00a3\u00a4\7%\2\2\u00a4"+
+		"\u00a5\7K\2\2\u00a5\u00a6\7F\2\2\u00a6\u00a7\7>\2\2\u00a7\u00a8\7\60\2"+
+		"\2\u00a8\u00a9\7@\2\2\u00a9\62\3\2\2\2\u00aa\u00ab\7%\2\2\u00ab\u00ac"+
+		"\7Q\2\2\u00ac\u00ad\7R\2\2\u00ad\u00ae\7>\2\2\u00ae\64\3\2\2\2\u00af\u00b0"+
+		"\7%\2\2\u00b0\u00b1\7Q\2\2\u00b1\u00b2\7R\2\2\u00b2\u00b3\7>\2\2\u00b3"+
+		"\u00b4\7#\2\2\u00b4\66\3\2\2\2\u00b5\u00b6\7%\2\2\u00b6\u00b7\7Q\2\2\u00b7"+
+		"\u00b8\7R\2\2\u00b8\u00b9\7>\2\2\u00b9\u00ba\7\60\2\2\u00ba\u00bb\7@\2"+
+		"\2\u00bb8\3\2\2\2\u00bc\u00bd\7%\2\2\u00bd\u00be\7N\2\2\u00be\u00bf\7"+
+		"V\2\2\u00bf\u00c0\7>\2\2\u00c0:\3\2\2\2\u00c1\u00c2\7%\2\2\u00c2\u00c3"+
+		"\7N\2\2\u00c3\u00c4\7V\2\2\u00c4\u00c5\7>\2\2\u00c5\u00c6\7#\2\2\u00c6"+
+		"<\3\2\2\2\u00c7\u00c8\7%\2\2\u00c8\u00c9\7N\2\2\u00c9\u00ca\7V\2\2\u00ca"+
+		"\u00cb\7>\2\2\u00cb\u00cc\7\60\2\2\u00cc\u00cd\7@\2\2\u00cd>\3\2\2\2\u00ce"+
+		"\u00cf\7\62\2\2\u00cf@\3\2\2\2\u00d0\u00d1\7\63\2\2\u00d1B\3\2\2\2\u00d2"+
+		"\u00d3\7\64\2\2\u00d3D\3\2\2\2\u00d4\u00d5\7\65\2\2\u00d5F\3\2\2\2\u00d6"+
+		"\u00d7\7\66\2\2\u00d7H\3\2\2\2\u00d8\u00d9\7\67\2\2\u00d9J\3\2\2\2\u00da"+
+		"\u00db\78\2\2\u00dbL\3\2\2\2\u00dc\u00dd\79\2\2\u00ddN\3\2\2\2\u00de\u00df"+
+		"\7:\2\2\u00dfP\3\2\2\2\u00e0\u00e1\7;\2\2\u00e1R\3\2\2\2\u00e2\u00e4\t"+
+		"\2\2\2\u00e3\u00e2\3\2\2\2\u00e4\u00e5\3\2\2\2\u00e5\u00e3\3\2\2\2\u00e5"+
+		"\u00e6\3\2\2\2\u00e6\u00e7\3\2\2\2\u00e7\u00e8\b*\2\2\u00e8T\3\2\2\2\4"+
+		"\2\u00e5\3\b\2\2";
+	public static final ATN _ATN =
+		new ATNDeserializer().deserialize(_serializedATN.toCharArray());
+	static {
+		_decisionToDFA = new DFA[_ATN.getNumberOfDecisions()];
+		for (int i = 0; i < _ATN.getNumberOfDecisions(); i++) {
+			_decisionToDFA[i] = new DFA(_ATN.getDecisionState(i), i);
+		}
+	}
+}
\ No newline at end of file
diff --git a/code/antlr4/.antlr/SearchLexer.tokens b/code/antlr4/.antlr/SearchLexer.tokens
new file mode 100644
index 0000000..372bf0c
--- /dev/null
+++ b/code/antlr4/.antlr/SearchLexer.tokens
@@ -0,0 +1,81 @@
+T__0=1
+T__1=2
+T__2=3
+T__3=4
+T__4=5
+T__5=6
+T__6=7
+T__7=8
+T__8=9
+T__9=10
+T__10=11
+T__11=12
+T__12=13
+T__13=14
+T__14=15
+T__15=16
+T__16=17
+T__17=18
+T__18=19
+T__19=20
+T__20=21
+T__21=22
+T__22=23
+T__23=24
+T__24=25
+T__25=26
+T__26=27
+T__27=28
+T__28=29
+T__29=30
+T__30=31
+T__31=32
+T__32=33
+T__33=34
+T__34=35
+T__35=36
+T__36=37
+T__37=38
+T__38=39
+T__39=40
+WS=41
+'->'=1
+'_'=2
+'if'=3
+'else'=4
+'for'=5
+'forEach'=6
+'while'=7
+'return'=8
+'NULL'=9
+'('=10
+')'=11
+'['=12
+']'=13
+'{'=14
+'}'=15
+'"'=16
+'='=17
+'.'=18
+','=19
+';'=20
+'#ID<'=21
+'>'=22
+'#ID<!'=23
+'#ID<.>'=24
+'#OP<'=25
+'#OP<!'=26
+'#OP<.>'=27
+'#LT<'=28
+'#LT<!'=29
+'#LT<.>'=30
+'0'=31
+'1'=32
+'2'=33
+'3'=34
+'4'=35
+'5'=36
+'6'=37
+'7'=38
+'8'=39
+'9'=40
diff --git a/code/antlr4/.antlr/SearchParser.java b/code/antlr4/.antlr/SearchParser.java
new file mode 100644
index 0000000..139afe3
--- /dev/null
+++ b/code/antlr4/.antlr/SearchParser.java
@@ -0,0 +1,832 @@
+// Generated from /home/luca/Desktop/Project/dSearch/code/antlr4/Search.g4 by ANTLR 4.7.1
+import org.antlr.v4.runtime.atn.*;
+import org.antlr.v4.runtime.dfa.DFA;
+import org.antlr.v4.runtime.*;
+import org.antlr.v4.runtime.misc.*;
+import org.antlr.v4.runtime.tree.*;
+import java.util.List;
+import java.util.Iterator;
+import java.util.ArrayList;
+
+@SuppressWarnings({"all", "warnings", "unchecked", "unused", "cast"})
+public class SearchParser extends Parser {
+	static { RuntimeMetaData.checkVersion("4.7.1", RuntimeMetaData.VERSION); }
+
+	protected static final DFA[] _decisionToDFA;
+	protected static final PredictionContextCache _sharedContextCache =
+		new PredictionContextCache();
+	public static final int
+		T__0=1, T__1=2, T__2=3, T__3=4, T__4=5, T__5=6, T__6=7, T__7=8, T__8=9, 
+		T__9=10, T__10=11, T__11=12, T__12=13, T__13=14, T__14=15, T__15=16, T__16=17, 
+		T__17=18, T__18=19, T__19=20, T__20=21, T__21=22, T__22=23, T__23=24, 
+		T__24=25, T__25=26, T__26=27, T__27=28, T__28=29, T__29=30, T__30=31, 
+		T__31=32, T__32=33, T__33=34, T__34=35, T__35=36, T__36=37, T__37=38, 
+		T__38=39, T__39=40, WS=41;
+	public static final int
+		RULE_query = 0, RULE_code = 1, RULE_token = 2, RULE_keyword = 3, RULE_punctuator = 4, 
+		RULE_identifier = 5, RULE_operator = 6, RULE_literal = 7, RULE_digit = 8;
+	public static final String[] ruleNames = {
+		"query", "code", "token", "keyword", "punctuator", "identifier", "operator", 
+		"literal", "digit"
+	};
+
+	private static final String[] _LITERAL_NAMES = {
+		null, "'->'", "'_'", "'if'", "'else'", "'for'", "'forEach'", "'while'", 
+		"'return'", "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", 
+		"'='", "'.'", "','", "';'", "'#ID<'", "'>'", "'#ID<!'", "'#ID<.>'", "'#OP<'", 
+		"'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", "'#LT<.>'", "'0'", "'1'", 
+		"'2'", "'3'", "'4'", "'5'", "'6'", "'7'", "'8'", "'9'"
+	};
+	private static final String[] _SYMBOLIC_NAMES = {
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, "WS"
+	};
+	public static final Vocabulary VOCABULARY = new VocabularyImpl(_LITERAL_NAMES, _SYMBOLIC_NAMES);
+
+	/**
+	 * @deprecated Use {@link #VOCABULARY} instead.
+	 */
+	@Deprecated
+	public static final String[] tokenNames;
+	static {
+		tokenNames = new String[_SYMBOLIC_NAMES.length];
+		for (int i = 0; i < tokenNames.length; i++) {
+			tokenNames[i] = VOCABULARY.getLiteralName(i);
+			if (tokenNames[i] == null) {
+				tokenNames[i] = VOCABULARY.getSymbolicName(i);
+			}
+
+			if (tokenNames[i] == null) {
+				tokenNames[i] = "<INVALID>";
+			}
+		}
+	}
+
+	@Override
+	@Deprecated
+	public String[] getTokenNames() {
+		return tokenNames;
+	}
+
+	@Override
+
+	public Vocabulary getVocabulary() {
+		return VOCABULARY;
+	}
+
+	@Override
+	public String getGrammarFileName() { return "Search.g4"; }
+
+	@Override
+	public String[] getRuleNames() { return ruleNames; }
+
+	@Override
+	public String getSerializedATN() { return _serializedATN; }
+
+	@Override
+	public ATN getATN() { return _ATN; }
+
+	public SearchParser(TokenStream input) {
+		super(input);
+		_interp = new ParserATNSimulator(this,_ATN,_decisionToDFA,_sharedContextCache);
+	}
+	public static class QueryContext extends ParserRuleContext {
+		public List<CodeContext> code() {
+			return getRuleContexts(CodeContext.class);
+		}
+		public CodeContext code(int i) {
+			return getRuleContext(CodeContext.class,i);
+		}
+		public QueryContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_query; }
+	}
+
+	public final QueryContext query() throws RecognitionException {
+		QueryContext _localctx = new QueryContext(_ctx, getState());
+		enterRule(_localctx, 0, RULE_query);
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(18);
+			code();
+			setState(19);
+			match(T__0);
+			setState(20);
+			code();
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class CodeContext extends ParserRuleContext {
+		public List<TokenContext> token() {
+			return getRuleContexts(TokenContext.class);
+		}
+		public TokenContext token(int i) {
+			return getRuleContext(TokenContext.class,i);
+		}
+		public CodeContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_code; }
+	}
+
+	public final CodeContext code() throws RecognitionException {
+		CodeContext _localctx = new CodeContext(_ctx, getState());
+		enterRule(_localctx, 2, RULE_code);
+		int _la;
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(25);
+			_errHandler.sync(this);
+			_la = _input.LA(1);
+			while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+				{
+				{
+				setState(22);
+				token();
+				}
+				}
+				setState(27);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+			}
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class TokenContext extends ParserRuleContext {
+		public IdentifierContext identifier() {
+			return getRuleContext(IdentifierContext.class,0);
+		}
+		public KeywordContext keyword() {
+			return getRuleContext(KeywordContext.class,0);
+		}
+		public PunctuatorContext punctuator() {
+			return getRuleContext(PunctuatorContext.class,0);
+		}
+		public OperatorContext operator() {
+			return getRuleContext(OperatorContext.class,0);
+		}
+		public LiteralContext literal() {
+			return getRuleContext(LiteralContext.class,0);
+		}
+		public TokenContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_token; }
+	}
+
+	public final TokenContext token() throws RecognitionException {
+		TokenContext _localctx = new TokenContext(_ctx, getState());
+		enterRule(_localctx, 4, RULE_token);
+		try {
+			setState(34);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__20:
+			case T__22:
+			case T__23:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(28);
+				identifier();
+				}
+				break;
+			case T__2:
+			case T__3:
+			case T__4:
+			case T__5:
+			case T__6:
+			case T__7:
+			case T__8:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(29);
+				keyword();
+				}
+				break;
+			case T__9:
+			case T__11:
+			case T__13:
+			case T__15:
+			case T__16:
+			case T__17:
+			case T__18:
+			case T__19:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(30);
+				punctuator();
+				}
+				break;
+			case T__24:
+			case T__25:
+			case T__26:
+				enterOuterAlt(_localctx, 4);
+				{
+				setState(31);
+				operator();
+				}
+				break;
+			case T__27:
+			case T__28:
+			case T__29:
+				enterOuterAlt(_localctx, 5);
+				{
+				setState(32);
+				literal();
+				}
+				break;
+			case T__1:
+				enterOuterAlt(_localctx, 6);
+				{
+				setState(33);
+				match(T__1);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class KeywordContext extends ParserRuleContext {
+		public KeywordContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_keyword; }
+	}
+
+	public final KeywordContext keyword() throws RecognitionException {
+		KeywordContext _localctx = new KeywordContext(_ctx, getState());
+		enterRule(_localctx, 6, RULE_keyword);
+		int _la;
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(36);
+			_la = _input.LA(1);
+			if ( !((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8))) != 0)) ) {
+			_errHandler.recoverInline(this);
+			}
+			else {
+				if ( _input.LA(1)==Token.EOF ) matchedEOF = true;
+				_errHandler.reportMatch(this);
+				consume();
+			}
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class PunctuatorContext extends ParserRuleContext {
+		public List<TokenContext> token() {
+			return getRuleContexts(TokenContext.class);
+		}
+		public TokenContext token(int i) {
+			return getRuleContext(TokenContext.class,i);
+		}
+		public PunctuatorContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_punctuator; }
+	}
+
+	public final PunctuatorContext punctuator() throws RecognitionException {
+		PunctuatorContext _localctx = new PunctuatorContext(_ctx, getState());
+		enterRule(_localctx, 8, RULE_punctuator);
+		int _la;
+		try {
+			int _alt;
+			setState(74);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__9:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(38);
+				match(T__9);
+				setState(42);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+					{
+					{
+					setState(39);
+					token();
+					}
+					}
+					setState(44);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(45);
+				match(T__10);
+				}
+				break;
+			case T__11:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(46);
+				match(T__11);
+				setState(50);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+					{
+					{
+					setState(47);
+					token();
+					}
+					}
+					setState(52);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(53);
+				match(T__12);
+				}
+				break;
+			case T__13:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(54);
+				match(T__13);
+				setState(58);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+					{
+					{
+					setState(55);
+					token();
+					}
+					}
+					setState(60);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(61);
+				match(T__14);
+				}
+				break;
+			case T__15:
+				enterOuterAlt(_localctx, 4);
+				{
+				setState(62);
+				match(T__15);
+				setState(66);
+				_errHandler.sync(this);
+				_alt = getInterpreter().adaptivePredict(_input,5,_ctx);
+				while ( _alt!=2 && _alt!=org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER ) {
+					if ( _alt==1 ) {
+						{
+						{
+						setState(63);
+						token();
+						}
+						} 
+					}
+					setState(68);
+					_errHandler.sync(this);
+					_alt = getInterpreter().adaptivePredict(_input,5,_ctx);
+				}
+				setState(69);
+				match(T__15);
+				}
+				break;
+			case T__16:
+				enterOuterAlt(_localctx, 5);
+				{
+				setState(70);
+				match(T__16);
+				}
+				break;
+			case T__17:
+				enterOuterAlt(_localctx, 6);
+				{
+				setState(71);
+				match(T__17);
+				}
+				break;
+			case T__18:
+				enterOuterAlt(_localctx, 7);
+				{
+				setState(72);
+				match(T__18);
+				}
+				break;
+			case T__19:
+				enterOuterAlt(_localctx, 8);
+				{
+				setState(73);
+				match(T__19);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class IdentifierContext extends ParserRuleContext {
+		public List<DigitContext> digit() {
+			return getRuleContexts(DigitContext.class);
+		}
+		public DigitContext digit(int i) {
+			return getRuleContext(DigitContext.class,i);
+		}
+		public IdentifierContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_identifier; }
+	}
+
+	public final IdentifierContext identifier() throws RecognitionException {
+		IdentifierContext _localctx = new IdentifierContext(_ctx, getState());
+		enterRule(_localctx, 10, RULE_identifier);
+		int _la;
+		try {
+			setState(93);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__20:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(76);
+				match(T__20);
+				setState(80);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(77);
+					digit();
+					}
+					}
+					setState(82);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(83);
+				match(T__21);
+				}
+				break;
+			case T__22:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(84);
+				match(T__22);
+				setState(88);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(85);
+					digit();
+					}
+					}
+					setState(90);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(91);
+				match(T__21);
+				}
+				break;
+			case T__23:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(92);
+				match(T__23);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class OperatorContext extends ParserRuleContext {
+		public List<DigitContext> digit() {
+			return getRuleContexts(DigitContext.class);
+		}
+		public DigitContext digit(int i) {
+			return getRuleContext(DigitContext.class,i);
+		}
+		public OperatorContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_operator; }
+	}
+
+	public final OperatorContext operator() throws RecognitionException {
+		OperatorContext _localctx = new OperatorContext(_ctx, getState());
+		enterRule(_localctx, 12, RULE_operator);
+		int _la;
+		try {
+			setState(112);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__24:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(95);
+				match(T__24);
+				setState(99);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(96);
+					digit();
+					}
+					}
+					setState(101);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(102);
+				match(T__21);
+				}
+				break;
+			case T__25:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(103);
+				match(T__25);
+				setState(107);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(104);
+					digit();
+					}
+					}
+					setState(109);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(110);
+				match(T__21);
+				}
+				break;
+			case T__26:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(111);
+				match(T__26);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class LiteralContext extends ParserRuleContext {
+		public List<DigitContext> digit() {
+			return getRuleContexts(DigitContext.class);
+		}
+		public DigitContext digit(int i) {
+			return getRuleContext(DigitContext.class,i);
+		}
+		public LiteralContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_literal; }
+	}
+
+	public final LiteralContext literal() throws RecognitionException {
+		LiteralContext _localctx = new LiteralContext(_ctx, getState());
+		enterRule(_localctx, 14, RULE_literal);
+		int _la;
+		try {
+			setState(131);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__27:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(114);
+				match(T__27);
+				setState(118);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(115);
+					digit();
+					}
+					}
+					setState(120);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(121);
+				match(T__21);
+				}
+				break;
+			case T__28:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(122);
+				match(T__28);
+				setState(126);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(123);
+					digit();
+					}
+					}
+					setState(128);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(129);
+				match(T__21);
+				}
+				break;
+			case T__29:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(130);
+				match(T__29);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class DigitContext extends ParserRuleContext {
+		public DigitContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_digit; }
+	}
+
+	public final DigitContext digit() throws RecognitionException {
+		DigitContext _localctx = new DigitContext(_ctx, getState());
+		enterRule(_localctx, 16, RULE_digit);
+		int _la;
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(133);
+			_la = _input.LA(1);
+			if ( !((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) ) {
+			_errHandler.recoverInline(this);
+			}
+			else {
+				if ( _input.LA(1)==Token.EOF ) matchedEOF = true;
+				_errHandler.reportMatch(this);
+				consume();
+			}
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static final String _serializedATN =
+		"\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3+\u008a\4\2\t\2\4"+
+		"\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7\4\b\t\b\4\t\t\t\4\n\t\n\3\2\3\2"+
+		"\3\2\3\2\3\3\7\3\32\n\3\f\3\16\3\35\13\3\3\4\3\4\3\4\3\4\3\4\3\4\5\4%"+
+		"\n\4\3\5\3\5\3\6\3\6\7\6+\n\6\f\6\16\6.\13\6\3\6\3\6\3\6\7\6\63\n\6\f"+
+		"\6\16\6\66\13\6\3\6\3\6\3\6\7\6;\n\6\f\6\16\6>\13\6\3\6\3\6\3\6\7\6C\n"+
+		"\6\f\6\16\6F\13\6\3\6\3\6\3\6\3\6\3\6\5\6M\n\6\3\7\3\7\7\7Q\n\7\f\7\16"+
+		"\7T\13\7\3\7\3\7\3\7\7\7Y\n\7\f\7\16\7\\\13\7\3\7\3\7\5\7`\n\7\3\b\3\b"+
+		"\7\bd\n\b\f\b\16\bg\13\b\3\b\3\b\3\b\7\bl\n\b\f\b\16\bo\13\b\3\b\3\b\5"+
+		"\bs\n\b\3\t\3\t\7\tw\n\t\f\t\16\tz\13\t\3\t\3\t\3\t\7\t\177\n\t\f\t\16"+
+		"\t\u0082\13\t\3\t\3\t\5\t\u0086\n\t\3\n\3\n\3\n\2\2\13\2\4\6\b\n\f\16"+
+		"\20\22\2\4\3\2\5\13\3\2!*\2\u009d\2\24\3\2\2\2\4\33\3\2\2\2\6$\3\2\2\2"+
+		"\b&\3\2\2\2\nL\3\2\2\2\f_\3\2\2\2\16r\3\2\2\2\20\u0085\3\2\2\2\22\u0087"+
+		"\3\2\2\2\24\25\5\4\3\2\25\26\7\3\2\2\26\27\5\4\3\2\27\3\3\2\2\2\30\32"+
+		"\5\6\4\2\31\30\3\2\2\2\32\35\3\2\2\2\33\31\3\2\2\2\33\34\3\2\2\2\34\5"+
+		"\3\2\2\2\35\33\3\2\2\2\36%\5\f\7\2\37%\5\b\5\2 %\5\n\6\2!%\5\16\b\2\""+
+		"%\5\20\t\2#%\7\4\2\2$\36\3\2\2\2$\37\3\2\2\2$ \3\2\2\2$!\3\2\2\2$\"\3"+
+		"\2\2\2$#\3\2\2\2%\7\3\2\2\2&\'\t\2\2\2\'\t\3\2\2\2(,\7\f\2\2)+\5\6\4\2"+
+		"*)\3\2\2\2+.\3\2\2\2,*\3\2\2\2,-\3\2\2\2-/\3\2\2\2.,\3\2\2\2/M\7\r\2\2"+
+		"\60\64\7\16\2\2\61\63\5\6\4\2\62\61\3\2\2\2\63\66\3\2\2\2\64\62\3\2\2"+
+		"\2\64\65\3\2\2\2\65\67\3\2\2\2\66\64\3\2\2\2\67M\7\17\2\28<\7\20\2\29"+
+		";\5\6\4\2:9\3\2\2\2;>\3\2\2\2<:\3\2\2\2<=\3\2\2\2=?\3\2\2\2><\3\2\2\2"+
+		"?M\7\21\2\2@D\7\22\2\2AC\5\6\4\2BA\3\2\2\2CF\3\2\2\2DB\3\2\2\2DE\3\2\2"+
+		"\2EG\3\2\2\2FD\3\2\2\2GM\7\22\2\2HM\7\23\2\2IM\7\24\2\2JM\7\25\2\2KM\7"+
+		"\26\2\2L(\3\2\2\2L\60\3\2\2\2L8\3\2\2\2L@\3\2\2\2LH\3\2\2\2LI\3\2\2\2"+
+		"LJ\3\2\2\2LK\3\2\2\2M\13\3\2\2\2NR\7\27\2\2OQ\5\22\n\2PO\3\2\2\2QT\3\2"+
+		"\2\2RP\3\2\2\2RS\3\2\2\2SU\3\2\2\2TR\3\2\2\2U`\7\30\2\2VZ\7\31\2\2WY\5"+
+		"\22\n\2XW\3\2\2\2Y\\\3\2\2\2ZX\3\2\2\2Z[\3\2\2\2[]\3\2\2\2\\Z\3\2\2\2"+
+		"]`\7\30\2\2^`\7\32\2\2_N\3\2\2\2_V\3\2\2\2_^\3\2\2\2`\r\3\2\2\2ae\7\33"+
+		"\2\2bd\5\22\n\2cb\3\2\2\2dg\3\2\2\2ec\3\2\2\2ef\3\2\2\2fh\3\2\2\2ge\3"+
+		"\2\2\2hs\7\30\2\2im\7\34\2\2jl\5\22\n\2kj\3\2\2\2lo\3\2\2\2mk\3\2\2\2"+
+		"mn\3\2\2\2np\3\2\2\2om\3\2\2\2ps\7\30\2\2qs\7\35\2\2ra\3\2\2\2ri\3\2\2"+
+		"\2rq\3\2\2\2s\17\3\2\2\2tx\7\36\2\2uw\5\22\n\2vu\3\2\2\2wz\3\2\2\2xv\3"+
+		"\2\2\2xy\3\2\2\2y{\3\2\2\2zx\3\2\2\2{\u0086\7\30\2\2|\u0080\7\37\2\2}"+
+		"\177\5\22\n\2~}\3\2\2\2\177\u0082\3\2\2\2\u0080~\3\2\2\2\u0080\u0081\3"+
+		"\2\2\2\u0081\u0083\3\2\2\2\u0082\u0080\3\2\2\2\u0083\u0086\7\30\2\2\u0084"+
+		"\u0086\7 \2\2\u0085t\3\2\2\2\u0085|\3\2\2\2\u0085\u0084\3\2\2\2\u0086"+
+		"\21\3\2\2\2\u0087\u0088\t\3\2\2\u0088\23\3\2\2\2\22\33$,\64<DLRZ_emrx"+
+		"\u0080\u0085";
+	public static final ATN _ATN =
+		new ATNDeserializer().deserialize(_serializedATN.toCharArray());
+	static {
+		_decisionToDFA = new DFA[_ATN.getNumberOfDecisions()];
+		for (int i = 0; i < _ATN.getNumberOfDecisions(); i++) {
+			_decisionToDFA[i] = new DFA(_ATN.getDecisionState(i), i);
+		}
+	}
+}
\ No newline at end of file
diff --git a/code/antlr4/Search.g4 b/code/antlr4/Search.g4
index 1f7fd42..dfdb50c 100644
--- a/code/antlr4/Search.g4
+++ b/code/antlr4/Search.g4
@@ -1,58 +1,22 @@
 grammar Search;
 
-query: expr '->' expr;
-
-expr: token*;
-
-token: identifier 
-	| keyword 
-	| punctuator 
-	| op
-	| '_';
-
-identifier: '#ID<' digit* '>' | '#N<' digit* '>' | '#ID<.>' | '#N<.>' ;
-
-digit:  '0'
-	|'1'
-	|'2'
-	|'3'
-	|'4'
-	|'5'
-	|'6'
-	|'7'
-	|'8'
-	|'9';
-
-keyword: 'if' 
-	| 'else' 
-	| 'for' 
-	| 'forEach' 
-	| 'while' 
-	| 'return' 
-	| 'NULL';
-
-punctuator: '('token*')'
-	| '['token*']'
-	| '{'token*'}'
-	| '"'token*'"'
-	| '='
-	| '.'
-	| ','
-	| ';';
-
-op:     '+' 
-	| '−' 
-	| '*' 
-	| '/'
-	| '==' 
-	| '<' 
-	| '>' 
-	| '<='
-	| '>='
-	| '==' 
-	| '!=' 
-	| '&&'
-	| '||'
-	| '#OP<' digit* '>' ;
-
-WS:     [ \t\r\n]+ -> skip ;
+query: code '->' code;
+
+code: token*;
+
+token: identifier | keyword | punctuator | operator| literal| '_';
+
+keyword: 'if' | 'else' | 'for' | 'forEach' | 'while' | 'return' | 'NULL';
+
+punctuator: '('token*')' | '['token*']' | '{'token*'}'| '"'token*'"'| '='| '.'| ',' | ';';
+
+identifier: '#ID<' digit* '>' | '#ID<!' digit* '>' | '#ID<.>';
+
+operator: '#OP<' digit* '>' | '#OP<!' digit* '>' | '#OP<.>';
+
+literal: '#LT<' digit* '>' | '#LT<!' digit* '>' | '#LT<.>';
+
+digit:  '0' | '1' | '2' | '3' | '4' | '5' | '6' |'7' | '8' | '9';
+
+
+WS:     [ \t\r\n]+ -> skip ;
\ No newline at end of file
diff --git a/code/antlr4/SearchLexer.py b/code/antlr4/SearchLexer.py
index d1ff21d..440f5f6 100644
--- a/code/antlr4/SearchLexer.py
+++ b/code/antlr4/SearchLexer.py
@@ -7,101 +7,94 @@ import sys
 
 def serializedATN():
     with StringIO() as buf:
-        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2\62")
-        buf.write("\u00f8\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
+        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2+")
+        buf.write("\u00e9\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
         buf.write("\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r")
         buf.write("\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23")
         buf.write("\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30")
         buf.write("\4\31\t\31\4\32\t\32\4\33\t\33\4\34\t\34\4\35\t\35\4\36")
         buf.write("\t\36\4\37\t\37\4 \t \4!\t!\4\"\t\"\4#\t#\4$\t$\4%\t%")
-        buf.write("\4&\t&\4\'\t\'\4(\t(\4)\t)\4*\t*\4+\t+\4,\t,\4-\t-\4.")
-        buf.write("\t.\4/\t/\4\60\t\60\4\61\t\61\3\2\3\2\3\2\3\3\3\3\3\4")
-        buf.write("\3\4\3\4\3\4\3\4\3\5\3\5\3\6\3\6\3\6\3\6\3\7\3\7\3\7\3")
-        buf.write("\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\t\3\t\3\n\3\n")
-        buf.write("\3\13\3\13\3\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17\3\20\3")
-        buf.write("\20\3\21\3\21\3\22\3\22\3\23\3\23\3\23\3\24\3\24\3\24")
-        buf.write("\3\24\3\24\3\25\3\25\3\25\3\25\3\26\3\26\3\26\3\26\3\26")
-        buf.write("\3\26\3\26\3\26\3\27\3\27\3\27\3\27\3\27\3\27\3\30\3\30")
-        buf.write("\3\30\3\30\3\30\3\30\3\30\3\31\3\31\3\31\3\31\3\31\3\32")
-        buf.write("\3\32\3\33\3\33\3\34\3\34\3\35\3\35\3\36\3\36\3\37\3\37")
-        buf.write("\3 \3 \3!\3!\3\"\3\"\3#\3#\3$\3$\3%\3%\3&\3&\3\'\3\'\3")
-        buf.write("(\3(\3)\3)\3)\3*\3*\3+\3+\3+\3,\3,\3,\3-\3-\3-\3.\3.\3")
-        buf.write(".\3/\3/\3/\3\60\3\60\3\60\3\60\3\60\3\61\6\61\u00f3\n")
-        buf.write("\61\r\61\16\61\u00f4\3\61\3\61\2\2\62\3\3\5\4\7\5\t\6")
-        buf.write("\13\7\r\b\17\t\21\n\23\13\25\f\27\r\31\16\33\17\35\20")
-        buf.write("\37\21!\22#\23%\24\'\25)\26+\27-\30/\31\61\32\63\33\65")
-        buf.write("\34\67\359\36;\37= ?!A\"C#E$G%I&K\'M(O)Q*S+U,W-Y.[/]\60")
-        buf.write("_\61a\62\3\2\3\5\2\13\f\17\17\"\"\2\u00f8\2\3\3\2\2\2")
-        buf.write("\2\5\3\2\2\2\2\7\3\2\2\2\2\t\3\2\2\2\2\13\3\2\2\2\2\r")
-        buf.write("\3\2\2\2\2\17\3\2\2\2\2\21\3\2\2\2\2\23\3\2\2\2\2\25\3")
-        buf.write("\2\2\2\2\27\3\2\2\2\2\31\3\2\2\2\2\33\3\2\2\2\2\35\3\2")
-        buf.write("\2\2\2\37\3\2\2\2\2!\3\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2\'")
-        buf.write("\3\2\2\2\2)\3\2\2\2\2+\3\2\2\2\2-\3\2\2\2\2/\3\2\2\2\2")
-        buf.write("\61\3\2\2\2\2\63\3\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\29")
-        buf.write("\3\2\2\2\2;\3\2\2\2\2=\3\2\2\2\2?\3\2\2\2\2A\3\2\2\2\2")
-        buf.write("C\3\2\2\2\2E\3\2\2\2\2G\3\2\2\2\2I\3\2\2\2\2K\3\2\2\2")
-        buf.write("\2M\3\2\2\2\2O\3\2\2\2\2Q\3\2\2\2\2S\3\2\2\2\2U\3\2\2")
-        buf.write("\2\2W\3\2\2\2\2Y\3\2\2\2\2[\3\2\2\2\2]\3\2\2\2\2_\3\2")
-        buf.write("\2\2\2a\3\2\2\2\3c\3\2\2\2\5f\3\2\2\2\7h\3\2\2\2\tm\3")
-        buf.write("\2\2\2\13o\3\2\2\2\rs\3\2\2\2\17z\3\2\2\2\21\u0080\3\2")
-        buf.write("\2\2\23\u0082\3\2\2\2\25\u0084\3\2\2\2\27\u0086\3\2\2")
-        buf.write("\2\31\u0088\3\2\2\2\33\u008a\3\2\2\2\35\u008c\3\2\2\2")
-        buf.write("\37\u008e\3\2\2\2!\u0090\3\2\2\2#\u0092\3\2\2\2%\u0094")
-        buf.write("\3\2\2\2\'\u0097\3\2\2\2)\u009c\3\2\2\2+\u00a0\3\2\2\2")
-        buf.write("-\u00a8\3\2\2\2/\u00ae\3\2\2\2\61\u00b5\3\2\2\2\63\u00ba")
-        buf.write("\3\2\2\2\65\u00bc\3\2\2\2\67\u00be\3\2\2\29\u00c0\3\2")
-        buf.write("\2\2;\u00c2\3\2\2\2=\u00c4\3\2\2\2?\u00c6\3\2\2\2A\u00c8")
-        buf.write("\3\2\2\2C\u00ca\3\2\2\2E\u00cc\3\2\2\2G\u00ce\3\2\2\2")
-        buf.write("I\u00d0\3\2\2\2K\u00d2\3\2\2\2M\u00d4\3\2\2\2O\u00d6\3")
-        buf.write("\2\2\2Q\u00d8\3\2\2\2S\u00db\3\2\2\2U\u00dd\3\2\2\2W\u00e0")
-        buf.write("\3\2\2\2Y\u00e3\3\2\2\2[\u00e6\3\2\2\2]\u00e9\3\2\2\2")
-        buf.write("_\u00ec\3\2\2\2a\u00f2\3\2\2\2cd\7/\2\2de\7@\2\2e\4\3")
-        buf.write("\2\2\2fg\7a\2\2g\6\3\2\2\2hi\7%\2\2ij\7K\2\2jk\7F\2\2")
-        buf.write("kl\7>\2\2l\b\3\2\2\2mn\7@\2\2n\n\3\2\2\2op\7%\2\2pq\7")
-        buf.write("P\2\2qr\7>\2\2r\f\3\2\2\2st\7%\2\2tu\7K\2\2uv\7F\2\2v")
-        buf.write("w\7>\2\2wx\7\60\2\2xy\7@\2\2y\16\3\2\2\2z{\7%\2\2{|\7")
-        buf.write("P\2\2|}\7>\2\2}~\7\60\2\2~\177\7@\2\2\177\20\3\2\2\2\u0080")
-        buf.write("\u0081\7\62\2\2\u0081\22\3\2\2\2\u0082\u0083\7\63\2\2")
-        buf.write("\u0083\24\3\2\2\2\u0084\u0085\7\64\2\2\u0085\26\3\2\2")
-        buf.write("\2\u0086\u0087\7\65\2\2\u0087\30\3\2\2\2\u0088\u0089\7")
-        buf.write("\66\2\2\u0089\32\3\2\2\2\u008a\u008b\7\67\2\2\u008b\34")
-        buf.write("\3\2\2\2\u008c\u008d\78\2\2\u008d\36\3\2\2\2\u008e\u008f")
-        buf.write("\79\2\2\u008f \3\2\2\2\u0090\u0091\7:\2\2\u0091\"\3\2")
-        buf.write("\2\2\u0092\u0093\7;\2\2\u0093$\3\2\2\2\u0094\u0095\7k")
-        buf.write("\2\2\u0095\u0096\7h\2\2\u0096&\3\2\2\2\u0097\u0098\7g")
-        buf.write("\2\2\u0098\u0099\7n\2\2\u0099\u009a\7u\2\2\u009a\u009b")
-        buf.write("\7g\2\2\u009b(\3\2\2\2\u009c\u009d\7h\2\2\u009d\u009e")
-        buf.write("\7q\2\2\u009e\u009f\7t\2\2\u009f*\3\2\2\2\u00a0\u00a1")
-        buf.write("\7h\2\2\u00a1\u00a2\7q\2\2\u00a2\u00a3\7t\2\2\u00a3\u00a4")
-        buf.write("\7G\2\2\u00a4\u00a5\7c\2\2\u00a5\u00a6\7e\2\2\u00a6\u00a7")
-        buf.write("\7j\2\2\u00a7,\3\2\2\2\u00a8\u00a9\7y\2\2\u00a9\u00aa")
-        buf.write("\7j\2\2\u00aa\u00ab\7k\2\2\u00ab\u00ac\7n\2\2\u00ac\u00ad")
-        buf.write("\7g\2\2\u00ad.\3\2\2\2\u00ae\u00af\7t\2\2\u00af\u00b0")
-        buf.write("\7g\2\2\u00b0\u00b1\7v\2\2\u00b1\u00b2\7w\2\2\u00b2\u00b3")
-        buf.write("\7t\2\2\u00b3\u00b4\7p\2\2\u00b4\60\3\2\2\2\u00b5\u00b6")
-        buf.write("\7P\2\2\u00b6\u00b7\7W\2\2\u00b7\u00b8\7N\2\2\u00b8\u00b9")
-        buf.write("\7N\2\2\u00b9\62\3\2\2\2\u00ba\u00bb\7*\2\2\u00bb\64\3")
-        buf.write("\2\2\2\u00bc\u00bd\7+\2\2\u00bd\66\3\2\2\2\u00be\u00bf")
-        buf.write("\7]\2\2\u00bf8\3\2\2\2\u00c0\u00c1\7_\2\2\u00c1:\3\2\2")
-        buf.write("\2\u00c2\u00c3\7}\2\2\u00c3<\3\2\2\2\u00c4\u00c5\7\177")
-        buf.write("\2\2\u00c5>\3\2\2\2\u00c6\u00c7\7$\2\2\u00c7@\3\2\2\2")
-        buf.write("\u00c8\u00c9\7?\2\2\u00c9B\3\2\2\2\u00ca\u00cb\7\60\2")
-        buf.write("\2\u00cbD\3\2\2\2\u00cc\u00cd\7.\2\2\u00cdF\3\2\2\2\u00ce")
-        buf.write("\u00cf\7=\2\2\u00cfH\3\2\2\2\u00d0\u00d1\7-\2\2\u00d1")
-        buf.write("J\3\2\2\2\u00d2\u00d3\7\u2214\2\2\u00d3L\3\2\2\2\u00d4")
-        buf.write("\u00d5\7,\2\2\u00d5N\3\2\2\2\u00d6\u00d7\7\61\2\2\u00d7")
-        buf.write("P\3\2\2\2\u00d8\u00d9\7?\2\2\u00d9\u00da\7?\2\2\u00da")
-        buf.write("R\3\2\2\2\u00db\u00dc\7>\2\2\u00dcT\3\2\2\2\u00dd\u00de")
-        buf.write("\7>\2\2\u00de\u00df\7?\2\2\u00dfV\3\2\2\2\u00e0\u00e1")
-        buf.write("\7@\2\2\u00e1\u00e2\7?\2\2\u00e2X\3\2\2\2\u00e3\u00e4")
-        buf.write("\7#\2\2\u00e4\u00e5\7?\2\2\u00e5Z\3\2\2\2\u00e6\u00e7")
-        buf.write("\7(\2\2\u00e7\u00e8\7(\2\2\u00e8\\\3\2\2\2\u00e9\u00ea")
-        buf.write("\7~\2\2\u00ea\u00eb\7~\2\2\u00eb^\3\2\2\2\u00ec\u00ed")
-        buf.write("\7%\2\2\u00ed\u00ee\7Q\2\2\u00ee\u00ef\7R\2\2\u00ef\u00f0")
-        buf.write("\7>\2\2\u00f0`\3\2\2\2\u00f1\u00f3\t\2\2\2\u00f2\u00f1")
-        buf.write("\3\2\2\2\u00f3\u00f4\3\2\2\2\u00f4\u00f2\3\2\2\2\u00f4")
-        buf.write("\u00f5\3\2\2\2\u00f5\u00f6\3\2\2\2\u00f6\u00f7\b\61\2")
-        buf.write("\2\u00f7b\3\2\2\2\4\2\u00f4\3\b\2\2")
+        buf.write("\4&\t&\4\'\t\'\4(\t(\4)\t)\4*\t*\3\2\3\2\3\2\3\3\3\3\3")
+        buf.write("\4\3\4\3\4\3\5\3\5\3\5\3\5\3\5\3\6\3\6\3\6\3\6\3\7\3\7")
+        buf.write("\3\7\3\7\3\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\t\3")
+        buf.write("\t\3\t\3\t\3\t\3\t\3\t\3\n\3\n\3\n\3\n\3\n\3\13\3\13\3")
+        buf.write("\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17\3\20\3\20\3\21\3\21")
+        buf.write("\3\22\3\22\3\23\3\23\3\24\3\24\3\25\3\25\3\26\3\26\3\26")
+        buf.write("\3\26\3\26\3\27\3\27\3\30\3\30\3\30\3\30\3\30\3\30\3\31")
+        buf.write("\3\31\3\31\3\31\3\31\3\31\3\31\3\32\3\32\3\32\3\32\3\32")
+        buf.write("\3\33\3\33\3\33\3\33\3\33\3\33\3\34\3\34\3\34\3\34\3\34")
+        buf.write("\3\34\3\34\3\35\3\35\3\35\3\35\3\35\3\36\3\36\3\36\3\36")
+        buf.write("\3\36\3\36\3\37\3\37\3\37\3\37\3\37\3\37\3\37\3 \3 \3")
+        buf.write("!\3!\3\"\3\"\3#\3#\3$\3$\3%\3%\3&\3&\3\'\3\'\3(\3(\3)")
+        buf.write("\3)\3*\6*\u00e4\n*\r*\16*\u00e5\3*\3*\2\2+\3\3\5\4\7\5")
+        buf.write("\t\6\13\7\r\b\17\t\21\n\23\13\25\f\27\r\31\16\33\17\35")
+        buf.write("\20\37\21!\22#\23%\24\'\25)\26+\27-\30/\31\61\32\63\33")
+        buf.write("\65\34\67\359\36;\37= ?!A\"C#E$G%I&K\'M(O)Q*S+\3\2\3\5")
+        buf.write("\2\13\f\17\17\"\"\2\u00e9\2\3\3\2\2\2\2\5\3\2\2\2\2\7")
+        buf.write("\3\2\2\2\2\t\3\2\2\2\2\13\3\2\2\2\2\r\3\2\2\2\2\17\3\2")
+        buf.write("\2\2\2\21\3\2\2\2\2\23\3\2\2\2\2\25\3\2\2\2\2\27\3\2\2")
+        buf.write("\2\2\31\3\2\2\2\2\33\3\2\2\2\2\35\3\2\2\2\2\37\3\2\2\2")
+        buf.write("\2!\3\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2\'\3\2\2\2\2)\3\2\2")
+        buf.write("\2\2+\3\2\2\2\2-\3\2\2\2\2/\3\2\2\2\2\61\3\2\2\2\2\63")
+        buf.write("\3\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\29\3\2\2\2\2;\3\2\2")
+        buf.write("\2\2=\3\2\2\2\2?\3\2\2\2\2A\3\2\2\2\2C\3\2\2\2\2E\3\2")
+        buf.write("\2\2\2G\3\2\2\2\2I\3\2\2\2\2K\3\2\2\2\2M\3\2\2\2\2O\3")
+        buf.write("\2\2\2\2Q\3\2\2\2\2S\3\2\2\2\3U\3\2\2\2\5X\3\2\2\2\7Z")
+        buf.write("\3\2\2\2\t]\3\2\2\2\13b\3\2\2\2\rf\3\2\2\2\17n\3\2\2\2")
+        buf.write("\21t\3\2\2\2\23{\3\2\2\2\25\u0080\3\2\2\2\27\u0082\3\2")
+        buf.write("\2\2\31\u0084\3\2\2\2\33\u0086\3\2\2\2\35\u0088\3\2\2")
+        buf.write("\2\37\u008a\3\2\2\2!\u008c\3\2\2\2#\u008e\3\2\2\2%\u0090")
+        buf.write("\3\2\2\2\'\u0092\3\2\2\2)\u0094\3\2\2\2+\u0096\3\2\2\2")
+        buf.write("-\u009b\3\2\2\2/\u009d\3\2\2\2\61\u00a3\3\2\2\2\63\u00aa")
+        buf.write("\3\2\2\2\65\u00af\3\2\2\2\67\u00b5\3\2\2\29\u00bc\3\2")
+        buf.write("\2\2;\u00c1\3\2\2\2=\u00c7\3\2\2\2?\u00ce\3\2\2\2A\u00d0")
+        buf.write("\3\2\2\2C\u00d2\3\2\2\2E\u00d4\3\2\2\2G\u00d6\3\2\2\2")
+        buf.write("I\u00d8\3\2\2\2K\u00da\3\2\2\2M\u00dc\3\2\2\2O\u00de\3")
+        buf.write("\2\2\2Q\u00e0\3\2\2\2S\u00e3\3\2\2\2UV\7/\2\2VW\7@\2\2")
+        buf.write("W\4\3\2\2\2XY\7a\2\2Y\6\3\2\2\2Z[\7k\2\2[\\\7h\2\2\\\b")
+        buf.write("\3\2\2\2]^\7g\2\2^_\7n\2\2_`\7u\2\2`a\7g\2\2a\n\3\2\2")
+        buf.write("\2bc\7h\2\2cd\7q\2\2de\7t\2\2e\f\3\2\2\2fg\7h\2\2gh\7")
+        buf.write("q\2\2hi\7t\2\2ij\7G\2\2jk\7c\2\2kl\7e\2\2lm\7j\2\2m\16")
+        buf.write("\3\2\2\2no\7y\2\2op\7j\2\2pq\7k\2\2qr\7n\2\2rs\7g\2\2")
+        buf.write("s\20\3\2\2\2tu\7t\2\2uv\7g\2\2vw\7v\2\2wx\7w\2\2xy\7t")
+        buf.write("\2\2yz\7p\2\2z\22\3\2\2\2{|\7P\2\2|}\7W\2\2}~\7N\2\2~")
+        buf.write("\177\7N\2\2\177\24\3\2\2\2\u0080\u0081\7*\2\2\u0081\26")
+        buf.write("\3\2\2\2\u0082\u0083\7+\2\2\u0083\30\3\2\2\2\u0084\u0085")
+        buf.write("\7]\2\2\u0085\32\3\2\2\2\u0086\u0087\7_\2\2\u0087\34\3")
+        buf.write("\2\2\2\u0088\u0089\7}\2\2\u0089\36\3\2\2\2\u008a\u008b")
+        buf.write("\7\177\2\2\u008b \3\2\2\2\u008c\u008d\7$\2\2\u008d\"\3")
+        buf.write("\2\2\2\u008e\u008f\7?\2\2\u008f$\3\2\2\2\u0090\u0091\7")
+        buf.write("\60\2\2\u0091&\3\2\2\2\u0092\u0093\7.\2\2\u0093(\3\2\2")
+        buf.write("\2\u0094\u0095\7=\2\2\u0095*\3\2\2\2\u0096\u0097\7%\2")
+        buf.write("\2\u0097\u0098\7K\2\2\u0098\u0099\7F\2\2\u0099\u009a\7")
+        buf.write(">\2\2\u009a,\3\2\2\2\u009b\u009c\7@\2\2\u009c.\3\2\2\2")
+        buf.write("\u009d\u009e\7%\2\2\u009e\u009f\7K\2\2\u009f\u00a0\7F")
+        buf.write("\2\2\u00a0\u00a1\7>\2\2\u00a1\u00a2\7#\2\2\u00a2\60\3")
+        buf.write("\2\2\2\u00a3\u00a4\7%\2\2\u00a4\u00a5\7K\2\2\u00a5\u00a6")
+        buf.write("\7F\2\2\u00a6\u00a7\7>\2\2\u00a7\u00a8\7\60\2\2\u00a8")
+        buf.write("\u00a9\7@\2\2\u00a9\62\3\2\2\2\u00aa\u00ab\7%\2\2\u00ab")
+        buf.write("\u00ac\7Q\2\2\u00ac\u00ad\7R\2\2\u00ad\u00ae\7>\2\2\u00ae")
+        buf.write("\64\3\2\2\2\u00af\u00b0\7%\2\2\u00b0\u00b1\7Q\2\2\u00b1")
+        buf.write("\u00b2\7R\2\2\u00b2\u00b3\7>\2\2\u00b3\u00b4\7#\2\2\u00b4")
+        buf.write("\66\3\2\2\2\u00b5\u00b6\7%\2\2\u00b6\u00b7\7Q\2\2\u00b7")
+        buf.write("\u00b8\7R\2\2\u00b8\u00b9\7>\2\2\u00b9\u00ba\7\60\2\2")
+        buf.write("\u00ba\u00bb\7@\2\2\u00bb8\3\2\2\2\u00bc\u00bd\7%\2\2")
+        buf.write("\u00bd\u00be\7N\2\2\u00be\u00bf\7V\2\2\u00bf\u00c0\7>")
+        buf.write("\2\2\u00c0:\3\2\2\2\u00c1\u00c2\7%\2\2\u00c2\u00c3\7N")
+        buf.write("\2\2\u00c3\u00c4\7V\2\2\u00c4\u00c5\7>\2\2\u00c5\u00c6")
+        buf.write("\7#\2\2\u00c6<\3\2\2\2\u00c7\u00c8\7%\2\2\u00c8\u00c9")
+        buf.write("\7N\2\2\u00c9\u00ca\7V\2\2\u00ca\u00cb\7>\2\2\u00cb\u00cc")
+        buf.write("\7\60\2\2\u00cc\u00cd\7@\2\2\u00cd>\3\2\2\2\u00ce\u00cf")
+        buf.write("\7\62\2\2\u00cf@\3\2\2\2\u00d0\u00d1\7\63\2\2\u00d1B\3")
+        buf.write("\2\2\2\u00d2\u00d3\7\64\2\2\u00d3D\3\2\2\2\u00d4\u00d5")
+        buf.write("\7\65\2\2\u00d5F\3\2\2\2\u00d6\u00d7\7\66\2\2\u00d7H\3")
+        buf.write("\2\2\2\u00d8\u00d9\7\67\2\2\u00d9J\3\2\2\2\u00da\u00db")
+        buf.write("\78\2\2\u00dbL\3\2\2\2\u00dc\u00dd\79\2\2\u00ddN\3\2\2")
+        buf.write("\2\u00de\u00df\7:\2\2\u00dfP\3\2\2\2\u00e0\u00e1\7;\2")
+        buf.write("\2\u00e1R\3\2\2\2\u00e2\u00e4\t\2\2\2\u00e3\u00e2\3\2")
+        buf.write("\2\2\u00e4\u00e5\3\2\2\2\u00e5\u00e3\3\2\2\2\u00e5\u00e6")
+        buf.write("\3\2\2\2\u00e6\u00e7\3\2\2\2\u00e7\u00e8\b*\2\2\u00e8")
+        buf.write("T\3\2\2\2\4\2\u00e5\3\b\2\2")
         return buf.getvalue()
 
 
@@ -151,26 +144,19 @@ class SearchLexer(Lexer):
     T__37 = 38
     T__38 = 39
     T__39 = 40
-    T__40 = 41
-    T__41 = 42
-    T__42 = 43
-    T__43 = 44
-    T__44 = 45
-    T__45 = 46
-    T__46 = 47
-    WS = 48
+    WS = 41
 
     channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]
 
     modeNames = [ "DEFAULT_MODE" ]
 
     literalNames = [ "<INVALID>",
-            "'->'", "'_'", "'#ID<'", "'>'", "'#N<'", "'#ID<.>'", "'#N<.>'", 
-            "'0'", "'1'", "'2'", "'3'", "'4'", "'5'", "'6'", "'7'", "'8'", 
-            "'9'", "'if'", "'else'", "'for'", "'forEach'", "'while'", "'return'", 
-            "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", 
-            "'='", "'.'", "','", "';'", "'+'", "'\u2212'", "'*'", "'/'", 
-            "'=='", "'<'", "'<='", "'>='", "'!='", "'&&'", "'||'", "'#OP<'" ]
+            "'->'", "'_'", "'if'", "'else'", "'for'", "'forEach'", "'while'", 
+            "'return'", "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", 
+            "'\"'", "'='", "'.'", "','", "';'", "'#ID<'", "'>'", "'#ID<!'", 
+            "'#ID<.>'", "'#OP<'", "'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", 
+            "'#LT<.>'", "'0'", "'1'", "'2'", "'3'", "'4'", "'5'", "'6'", 
+            "'7'", "'8'", "'9'" ]
 
     symbolicNames = [ "<INVALID>",
             "WS" ]
@@ -181,8 +167,7 @@ class SearchLexer(Lexer):
                   "T__20", "T__21", "T__22", "T__23", "T__24", "T__25", 
                   "T__26", "T__27", "T__28", "T__29", "T__30", "T__31", 
                   "T__32", "T__33", "T__34", "T__35", "T__36", "T__37", 
-                  "T__38", "T__39", "T__40", "T__41", "T__42", "T__43", 
-                  "T__44", "T__45", "T__46", "WS" ]
+                  "T__38", "T__39", "WS" ]
 
     grammarFileName = "Search.g4"
 
diff --git a/code/antlr4/SearchListener.py b/code/antlr4/SearchListener.py
index 1879435..41f83c2 100644
--- a/code/antlr4/SearchListener.py
+++ b/code/antlr4/SearchListener.py
@@ -17,12 +17,12 @@ class SearchListener(ParseTreeListener):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#expr.
-    def enterExpr(self, ctx:SearchParser.ExprContext):
+    # Enter a parse tree produced by SearchParser#code.
+    def enterCode(self, ctx:SearchParser.CodeContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#expr.
-    def exitExpr(self, ctx:SearchParser.ExprContext):
+    # Exit a parse tree produced by SearchParser#code.
+    def exitCode(self, ctx:SearchParser.CodeContext):
         pass
 
 
@@ -35,48 +35,57 @@ class SearchListener(ParseTreeListener):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#identifier.
-    def enterIdentifier(self, ctx:SearchParser.IdentifierContext):
+    # Enter a parse tree produced by SearchParser#keyword.
+    def enterKeyword(self, ctx:SearchParser.KeywordContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#identifier.
-    def exitIdentifier(self, ctx:SearchParser.IdentifierContext):
+    # Exit a parse tree produced by SearchParser#keyword.
+    def exitKeyword(self, ctx:SearchParser.KeywordContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#digit.
-    def enterDigit(self, ctx:SearchParser.DigitContext):
+    # Enter a parse tree produced by SearchParser#punctuator.
+    def enterPunctuator(self, ctx:SearchParser.PunctuatorContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#digit.
-    def exitDigit(self, ctx:SearchParser.DigitContext):
+    # Exit a parse tree produced by SearchParser#punctuator.
+    def exitPunctuator(self, ctx:SearchParser.PunctuatorContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#keyword.
-    def enterKeyword(self, ctx:SearchParser.KeywordContext):
+    # Enter a parse tree produced by SearchParser#identifier.
+    def enterIdentifier(self, ctx:SearchParser.IdentifierContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#keyword.
-    def exitKeyword(self, ctx:SearchParser.KeywordContext):
+    # Exit a parse tree produced by SearchParser#identifier.
+    def exitIdentifier(self, ctx:SearchParser.IdentifierContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#punctuator.
-    def enterPunctuator(self, ctx:SearchParser.PunctuatorContext):
+    # Enter a parse tree produced by SearchParser#operator.
+    def enterOperator(self, ctx:SearchParser.OperatorContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#punctuator.
-    def exitPunctuator(self, ctx:SearchParser.PunctuatorContext):
+    # Exit a parse tree produced by SearchParser#operator.
+    def exitOperator(self, ctx:SearchParser.OperatorContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#op.
-    def enterOp(self, ctx:SearchParser.OpContext):
+    # Enter a parse tree produced by SearchParser#literal.
+    def enterLiteral(self, ctx:SearchParser.LiteralContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#op.
-    def exitOp(self, ctx:SearchParser.OpContext):
+    # Exit a parse tree produced by SearchParser#literal.
+    def exitLiteral(self, ctx:SearchParser.LiteralContext):
+        pass
+
+
+    # Enter a parse tree produced by SearchParser#digit.
+    def enterDigit(self, ctx:SearchParser.DigitContext):
+        pass
+
+    # Exit a parse tree produced by SearchParser#digit.
+    def exitDigit(self, ctx:SearchParser.DigitContext):
         pass
 
 
diff --git a/code/antlr4/SearchParser.py b/code/antlr4/SearchParser.py
index 64b4fa5..800cb84 100644
--- a/code/antlr4/SearchParser.py
+++ b/code/antlr4/SearchParser.py
@@ -7,48 +7,54 @@ import sys
 
 def serializedATN():
     with StringIO() as buf:
-        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3\62")
-        buf.write("y\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7\4\b")
-        buf.write("\t\b\4\t\t\t\3\2\3\2\3\2\3\2\3\3\7\3\30\n\3\f\3\16\3\33")
-        buf.write("\13\3\3\4\3\4\3\4\3\4\3\4\5\4\"\n\4\3\5\3\5\7\5&\n\5\f")
-        buf.write("\5\16\5)\13\5\3\5\3\5\3\5\7\5.\n\5\f\5\16\5\61\13\5\3")
-        buf.write("\5\3\5\3\5\5\5\66\n\5\3\6\3\6\3\7\3\7\3\b\3\b\7\b>\n\b")
-        buf.write("\f\b\16\bA\13\b\3\b\3\b\3\b\7\bF\n\b\f\b\16\bI\13\b\3")
-        buf.write("\b\3\b\3\b\7\bN\n\b\f\b\16\bQ\13\b\3\b\3\b\3\b\7\bV\n")
-        buf.write("\b\f\b\16\bY\13\b\3\b\3\b\3\b\3\b\3\b\5\b`\n\b\3\t\3\t")
-        buf.write("\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\7")
-        buf.write("\tq\n\t\f\t\16\tt\13\t\3\t\5\tw\n\t\3\t\2\2\n\2\4\6\b")
-        buf.write("\n\f\16\20\2\4\3\2\n\23\3\2\24\32\2\u0093\2\22\3\2\2\2")
-        buf.write("\4\31\3\2\2\2\6!\3\2\2\2\b\65\3\2\2\2\n\67\3\2\2\2\f9")
-        buf.write("\3\2\2\2\16_\3\2\2\2\20v\3\2\2\2\22\23\5\4\3\2\23\24\7")
-        buf.write("\3\2\2\24\25\5\4\3\2\25\3\3\2\2\2\26\30\5\6\4\2\27\26")
-        buf.write("\3\2\2\2\30\33\3\2\2\2\31\27\3\2\2\2\31\32\3\2\2\2\32")
-        buf.write("\5\3\2\2\2\33\31\3\2\2\2\34\"\5\b\5\2\35\"\5\f\7\2\36")
-        buf.write("\"\5\16\b\2\37\"\5\20\t\2 \"\7\4\2\2!\34\3\2\2\2!\35\3")
-        buf.write("\2\2\2!\36\3\2\2\2!\37\3\2\2\2! \3\2\2\2\"\7\3\2\2\2#")
-        buf.write("\'\7\5\2\2$&\5\n\6\2%$\3\2\2\2&)\3\2\2\2\'%\3\2\2\2\'")
-        buf.write("(\3\2\2\2(*\3\2\2\2)\'\3\2\2\2*\66\7\6\2\2+/\7\7\2\2,")
-        buf.write(".\5\n\6\2-,\3\2\2\2.\61\3\2\2\2/-\3\2\2\2/\60\3\2\2\2")
-        buf.write("\60\62\3\2\2\2\61/\3\2\2\2\62\66\7\6\2\2\63\66\7\b\2\2")
-        buf.write("\64\66\7\t\2\2\65#\3\2\2\2\65+\3\2\2\2\65\63\3\2\2\2\65")
-        buf.write("\64\3\2\2\2\66\t\3\2\2\2\678\t\2\2\28\13\3\2\2\29:\t\3")
-        buf.write("\2\2:\r\3\2\2\2;?\7\33\2\2<>\5\6\4\2=<\3\2\2\2>A\3\2\2")
-        buf.write("\2?=\3\2\2\2?@\3\2\2\2@B\3\2\2\2A?\3\2\2\2B`\7\34\2\2")
-        buf.write("CG\7\35\2\2DF\5\6\4\2ED\3\2\2\2FI\3\2\2\2GE\3\2\2\2GH")
-        buf.write("\3\2\2\2HJ\3\2\2\2IG\3\2\2\2J`\7\36\2\2KO\7\37\2\2LN\5")
-        buf.write("\6\4\2ML\3\2\2\2NQ\3\2\2\2OM\3\2\2\2OP\3\2\2\2PR\3\2\2")
-        buf.write("\2QO\3\2\2\2R`\7 \2\2SW\7!\2\2TV\5\6\4\2UT\3\2\2\2VY\3")
-        buf.write("\2\2\2WU\3\2\2\2WX\3\2\2\2XZ\3\2\2\2YW\3\2\2\2Z`\7!\2")
-        buf.write("\2[`\7\"\2\2\\`\7#\2\2]`\7$\2\2^`\7%\2\2_;\3\2\2\2_C\3")
-        buf.write("\2\2\2_K\3\2\2\2_S\3\2\2\2_[\3\2\2\2_\\\3\2\2\2_]\3\2")
-        buf.write("\2\2_^\3\2\2\2`\17\3\2\2\2aw\7&\2\2bw\7\'\2\2cw\7(\2\2")
-        buf.write("dw\7)\2\2ew\7*\2\2fw\7+\2\2gw\7\6\2\2hw\7,\2\2iw\7-\2")
-        buf.write("\2jw\7*\2\2kw\7.\2\2lw\7/\2\2mw\7\60\2\2nr\7\61\2\2oq")
-        buf.write("\5\n\6\2po\3\2\2\2qt\3\2\2\2rp\3\2\2\2rs\3\2\2\2su\3\2")
-        buf.write("\2\2tr\3\2\2\2uw\7\6\2\2va\3\2\2\2vb\3\2\2\2vc\3\2\2\2")
-        buf.write("vd\3\2\2\2ve\3\2\2\2vf\3\2\2\2vg\3\2\2\2vh\3\2\2\2vi\3")
-        buf.write("\2\2\2vj\3\2\2\2vk\3\2\2\2vl\3\2\2\2vm\3\2\2\2vn\3\2\2")
-        buf.write("\2w\21\3\2\2\2\16\31!\'/\65?GOW_rv")
+        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3+")
+        buf.write("\u008a\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7")
+        buf.write("\4\b\t\b\4\t\t\t\4\n\t\n\3\2\3\2\3\2\3\2\3\3\7\3\32\n")
+        buf.write("\3\f\3\16\3\35\13\3\3\4\3\4\3\4\3\4\3\4\3\4\5\4%\n\4\3")
+        buf.write("\5\3\5\3\6\3\6\7\6+\n\6\f\6\16\6.\13\6\3\6\3\6\3\6\7\6")
+        buf.write("\63\n\6\f\6\16\6\66\13\6\3\6\3\6\3\6\7\6;\n\6\f\6\16\6")
+        buf.write(">\13\6\3\6\3\6\3\6\7\6C\n\6\f\6\16\6F\13\6\3\6\3\6\3\6")
+        buf.write("\3\6\3\6\5\6M\n\6\3\7\3\7\7\7Q\n\7\f\7\16\7T\13\7\3\7")
+        buf.write("\3\7\3\7\7\7Y\n\7\f\7\16\7\\\13\7\3\7\3\7\5\7`\n\7\3\b")
+        buf.write("\3\b\7\bd\n\b\f\b\16\bg\13\b\3\b\3\b\3\b\7\bl\n\b\f\b")
+        buf.write("\16\bo\13\b\3\b\3\b\5\bs\n\b\3\t\3\t\7\tw\n\t\f\t\16\t")
+        buf.write("z\13\t\3\t\3\t\3\t\7\t\177\n\t\f\t\16\t\u0082\13\t\3\t")
+        buf.write("\3\t\5\t\u0086\n\t\3\n\3\n\3\n\2\2\13\2\4\6\b\n\f\16\20")
+        buf.write("\22\2\4\3\2\5\13\3\2!*\2\u009d\2\24\3\2\2\2\4\33\3\2\2")
+        buf.write("\2\6$\3\2\2\2\b&\3\2\2\2\nL\3\2\2\2\f_\3\2\2\2\16r\3\2")
+        buf.write("\2\2\20\u0085\3\2\2\2\22\u0087\3\2\2\2\24\25\5\4\3\2\25")
+        buf.write("\26\7\3\2\2\26\27\5\4\3\2\27\3\3\2\2\2\30\32\5\6\4\2\31")
+        buf.write("\30\3\2\2\2\32\35\3\2\2\2\33\31\3\2\2\2\33\34\3\2\2\2")
+        buf.write("\34\5\3\2\2\2\35\33\3\2\2\2\36%\5\f\7\2\37%\5\b\5\2 %")
+        buf.write("\5\n\6\2!%\5\16\b\2\"%\5\20\t\2#%\7\4\2\2$\36\3\2\2\2")
+        buf.write("$\37\3\2\2\2$ \3\2\2\2$!\3\2\2\2$\"\3\2\2\2$#\3\2\2\2")
+        buf.write("%\7\3\2\2\2&\'\t\2\2\2\'\t\3\2\2\2(,\7\f\2\2)+\5\6\4\2")
+        buf.write("*)\3\2\2\2+.\3\2\2\2,*\3\2\2\2,-\3\2\2\2-/\3\2\2\2.,\3")
+        buf.write("\2\2\2/M\7\r\2\2\60\64\7\16\2\2\61\63\5\6\4\2\62\61\3")
+        buf.write("\2\2\2\63\66\3\2\2\2\64\62\3\2\2\2\64\65\3\2\2\2\65\67")
+        buf.write("\3\2\2\2\66\64\3\2\2\2\67M\7\17\2\28<\7\20\2\29;\5\6\4")
+        buf.write("\2:9\3\2\2\2;>\3\2\2\2<:\3\2\2\2<=\3\2\2\2=?\3\2\2\2>")
+        buf.write("<\3\2\2\2?M\7\21\2\2@D\7\22\2\2AC\5\6\4\2BA\3\2\2\2CF")
+        buf.write("\3\2\2\2DB\3\2\2\2DE\3\2\2\2EG\3\2\2\2FD\3\2\2\2GM\7\22")
+        buf.write("\2\2HM\7\23\2\2IM\7\24\2\2JM\7\25\2\2KM\7\26\2\2L(\3\2")
+        buf.write("\2\2L\60\3\2\2\2L8\3\2\2\2L@\3\2\2\2LH\3\2\2\2LI\3\2\2")
+        buf.write("\2LJ\3\2\2\2LK\3\2\2\2M\13\3\2\2\2NR\7\27\2\2OQ\5\22\n")
+        buf.write("\2PO\3\2\2\2QT\3\2\2\2RP\3\2\2\2RS\3\2\2\2SU\3\2\2\2T")
+        buf.write("R\3\2\2\2U`\7\30\2\2VZ\7\31\2\2WY\5\22\n\2XW\3\2\2\2Y")
+        buf.write("\\\3\2\2\2ZX\3\2\2\2Z[\3\2\2\2[]\3\2\2\2\\Z\3\2\2\2]`")
+        buf.write("\7\30\2\2^`\7\32\2\2_N\3\2\2\2_V\3\2\2\2_^\3\2\2\2`\r")
+        buf.write("\3\2\2\2ae\7\33\2\2bd\5\22\n\2cb\3\2\2\2dg\3\2\2\2ec\3")
+        buf.write("\2\2\2ef\3\2\2\2fh\3\2\2\2ge\3\2\2\2hs\7\30\2\2im\7\34")
+        buf.write("\2\2jl\5\22\n\2kj\3\2\2\2lo\3\2\2\2mk\3\2\2\2mn\3\2\2")
+        buf.write("\2np\3\2\2\2om\3\2\2\2ps\7\30\2\2qs\7\35\2\2ra\3\2\2\2")
+        buf.write("ri\3\2\2\2rq\3\2\2\2s\17\3\2\2\2tx\7\36\2\2uw\5\22\n\2")
+        buf.write("vu\3\2\2\2wz\3\2\2\2xv\3\2\2\2xy\3\2\2\2y{\3\2\2\2zx\3")
+        buf.write("\2\2\2{\u0086\7\30\2\2|\u0080\7\37\2\2}\177\5\22\n\2~")
+        buf.write("}\3\2\2\2\177\u0082\3\2\2\2\u0080~\3\2\2\2\u0080\u0081")
+        buf.write("\3\2\2\2\u0081\u0083\3\2\2\2\u0082\u0080\3\2\2\2\u0083")
+        buf.write("\u0086\7\30\2\2\u0084\u0086\7 \2\2\u0085t\3\2\2\2\u0085")
+        buf.write("|\3\2\2\2\u0085\u0084\3\2\2\2\u0086\21\3\2\2\2\u0087\u0088")
+        buf.write("\t\3\2\2\u0088\23\3\2\2\2\22\33$,\64<DLRZ_emrx\u0080\u0085")
         return buf.getvalue()
 
 
@@ -62,14 +68,13 @@ class SearchParser ( Parser ):
 
     sharedContextCache = PredictionContextCache()
 
-    literalNames = [ "<INVALID>", "'->'", "'_'", "'#ID<'", "'>'", "'#N<'", 
-                     "'#ID<.>'", "'#N<.>'", "'0'", "'1'", "'2'", "'3'", 
-                     "'4'", "'5'", "'6'", "'7'", "'8'", "'9'", "'if'", "'else'", 
-                     "'for'", "'forEach'", "'while'", "'return'", "'NULL'", 
-                     "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", "'='", 
-                     "'.'", "','", "';'", "'+'", "'\u2212'", "'*'", "'/'", 
-                     "'=='", "'<'", "'<='", "'>='", "'!='", "'&&'", "'||'", 
-                     "'#OP<'" ]
+    literalNames = [ "<INVALID>", "'->'", "'_'", "'if'", "'else'", "'for'", 
+                     "'forEach'", "'while'", "'return'", "'NULL'", "'('", 
+                     "')'", "'['", "']'", "'{'", "'}'", "'\"'", "'='", "'.'", 
+                     "','", "';'", "'#ID<'", "'>'", "'#ID<!'", "'#ID<.>'", 
+                     "'#OP<'", "'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", 
+                     "'#LT<.>'", "'0'", "'1'", "'2'", "'3'", "'4'", "'5'", 
+                     "'6'", "'7'", "'8'", "'9'" ]
 
     symbolicNames = [ "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
@@ -81,21 +86,20 @@ class SearchParser ( Parser ):
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
-                      "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
-                      "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
-                      "WS" ]
+                      "<INVALID>", "WS" ]
 
     RULE_query = 0
-    RULE_expr = 1
+    RULE_code = 1
     RULE_token = 2
-    RULE_identifier = 3
-    RULE_digit = 4
-    RULE_keyword = 5
-    RULE_punctuator = 6
-    RULE_op = 7
+    RULE_keyword = 3
+    RULE_punctuator = 4
+    RULE_identifier = 5
+    RULE_operator = 6
+    RULE_literal = 7
+    RULE_digit = 8
 
-    ruleNames =  [ "query", "expr", "token", "identifier", "digit", "keyword", 
-                   "punctuator", "op" ]
+    ruleNames =  [ "query", "code", "token", "keyword", "punctuator", "identifier", 
+                   "operator", "literal", "digit" ]
 
     EOF = Token.EOF
     T__0=1
@@ -138,14 +142,7 @@ class SearchParser ( Parser ):
     T__37=38
     T__38=39
     T__39=40
-    T__40=41
-    T__41=42
-    T__42=43
-    T__43=44
-    T__44=45
-    T__45=46
-    T__46=47
-    WS=48
+    WS=41
 
     def __init__(self, input:TokenStream, output:TextIO = sys.stdout):
         super().__init__(input, output)
@@ -161,11 +158,11 @@ class SearchParser ( Parser ):
             super().__init__(parent, invokingState)
             self.parser = parser
 
-        def expr(self, i:int=None):
+        def code(self, i:int=None):
             if i is None:
-                return self.getTypedRuleContexts(SearchParser.ExprContext)
+                return self.getTypedRuleContexts(SearchParser.CodeContext)
             else:
-                return self.getTypedRuleContext(SearchParser.ExprContext,i)
+                return self.getTypedRuleContext(SearchParser.CodeContext,i)
 
 
         def getRuleIndex(self):
@@ -188,12 +185,12 @@ class SearchParser ( Parser ):
         self.enterRule(localctx, 0, self.RULE_query)
         try:
             self.enterOuterAlt(localctx, 1)
-            self.state = 16
-            self.expr()
-            self.state = 17
-            self.match(SearchParser.T__0)
             self.state = 18
-            self.expr()
+            self.code()
+            self.state = 19
+            self.match(SearchParser.T__0)
+            self.state = 20
+            self.code()
         except RecognitionException as re:
             localctx.exception = re
             self._errHandler.reportError(self, re)
@@ -202,7 +199,7 @@ class SearchParser ( Parser ):
             self.exitRule()
         return localctx
 
-    class ExprContext(ParserRuleContext):
+    class CodeContext(ParserRuleContext):
 
         def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
             super().__init__(parent, invokingState)
@@ -216,33 +213,33 @@ class SearchParser ( Parser ):
 
 
         def getRuleIndex(self):
-            return SearchParser.RULE_expr
+            return SearchParser.RULE_code
 
         def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterExpr" ):
-                listener.enterExpr(self)
+            if hasattr( listener, "enterCode" ):
+                listener.enterCode(self)
 
         def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitExpr" ):
-                listener.exitExpr(self)
+            if hasattr( listener, "exitCode" ):
+                listener.exitCode(self)
 
 
 
 
-    def expr(self):
+    def code(self):
 
-        localctx = SearchParser.ExprContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 2, self.RULE_expr)
+        localctx = SearchParser.CodeContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 2, self.RULE_code)
         self._la = 0 # Token type
         try:
             self.enterOuterAlt(localctx, 1)
-            self.state = 23
+            self.state = 25
             self._errHandler.sync(self)
             _la = self._input.LA(1)
-            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                self.state = 20
+            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                self.state = 22
                 self.token()
-                self.state = 25
+                self.state = 27
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
 
@@ -272,8 +269,12 @@ class SearchParser ( Parser ):
             return self.getTypedRuleContext(SearchParser.PunctuatorContext,0)
 
 
-        def op(self):
-            return self.getTypedRuleContext(SearchParser.OpContext,0)
+        def operator(self):
+            return self.getTypedRuleContext(SearchParser.OperatorContext,0)
+
+
+        def literal(self):
+            return self.getTypedRuleContext(SearchParser.LiteralContext,0)
 
 
         def getRuleIndex(self):
@@ -295,124 +296,38 @@ class SearchParser ( Parser ):
         localctx = SearchParser.TokenContext(self, self._ctx, self.state)
         self.enterRule(localctx, 4, self.RULE_token)
         try:
-            self.state = 31
+            self.state = 34
             self._errHandler.sync(self)
             token = self._input.LA(1)
-            if token in [SearchParser.T__2, SearchParser.T__4, SearchParser.T__5, SearchParser.T__6]:
+            if token in [SearchParser.T__20, SearchParser.T__22, SearchParser.T__23]:
                 self.enterOuterAlt(localctx, 1)
-                self.state = 26
+                self.state = 28
                 self.identifier()
                 pass
-            elif token in [SearchParser.T__17, SearchParser.T__18, SearchParser.T__19, SearchParser.T__20, SearchParser.T__21, SearchParser.T__22, SearchParser.T__23]:
+            elif token in [SearchParser.T__2, SearchParser.T__3, SearchParser.T__4, SearchParser.T__5, SearchParser.T__6, SearchParser.T__7, SearchParser.T__8]:
                 self.enterOuterAlt(localctx, 2)
-                self.state = 27
+                self.state = 29
                 self.keyword()
                 pass
-            elif token in [SearchParser.T__24, SearchParser.T__26, SearchParser.T__28, SearchParser.T__30, SearchParser.T__31, SearchParser.T__32, SearchParser.T__33, SearchParser.T__34]:
+            elif token in [SearchParser.T__9, SearchParser.T__11, SearchParser.T__13, SearchParser.T__15, SearchParser.T__16, SearchParser.T__17, SearchParser.T__18, SearchParser.T__19]:
                 self.enterOuterAlt(localctx, 3)
-                self.state = 28
+                self.state = 30
                 self.punctuator()
                 pass
-            elif token in [SearchParser.T__3, SearchParser.T__35, SearchParser.T__36, SearchParser.T__37, SearchParser.T__38, SearchParser.T__39, SearchParser.T__40, SearchParser.T__41, SearchParser.T__42, SearchParser.T__43, SearchParser.T__44, SearchParser.T__45, SearchParser.T__46]:
+            elif token in [SearchParser.T__24, SearchParser.T__25, SearchParser.T__26]:
                 self.enterOuterAlt(localctx, 4)
-                self.state = 29
-                self.op()
+                self.state = 31
+                self.operator()
                 pass
-            elif token in [SearchParser.T__1]:
+            elif token in [SearchParser.T__27, SearchParser.T__28, SearchParser.T__29]:
                 self.enterOuterAlt(localctx, 5)
-                self.state = 30
-                self.match(SearchParser.T__1)
+                self.state = 32
+                self.literal()
                 pass
-            else:
-                raise NoViableAltException(self)
-
-        except RecognitionException as re:
-            localctx.exception = re
-            self._errHandler.reportError(self, re)
-            self._errHandler.recover(self, re)
-        finally:
-            self.exitRule()
-        return localctx
-
-    class IdentifierContext(ParserRuleContext):
-
-        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
-            super().__init__(parent, invokingState)
-            self.parser = parser
-
-        def digit(self, i:int=None):
-            if i is None:
-                return self.getTypedRuleContexts(SearchParser.DigitContext)
-            else:
-                return self.getTypedRuleContext(SearchParser.DigitContext,i)
-
-
-        def getRuleIndex(self):
-            return SearchParser.RULE_identifier
-
-        def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterIdentifier" ):
-                listener.enterIdentifier(self)
-
-        def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitIdentifier" ):
-                listener.exitIdentifier(self)
-
-
-
-
-    def identifier(self):
-
-        localctx = SearchParser.IdentifierContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 6, self.RULE_identifier)
-        self._la = 0 # Token type
-        try:
-            self.state = 51
-            self._errHandler.sync(self)
-            token = self._input.LA(1)
-            if token in [SearchParser.T__2]:
-                self.enterOuterAlt(localctx, 1)
+            elif token in [SearchParser.T__1]:
+                self.enterOuterAlt(localctx, 6)
                 self.state = 33
-                self.match(SearchParser.T__2)
-                self.state = 37
-                self._errHandler.sync(self)
-                _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0):
-                    self.state = 34
-                    self.digit()
-                    self.state = 39
-                    self._errHandler.sync(self)
-                    _la = self._input.LA(1)
-
-                self.state = 40
-                self.match(SearchParser.T__3)
-                pass
-            elif token in [SearchParser.T__4]:
-                self.enterOuterAlt(localctx, 2)
-                self.state = 41
-                self.match(SearchParser.T__4)
-                self.state = 45
-                self._errHandler.sync(self)
-                _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0):
-                    self.state = 42
-                    self.digit()
-                    self.state = 47
-                    self._errHandler.sync(self)
-                    _la = self._input.LA(1)
-
-                self.state = 48
-                self.match(SearchParser.T__3)
-                pass
-            elif token in [SearchParser.T__5]:
-                self.enterOuterAlt(localctx, 3)
-                self.state = 49
-                self.match(SearchParser.T__5)
-                pass
-            elif token in [SearchParser.T__6]:
-                self.enterOuterAlt(localctx, 4)
-                self.state = 50
-                self.match(SearchParser.T__6)
+                self.match(SearchParser.T__1)
                 pass
             else:
                 raise NoViableAltException(self)
@@ -425,49 +340,6 @@ class SearchParser ( Parser ):
             self.exitRule()
         return localctx
 
-    class DigitContext(ParserRuleContext):
-
-        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
-            super().__init__(parent, invokingState)
-            self.parser = parser
-
-
-        def getRuleIndex(self):
-            return SearchParser.RULE_digit
-
-        def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterDigit" ):
-                listener.enterDigit(self)
-
-        def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitDigit" ):
-                listener.exitDigit(self)
-
-
-
-
-    def digit(self):
-
-        localctx = SearchParser.DigitContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 8, self.RULE_digit)
-        self._la = 0 # Token type
-        try:
-            self.enterOuterAlt(localctx, 1)
-            self.state = 53
-            _la = self._input.LA(1)
-            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0)):
-                self._errHandler.recoverInline(self)
-            else:
-                self._errHandler.reportMatch(self)
-                self.consume()
-        except RecognitionException as re:
-            localctx.exception = re
-            self._errHandler.reportError(self, re)
-            self._errHandler.recover(self, re)
-        finally:
-            self.exitRule()
-        return localctx
-
     class KeywordContext(ParserRuleContext):
 
         def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
@@ -492,13 +364,13 @@ class SearchParser ( Parser ):
     def keyword(self):
 
         localctx = SearchParser.KeywordContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 10, self.RULE_keyword)
+        self.enterRule(localctx, 6, self.RULE_keyword)
         self._la = 0 # Token type
         try:
             self.enterOuterAlt(localctx, 1)
-            self.state = 55
+            self.state = 36
             _la = self._input.LA(1)
-            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23))) != 0)):
+            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8))) != 0)):
                 self._errHandler.recoverInline(self)
             else:
                 self._errHandler.reportMatch(self)
@@ -541,100 +413,100 @@ class SearchParser ( Parser ):
     def punctuator(self):
 
         localctx = SearchParser.PunctuatorContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 12, self.RULE_punctuator)
+        self.enterRule(localctx, 8, self.RULE_punctuator)
         self._la = 0 # Token type
         try:
-            self.state = 93
+            self.state = 74
             self._errHandler.sync(self)
             token = self._input.LA(1)
-            if token in [SearchParser.T__24]:
+            if token in [SearchParser.T__9]:
                 self.enterOuterAlt(localctx, 1)
-                self.state = 57
-                self.match(SearchParser.T__24)
-                self.state = 61
+                self.state = 38
+                self.match(SearchParser.T__9)
+                self.state = 42
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                    self.state = 58
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                    self.state = 39
                     self.token()
-                    self.state = 63
+                    self.state = 44
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 64
-                self.match(SearchParser.T__25)
+                self.state = 45
+                self.match(SearchParser.T__10)
                 pass
-            elif token in [SearchParser.T__26]:
+            elif token in [SearchParser.T__11]:
                 self.enterOuterAlt(localctx, 2)
-                self.state = 65
-                self.match(SearchParser.T__26)
-                self.state = 69
+                self.state = 46
+                self.match(SearchParser.T__11)
+                self.state = 50
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                    self.state = 66
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                    self.state = 47
                     self.token()
-                    self.state = 71
+                    self.state = 52
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 72
-                self.match(SearchParser.T__27)
+                self.state = 53
+                self.match(SearchParser.T__12)
                 pass
-            elif token in [SearchParser.T__28]:
+            elif token in [SearchParser.T__13]:
                 self.enterOuterAlt(localctx, 3)
-                self.state = 73
-                self.match(SearchParser.T__28)
-                self.state = 77
+                self.state = 54
+                self.match(SearchParser.T__13)
+                self.state = 58
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                    self.state = 74
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                    self.state = 55
                     self.token()
-                    self.state = 79
+                    self.state = 60
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 80
-                self.match(SearchParser.T__29)
+                self.state = 61
+                self.match(SearchParser.T__14)
                 pass
-            elif token in [SearchParser.T__30]:
+            elif token in [SearchParser.T__15]:
                 self.enterOuterAlt(localctx, 4)
-                self.state = 81
-                self.match(SearchParser.T__30)
-                self.state = 85
+                self.state = 62
+                self.match(SearchParser.T__15)
+                self.state = 66
                 self._errHandler.sync(self)
-                _alt = self._interp.adaptivePredict(self._input,8,self._ctx)
+                _alt = self._interp.adaptivePredict(self._input,5,self._ctx)
                 while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                     if _alt==1:
-                        self.state = 82
+                        self.state = 63
                         self.token() 
-                    self.state = 87
+                    self.state = 68
                     self._errHandler.sync(self)
-                    _alt = self._interp.adaptivePredict(self._input,8,self._ctx)
+                    _alt = self._interp.adaptivePredict(self._input,5,self._ctx)
 
-                self.state = 88
-                self.match(SearchParser.T__30)
+                self.state = 69
+                self.match(SearchParser.T__15)
                 pass
-            elif token in [SearchParser.T__31]:
+            elif token in [SearchParser.T__16]:
                 self.enterOuterAlt(localctx, 5)
-                self.state = 89
-                self.match(SearchParser.T__31)
+                self.state = 70
+                self.match(SearchParser.T__16)
                 pass
-            elif token in [SearchParser.T__32]:
+            elif token in [SearchParser.T__17]:
                 self.enterOuterAlt(localctx, 6)
-                self.state = 90
-                self.match(SearchParser.T__32)
+                self.state = 71
+                self.match(SearchParser.T__17)
                 pass
-            elif token in [SearchParser.T__33]:
+            elif token in [SearchParser.T__18]:
                 self.enterOuterAlt(localctx, 7)
-                self.state = 91
-                self.match(SearchParser.T__33)
+                self.state = 72
+                self.match(SearchParser.T__18)
                 pass
-            elif token in [SearchParser.T__34]:
+            elif token in [SearchParser.T__19]:
                 self.enterOuterAlt(localctx, 8)
-                self.state = 92
-                self.match(SearchParser.T__34)
+                self.state = 73
+                self.match(SearchParser.T__19)
                 pass
             else:
                 raise NoViableAltException(self)
@@ -647,7 +519,7 @@ class SearchParser ( Parser ):
             self.exitRule()
         return localctx
 
-    class OpContext(ParserRuleContext):
+    class IdentifierContext(ParserRuleContext):
 
         def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
             super().__init__(parent, invokingState)
@@ -661,125 +533,285 @@ class SearchParser ( Parser ):
 
 
         def getRuleIndex(self):
-            return SearchParser.RULE_op
+            return SearchParser.RULE_identifier
 
         def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterOp" ):
-                listener.enterOp(self)
+            if hasattr( listener, "enterIdentifier" ):
+                listener.enterIdentifier(self)
 
         def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitOp" ):
-                listener.exitOp(self)
+            if hasattr( listener, "exitIdentifier" ):
+                listener.exitIdentifier(self)
 
 
 
 
-    def op(self):
+    def identifier(self):
 
-        localctx = SearchParser.OpContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 14, self.RULE_op)
+        localctx = SearchParser.IdentifierContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 10, self.RULE_identifier)
         self._la = 0 # Token type
         try:
-            self.state = 116
+            self.state = 93
             self._errHandler.sync(self)
-            la_ = self._interp.adaptivePredict(self._input,11,self._ctx)
-            if la_ == 1:
+            token = self._input.LA(1)
+            if token in [SearchParser.T__20]:
                 self.enterOuterAlt(localctx, 1)
-                self.state = 95
-                self.match(SearchParser.T__35)
-                pass
+                self.state = 76
+                self.match(SearchParser.T__20)
+                self.state = 80
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 77
+                    self.digit()
+                    self.state = 82
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 2:
-                self.enterOuterAlt(localctx, 2)
-                self.state = 96
-                self.match(SearchParser.T__36)
+                self.state = 83
+                self.match(SearchParser.T__21)
                 pass
+            elif token in [SearchParser.T__22]:
+                self.enterOuterAlt(localctx, 2)
+                self.state = 84
+                self.match(SearchParser.T__22)
+                self.state = 88
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 85
+                    self.digit()
+                    self.state = 90
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 3:
+                self.state = 91
+                self.match(SearchParser.T__21)
+                pass
+            elif token in [SearchParser.T__23]:
                 self.enterOuterAlt(localctx, 3)
-                self.state = 97
-                self.match(SearchParser.T__37)
+                self.state = 92
+                self.match(SearchParser.T__23)
                 pass
+            else:
+                raise NoViableAltException(self)
 
-            elif la_ == 4:
-                self.enterOuterAlt(localctx, 4)
-                self.state = 98
-                self.match(SearchParser.T__38)
-                pass
+        except RecognitionException as re:
+            localctx.exception = re
+            self._errHandler.reportError(self, re)
+            self._errHandler.recover(self, re)
+        finally:
+            self.exitRule()
+        return localctx
 
-            elif la_ == 5:
-                self.enterOuterAlt(localctx, 5)
-                self.state = 99
-                self.match(SearchParser.T__39)
-                pass
+    class OperatorContext(ParserRuleContext):
 
-            elif la_ == 6:
-                self.enterOuterAlt(localctx, 6)
-                self.state = 100
-                self.match(SearchParser.T__40)
-                pass
+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
+            super().__init__(parent, invokingState)
+            self.parser = parser
 
-            elif la_ == 7:
-                self.enterOuterAlt(localctx, 7)
-                self.state = 101
-                self.match(SearchParser.T__3)
-                pass
+        def digit(self, i:int=None):
+            if i is None:
+                return self.getTypedRuleContexts(SearchParser.DigitContext)
+            else:
+                return self.getTypedRuleContext(SearchParser.DigitContext,i)
+
+
+        def getRuleIndex(self):
+            return SearchParser.RULE_operator
+
+        def enterRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "enterOperator" ):
+                listener.enterOperator(self)
+
+        def exitRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "exitOperator" ):
+                listener.exitOperator(self)
+
+
+
+
+    def operator(self):
+
+        localctx = SearchParser.OperatorContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 12, self.RULE_operator)
+        self._la = 0 # Token type
+        try:
+            self.state = 112
+            self._errHandler.sync(self)
+            token = self._input.LA(1)
+            if token in [SearchParser.T__24]:
+                self.enterOuterAlt(localctx, 1)
+                self.state = 95
+                self.match(SearchParser.T__24)
+                self.state = 99
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 96
+                    self.digit()
+                    self.state = 101
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 8:
-                self.enterOuterAlt(localctx, 8)
                 self.state = 102
-                self.match(SearchParser.T__41)
+                self.match(SearchParser.T__21)
                 pass
-
-            elif la_ == 9:
-                self.enterOuterAlt(localctx, 9)
+            elif token in [SearchParser.T__25]:
+                self.enterOuterAlt(localctx, 2)
                 self.state = 103
-                self.match(SearchParser.T__42)
-                pass
+                self.match(SearchParser.T__25)
+                self.state = 107
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 104
+                    self.digit()
+                    self.state = 109
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 10:
-                self.enterOuterAlt(localctx, 10)
-                self.state = 104
-                self.match(SearchParser.T__39)
+                self.state = 110
+                self.match(SearchParser.T__21)
                 pass
-
-            elif la_ == 11:
-                self.enterOuterAlt(localctx, 11)
-                self.state = 105
-                self.match(SearchParser.T__43)
+            elif token in [SearchParser.T__26]:
+                self.enterOuterAlt(localctx, 3)
+                self.state = 111
+                self.match(SearchParser.T__26)
                 pass
+            else:
+                raise NoViableAltException(self)
 
-            elif la_ == 12:
-                self.enterOuterAlt(localctx, 12)
-                self.state = 106
-                self.match(SearchParser.T__44)
-                pass
+        except RecognitionException as re:
+            localctx.exception = re
+            self._errHandler.reportError(self, re)
+            self._errHandler.recover(self, re)
+        finally:
+            self.exitRule()
+        return localctx
+
+    class LiteralContext(ParserRuleContext):
+
+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
+            super().__init__(parent, invokingState)
+            self.parser = parser
+
+        def digit(self, i:int=None):
+            if i is None:
+                return self.getTypedRuleContexts(SearchParser.DigitContext)
+            else:
+                return self.getTypedRuleContext(SearchParser.DigitContext,i)
+
+
+        def getRuleIndex(self):
+            return SearchParser.RULE_literal
+
+        def enterRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "enterLiteral" ):
+                listener.enterLiteral(self)
+
+        def exitRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "exitLiteral" ):
+                listener.exitLiteral(self)
 
-            elif la_ == 13:
-                self.enterOuterAlt(localctx, 13)
-                self.state = 107
-                self.match(SearchParser.T__45)
-                pass
 
-            elif la_ == 14:
-                self.enterOuterAlt(localctx, 14)
-                self.state = 108
-                self.match(SearchParser.T__46)
-                self.state = 112
+
+
+    def literal(self):
+
+        localctx = SearchParser.LiteralContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 14, self.RULE_literal)
+        self._la = 0 # Token type
+        try:
+            self.state = 131
+            self._errHandler.sync(self)
+            token = self._input.LA(1)
+            if token in [SearchParser.T__27]:
+                self.enterOuterAlt(localctx, 1)
+                self.state = 114
+                self.match(SearchParser.T__27)
+                self.state = 118
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0):
-                    self.state = 109
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 115
                     self.digit()
-                    self.state = 114
+                    self.state = 120
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 115
-                self.match(SearchParser.T__3)
+                self.state = 121
+                self.match(SearchParser.T__21)
+                pass
+            elif token in [SearchParser.T__28]:
+                self.enterOuterAlt(localctx, 2)
+                self.state = 122
+                self.match(SearchParser.T__28)
+                self.state = 126
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 123
+                    self.digit()
+                    self.state = 128
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
+
+                self.state = 129
+                self.match(SearchParser.T__21)
+                pass
+            elif token in [SearchParser.T__29]:
+                self.enterOuterAlt(localctx, 3)
+                self.state = 130
+                self.match(SearchParser.T__29)
                 pass
+            else:
+                raise NoViableAltException(self)
+
+        except RecognitionException as re:
+            localctx.exception = re
+            self._errHandler.reportError(self, re)
+            self._errHandler.recover(self, re)
+        finally:
+            self.exitRule()
+        return localctx
+
+    class DigitContext(ParserRuleContext):
 
+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
+            super().__init__(parent, invokingState)
+            self.parser = parser
 
+
+        def getRuleIndex(self):
+            return SearchParser.RULE_digit
+
+        def enterRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "enterDigit" ):
+                listener.enterDigit(self)
+
+        def exitRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "exitDigit" ):
+                listener.exitDigit(self)
+
+
+
+
+    def digit(self):
+
+        localctx = SearchParser.DigitContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 16, self.RULE_digit)
+        self._la = 0 # Token type
+        try:
+            self.enterOuterAlt(localctx, 1)
+            self.state = 133
+            _la = self._input.LA(1)
+            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0)):
+                self._errHandler.recoverInline(self)
+            else:
+                self._errHandler.reportMatch(self)
+                self.consume()
         except RecognitionException as re:
             localctx.exception = re
             self._errHandler.reportError(self, re)
diff --git a/code/example.txt b/code/example.txt
index 56c4c47..a8ab280 100644
--- a/code/example.txt
+++ b/code/example.txt
@@ -1,21 +1,23 @@
-9for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<0>;#ID<.>#OP<.>){->for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<1>;#ID<.>#OP<.>){
-#ID<.>.#ID<.>(#N<0>,#N<1>);->#ID<.>.#ID<.>(#N<2>,#N<3>);
-#ID<.>.#ID<.>(#N<.>);->_
+for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<0>;#ID<.>#OP<.>){->for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<1>;#ID<.>#OP<.>){
+#ID<.>.#ID<.>(#LT<0>,#LT<1>);->#ID<.>.#ID<.>(#LT<!0>,#LT<!1>);
+#ID<.>.#ID<.>(#LT<.>);->_
 _->#ID<.>.#ID<.>();
-for(#ID<.>=#N<.>;#ID<.>#OP<0>#N<0>;#ID<.>#OP<.>){->for(#ID<.>=#N<.>;#ID<.>#OP<1>#N<1>;#ID<.>#OP<.>){
-for(#ID<.>=#N<.>;#ID<.>#OP<0>#N<0>;#ID<0>#OP<1>){->for(#ID<.>=#N<.>;#ID<.>#OP<2>#N<1>;#ID<1>#OP<3>){
-if(#ID<.>#OP<0>#N<.>){->if(#ID<.>#OP<1>#N<.>){
-if(#ID<.>#OP<.>#N<0>){->if(#ID<.>#OP<.>#N<1>){
-if(#ID<.>#OP<0>#N<.>){->if(#ID<.>#OP<1>#N<.>){
-#ID<.>.#ID<.>(#N<0>,#N<1>);->#ID<.>.#ID<.>(#N<2>,#N<3>);
-#ID<.>.#ID<.>(#N<.>);->_
-if(#ID<.>#OP<.>#N<0>){->if(#ID<.>#OP<.>#N<1>){
+for(#ID<.>=#LT<.>;#ID<.>#OP<0>#LT<0>;#ID<.>#OP<.>){->for(#ID<.>=#LT<.>;#ID<.>#OP<1>#LT<1>;#ID<.>#OP<.>){
+for(#ID<.>=#LT<.>;#ID<.>#OP<0>#LT<0>;#ID<0>#OP<1>){->for(#ID<.>=#LT<.>;#ID<.>#OP<2>#LT<1>;#ID<1>#OP<3>){
+if(#ID<.>#OP<0>#LT<.>){->if(#ID<.>#OP<1>#LT<.>){
+if(#ID<.>#OP<.>#LT<0>){->if(#ID<.>#OP<.>#LT<1>){
+if(#ID<.>#OP<0>#LT<.>){->if(#ID<.>#OP<1>#LT<.>){
+#ID<.>.#ID<.>(#LT<0>,#LT<1>);->#ID<.>.#ID<.>(#LT<2>,#LT<3>);
 
-if(#ID<.>#OP<0>#N<.>) -> if(#ID<.>#OP<1>#N<.>)
-if(#ID<.>#OP<.>#N<0>) -> if(#ID<.>#OP<.>#N<1>)
+if(#ID<.>#OP<.>#LT<0>){->if(#ID<.>#OP<.>#LT<1>){
 
-#ID<.>.#ID<.>(#N<100>,#N<21321>)->#ID<.>.#ID<.>(#N<23222>,,#N<2312313>
+if(#ID<.>#OP<0>#LT<.>) -> if(#ID<.>#OP<!0>#LT<.>)
+if(#ID<.>#OP<1>#LT<.>) -> if(#ID<.>#OP<1>#LT<.>)
+if(#ID<.>#OP<1>#LT<.>){ -> if(#ID<.>#OP<1>#LT<.>){
 
-if(#ID<.>#OP<0>#N<.>){ -> if(#ID<.>#OP<3>#N<.>){
-if(#ID<.>#OP<1>#N<.>) -> if(#ID<.>#OP<2>#N<.>)
-for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<1>;#ID<.>#OP<.>)->for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<2>;#ID<.>#OP<.>)
\ No newline at end of file
+#ID<.>.#ID<.>(#LT<100>,#LT<21321>)->#ID<.>.#ID<.>(#LT<23222>,,#LT<2312313>
+
+if(#ID<.>#OP<0>#LT<.>){ -> if(#ID<.>#OP<3>#LT<.>){
+if(#ID<.>#OP<1>#LT<.>) -> if(#ID<.>#OP<2>#LT<.>)
+for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<1>;#ID<.>#OP<.>)->for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<2>;#ID<.>#OP<.>)
+_ ->#ID<.>.#ID<.>(#LT<.>,#LT<.>);
diff --git a/code/git_changes.txt b/code/git_changes.txt
index b106a2d..3276ed5 100644
--- a/code/git_changes.txt
+++ b/code/git_changes.txt
@@ -7,12 +7,15 @@ index d58db74..f1c27f0 100644
  
     public static void main(String[] args) {
 
--        for(j=0;j<2;j++){
-+        for(j=0;j<3;j++){
+-              if(y>0){
++              if(y>5){
+
+-              if(y==0){
++              if(y!=0){
 
          Scanner s= new Scanner(System.in);
 
-         System.out.println("Geometry Area:\n1)Circle\n2)Rectangle\n3)Triangle\n");
+         System.out.println("Geometry Area:\n");
 
          switch(i) {
             case 1:
@@ -30,45 +33,27 @@ index d58db74..f1c27f0 100644
         }
 
 
-diff --git a/Area.java b/Area.java
+diff --git a/main.cpp b/main.cpp
 index d58db74..f1c27f0 100644
---- a/Area.java
-+++ b/Area.java
-@@ -3,24 +3,23 @@ import java.util.Scanner;
- public class Area {
+--- a/main.cpp
++++ b/maoin.cpp
+@@ -16,10 +16,10 @@ int main()
  
-    public static void main(String[] args) {
+    //add a call method
 
--        for(j=0;j>0;j++){
-+        for(j=0;j<1;j++){
+-    if(n>2)
++    if(n<2)
+      myfile << n;
 
--        for(j=0;j>0;i--){
-+        for(j=0;j<1;j++){
+-    while(i<1){
++    while(i>1){
+        cout << "The result is: " << sub(x2,x1) << endl; //swap arguments DONE
+        i++;
+    }
+@@ -32,7 +32,7 @@ int main()
 
-         Scanner s= new Scanner(System.in);
-
-         System.out.println("Geometry Area:\n1)Circle\n2)Rectangle\n3)Triangle\n");
 
--              if(x>0){
-+              if(x<0){
 
--              if(y>0){
-+              if(y>5){
-
--              if(y==0){
-+              if(y!=0){
-
-         switch(i) {
-            case 1:
--              Area.circle(6,7);
-+              Area.circle(5,5);
-              break;
-            case 2:
--              Area.rectangle(3);
-               Area.rectangle(2,1);
-              break;
-            default:
--              if(y>9){
-+              if(y>1){
-          }
-        }
+-    return 0;
++    return -1;
+}
diff --git a/code/git_functions.py b/code/git_functions.py
index 059745e..36e35a4 100644
--- a/code/git_functions.py
+++ b/code/git_functions.py
@@ -25,9 +25,9 @@ def git_clone():
 def git_log(repository):
     commit_log = []
 
-    command = "cd " + repository + "&& git log > git_log.txt"
+    command = "git log > ./test-changes/git_log.txt"
     os.system(command)
-    filename = repository + "/git_log.txt"
+    filename ="test-changes/git_log.txt"
 
     with open(filename) as fp:
         for line in fp:
@@ -45,9 +45,9 @@ def git_log(repository):
 #Compute the git diff
 def git_diff(commit_log, repository):
 
-    command = "echo '' > git_changes.txt"
+    command = "echo '' > ./test_changes/git_changes.txt"
     os.system(command)
 
     for i in commit_log:
-        command = "cd " + repository + "&& git diff " + i + " HEAD >> git_changes.txt"
+        command = "cd ./test-changes && git diff " + i + " HEAD >> git_changes.txt"
         os.system(command)
\ No newline at end of file
diff --git a/code/main.py b/code/main.py
index 639436a..c95c46d 100644
--- a/code/main.py
+++ b/code/main.py
@@ -29,13 +29,26 @@ def main():
     #Computation of similarity in different ways(cosine distance and jaccard index)
     position = 0
     ngrams = 3
+
     #[0] cosine distance threshold [1] jaccard distance threshold
-    thresholds = [0.1, 0.1]
+    thresholds = [0.83, 0.8]
+    ranked_list = []
+
+    query_tokens, query_ngrams = my_functions.query_normalization(query,ngrams)
 
+    my_functions.dataset_csv(changes_list_real, changes_list_abstract)
+    
     for change in changes_list_abstract:
-        my_functions.similarity(query.replace(' ', '').replace('\n', ''), change, position, ngrams, thresholds, changes_list_real)
+        my_functions.similarity(query_tokens, query_ngrams, change, position, ngrams, thresholds, changes_list_real, ranked_list)
         position += 1
 
+    # sort list with key
+    ranked_list.sort(reverse=True, key=my_functions.takeSecond)
+
+    print("\nThe changes found are:\n ")
+    for i in ranked_list:
+        print(i[0] + ' cosine: ' + i[1] + ' jaccard: ' +  i[2])
+
     #Programs ends
     end = time.time()
     print("\nThe program ends in:", round(end - start_time,1), "seconds. Total changes in the repository: ", position) 
diff --git a/code/my_functions.py b/code/my_functions.py
index f025d9c..1d55af1 100644
--- a/code/my_functions.py
+++ b/code/my_functions.py
@@ -7,6 +7,8 @@ from math import*
 from decimal import Decimal
 import copy
 from collections import Counter
+import csv
+from itertools import zip_longest
 import antlr4 
 
 import sys
@@ -22,6 +24,10 @@ def diff(first, second):
     else:
         return [i for i in range(len(first)) if first[i] != second[i]]
 
+#Take second element for list sorting key
+def takeSecond(elem):
+    return elem[1]
+    
 #Compute ngram of a string
 def ngram(change, ngrams):
     ngrams_list = {}
@@ -64,7 +70,7 @@ def antlr4_AbstractGrammar_Tokenizer(query):
 
     return list_abstract_token
 
-#Exacrt the changes from the git diff file
+#Extract the changes from the git diff file
 def analyze_diff_file(filename):
     temporary_array = []
     changes_list = []
@@ -149,10 +155,10 @@ def scanner(changes_list):
                     else:
                         if token.isdigit():
                             if(count in diff1 and bool == False):
-                                old[count] = '#N<' + str(n_num) + '>'
+                                old[count] = '#LT<' + str(n_num) + '>'
                                 n_num = n_num + 1 
                             else:    
-                                old[count] = '#N<.>'
+                                old[count] = '#LT<.>'
                         else: 
                             if(count in diff1 and bool == False):
                                 old[count] = '#ID<' + str(n_id) + '>'
@@ -163,6 +169,9 @@ def scanner(changes_list):
             count = count + 1
 
         count = 0
+        n_op = 0
+        n_id = 0
+        n_num = 0
 
         for token in new:
             if token == 'if' or token == 'else' or token =='for' or token =='while' or token =='forEach' or token =='while' or token =='return' or token =='NULL':
@@ -182,10 +191,10 @@ def scanner(changes_list):
                     else:
                         if token.isdigit():
                             if(count in diff1 and bool == False):
-                                new[count] = '#N<' + str(n_num) + '>'
+                                new[count] = '#LT<' + str(n_num) + '>'
                                 n_num = n_num + 1 
                             else:    
-                                new[count] = '#N<.>'
+                                new[count] = '#LT<.>'
                         else: 
                             if(count in diff1 and bool == False):
                                 new[count] = '#ID<' + str(n_id) + '>'
@@ -219,15 +228,13 @@ def scanner(changes_list):
 #Compute cosine similarity
 def cosine_similarity_ngrams(a, b):
 
-    vec1 = Counter(a)
-    vec2 = Counter(b)
+    v1 = Counter(a)
+    v2 = Counter(b)
     
-    intersection = set(vec1.keys()) & set(vec2.keys())
-    numerator = sum([vec1[x] * vec2[x] for x in intersection])
+    intersection = set(v1.keys()) & set(v2.keys())
 
-    sum1 = sum([vec1[x]**2 for x in vec1.keys()])
-    sum2 = sum([vec2[x]**2 for x in vec2.keys()])
-    denominator = math.sqrt(sum1) * math.sqrt(sum2)
+    numerator = sum([v1[x] * v2[x] for x in intersection])
+    denominator = math.sqrt(sum([v1[x]**2 for x in v1.keys()])) * math.sqrt(sum([v2[x]**2 for x in v2.keys()]))
 
     if not denominator:
         return 0.0
@@ -240,22 +247,76 @@ def getNgrams(string, n):
 #Compute Jaccard index similarity
 def jaccard_similarity(x,y):
  
- intersection_cardinality = len(set.intersection(*[set(x), set(y)]))
- union_cardinality = len(set.union(*[set(x), set(y)]))
+    intersection = len(set.intersection(*[set(x), set(y)]))
+    union = len(set.union(*[set(x), set(y)]))
  
- return intersection_cardinality/float(union_cardinality)
+    return intersection/float(union)
 
 #Compute the similarity between query and one change using different similarity algorithm. Print the change if over thresholds 
-def similarity(query, change, position, ngram, thresholds, changes_list_real):
+def similarity(query_tokens, query_ngrams, change, position, ngram, thresholds, changes_list_real, ranked_list):
+
+    temporary_list = []
 
-    ngrams_list1 = getNgrams(query, ngram)
+    #ngrams_list1 = getNgrams(query, ngram)
     ngrams_list2 = getNgrams(change, ngram)
 
-    abstract_tokens1 = antlr4_AbstractGrammar_Tokenizer(query)
+    #abstract_tokens1 = antlr4_AbstractGrammar_Tokenizer(query)
     abstract_tokens2 = antlr4_AbstractGrammar_Tokenizer(change)
 
-    cosine_score = cosine_similarity_ngrams(ngrams_list1,ngrams_list2)
-    jaccard_score = jaccard_similarity(abstract_tokens1, abstract_tokens2)
+    cosine_score = cosine_similarity_ngrams(query_ngrams,ngrams_list2)
+    jaccard_score = jaccard_similarity(query_tokens, abstract_tokens2)
    
     if cosine_score > thresholds[0] and jaccard_score > thresholds[1] :
-        print(changes_list_real[position] + ' cosine: ' + str(round(cosine_score,2)) + ' jaccard: ' + str(round(jaccard_score,2)))#+ ' eucledian: ' + str(round(eucledian_score,2)))
+        
+        temporary_list.append(changes_list_real[position])
+        temporary_list.append(str(round(cosine_score,2)))
+        temporary_list.append(str(round(jaccard_score,2)))
+
+        ranked_list.append(temporary_list)
+
+#Query digits normalization and n-grams and tokens computation
+def query_normalization(query, ngrams):
+    query_normalize = []
+
+    id = 0
+    op = 0
+    lt = 0
+    n = 0
+    l = len(str(query))
+
+    for n in range(0, l):
+        if(query[n] == '-'):
+                id = 0
+                op = 0
+                lt = 0
+
+                query_normalize.append(query[n])
+        else:
+            if query[n].isdigit():
+                if(n > 1):
+                    if(query[n-2] == 'D'):
+                        query_normalize.append(str(id))
+                        id += 1
+                    else:
+                        if(query[n-2] == 'P'):
+                            query_normalize.append(str(op))
+                            op += 1
+                        else:
+                           # if(query[n-2] == 'T'):
+                                query_normalize.append(str(lt))
+                                lt += 1
+                else: 
+                    query_normalize.append(query[n])
+            else: 
+                    query_normalize.append(query[n])
+
+        
+        n += 1
+
+    query_n = ''.join(query_normalize).replace(' ', '').replace('\n', '')
+
+    query_tokens = antlr4_AbstractGrammar_Tokenizer(query_n)
+    query_ngrams = getNgrams(query_n, ngrams)
+    
+
+    return query_tokens, query_ngrams
diff --git a/code/tests.py b/code/tests.py
index 6e72061..9b25953 100644
--- a/code/tests.py
+++ b/code/tests.py
@@ -1,41 +1,32 @@
+ #  stream = antlr4.CommonTokenStream(lexer)
+   # parser = SearchParser(stream)
+   # tree = parser.query()
+    #printer = SearchPrintListener()
+   # walker = antlr4.ParseTreeWalker()
+    #walker.walk(printer, tree)
+  #  print(tree.toStringTree())
+    
 import antlr4 
 
 import sys
-# insert at 1, 0 is the script path (or '' in REPL)
-sys.path.insert(1, './antlr4')
-
+sys.path.insert(1, './code/antlr4')
 from SearchLexer import SearchLexer
 from SearchListener import SearchListener
 from SearchParser import SearchParser
 
-#echo "3 * 3 - 2 + 2 * 2" | python main.py
-
 class SearchPrintListener(SearchListener):
-    def enterSearch(self, ctx):
-        print("Search: %s" % ctx.ID())
+    def enterHi(self, ctx):
+        print("Hello: %s" % ctx.ID())
 
-def antlr4_AbstractGrammar_Tokenizer(query):
+def main(query):
     lexer = SearchLexer(antlr4.InputStream(query))
-    list_abstract_token = []
-    while(1):
-        token = lexer.nextToken()
-        if(token.text == '<EOF>'):
-            break
-        list_abstract_token.append(token.text)
-
-    
-    for i in list_abstract_token:
-       print(i)
-
-    return list_abstract_token
-  #  stream = antlr4.CommonTokenStream(lexer)
-   # parser = SearchParser(stream)
-   # tree = parser.query()
-    #printer = SearchPrintListener()
-   # walker = antlr4.ParseTreeWalker()
-    #walker.walk(printer, tree)
-  #  print(tree.toStringTree())
-    
+    stream = antlr4.CommonTokenStream(lexer)
+    parser = SearchParser(stream)
+    tree = parser.query()
+    printer = SearchPrintListener()
+    walker = antlr4.ParseTreeWalker()
+    walker.walk(printer, tree)
+    #print(tree.toStringTree())
 
 if __name__ == '__main__':
-    antlr4_AbstractGrammar_Tokenizer('if(#ID<.>#OP<0>#N<.>) -> if(#ID<.>#OP<3>#N<.>)')
+    main('if(#ID<.>#OP<1>#LT<.>){ -> if(#ID<.>#OP<1>#LT<.>){<')
diff --git a/code/antlr4/.antlr/Search.interp b/code/antlr4/.antlr/Search.interp
new file mode 100644
index 0000000..b739ec4
--- /dev/null
+++ b/code/antlr4/.antlr/Search.interp
@@ -0,0 +1,102 @@
+token literal names:
+null
+'->'
+'_'
+'if'
+'else'
+'for'
+'forEach'
+'while'
+'return'
+'NULL'
+'('
+')'
+'['
+']'
+'{'
+'}'
+'"'
+'='
+'.'
+','
+';'
+'#ID<'
+'>'
+'#ID<!'
+'#ID<.>'
+'#OP<'
+'#OP<!'
+'#OP<.>'
+'#LT<'
+'#LT<!'
+'#LT<.>'
+'0'
+'1'
+'2'
+'3'
+'4'
+'5'
+'6'
+'7'
+'8'
+'9'
+null
+
+token symbolic names:
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+WS
+
+rule names:
+query
+code
+token
+keyword
+punctuator
+identifier
+operator
+literal
+digit
+
+
+atn:
+[3, 24715, 42794, 33075, 47597, 16764, 15335, 30598, 22884, 3, 43, 138, 4, 2, 9, 2, 4, 3, 9, 3, 4, 4, 9, 4, 4, 5, 9, 5, 4, 6, 9, 6, 4, 7, 9, 7, 4, 8, 9, 8, 4, 9, 9, 9, 4, 10, 9, 10, 3, 2, 3, 2, 3, 2, 3, 2, 3, 3, 7, 3, 26, 10, 3, 12, 3, 14, 3, 29, 11, 3, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 5, 4, 37, 10, 4, 3, 5, 3, 5, 3, 6, 3, 6, 7, 6, 43, 10, 6, 12, 6, 14, 6, 46, 11, 6, 3, 6, 3, 6, 3, 6, 7, 6, 51, 10, 6, 12, 6, 14, 6, 54, 11, 6, 3, 6, 3, 6, 3, 6, 7, 6, 59, 10, 6, 12, 6, 14, 6, 62, 11, 6, 3, 6, 3, 6, 3, 6, 7, 6, 67, 10, 6, 12, 6, 14, 6, 70, 11, 6, 3, 6, 3, 6, 3, 6, 3, 6, 3, 6, 5, 6, 77, 10, 6, 3, 7, 3, 7, 7, 7, 81, 10, 7, 12, 7, 14, 7, 84, 11, 7, 3, 7, 3, 7, 3, 7, 7, 7, 89, 10, 7, 12, 7, 14, 7, 92, 11, 7, 3, 7, 3, 7, 5, 7, 96, 10, 7, 3, 8, 3, 8, 7, 8, 100, 10, 8, 12, 8, 14, 8, 103, 11, 8, 3, 8, 3, 8, 3, 8, 7, 8, 108, 10, 8, 12, 8, 14, 8, 111, 11, 8, 3, 8, 3, 8, 5, 8, 115, 10, 8, 3, 9, 3, 9, 7, 9, 119, 10, 9, 12, 9, 14, 9, 122, 11, 9, 3, 9, 3, 9, 3, 9, 7, 9, 127, 10, 9, 12, 9, 14, 9, 130, 11, 9, 3, 9, 3, 9, 5, 9, 134, 10, 9, 3, 10, 3, 10, 3, 10, 2, 2, 11, 2, 4, 6, 8, 10, 12, 14, 16, 18, 2, 4, 3, 2, 5, 11, 3, 2, 33, 42, 2, 157, 2, 20, 3, 2, 2, 2, 4, 27, 3, 2, 2, 2, 6, 36, 3, 2, 2, 2, 8, 38, 3, 2, 2, 2, 10, 76, 3, 2, 2, 2, 12, 95, 3, 2, 2, 2, 14, 114, 3, 2, 2, 2, 16, 133, 3, 2, 2, 2, 18, 135, 3, 2, 2, 2, 20, 21, 5, 4, 3, 2, 21, 22, 7, 3, 2, 2, 22, 23, 5, 4, 3, 2, 23, 3, 3, 2, 2, 2, 24, 26, 5, 6, 4, 2, 25, 24, 3, 2, 2, 2, 26, 29, 3, 2, 2, 2, 27, 25, 3, 2, 2, 2, 27, 28, 3, 2, 2, 2, 28, 5, 3, 2, 2, 2, 29, 27, 3, 2, 2, 2, 30, 37, 5, 12, 7, 2, 31, 37, 5, 8, 5, 2, 32, 37, 5, 10, 6, 2, 33, 37, 5, 14, 8, 2, 34, 37, 5, 16, 9, 2, 35, 37, 7, 4, 2, 2, 36, 30, 3, 2, 2, 2, 36, 31, 3, 2, 2, 2, 36, 32, 3, 2, 2, 2, 36, 33, 3, 2, 2, 2, 36, 34, 3, 2, 2, 2, 36, 35, 3, 2, 2, 2, 37, 7, 3, 2, 2, 2, 38, 39, 9, 2, 2, 2, 39, 9, 3, 2, 2, 2, 40, 44, 7, 12, 2, 2, 41, 43, 5, 6, 4, 2, 42, 41, 3, 2, 2, 2, 43, 46, 3, 2, 2, 2, 44, 42, 3, 2, 2, 2, 44, 45, 3, 2, 2, 2, 45, 47, 3, 2, 2, 2, 46, 44, 3, 2, 2, 2, 47, 77, 7, 13, 2, 2, 48, 52, 7, 14, 2, 2, 49, 51, 5, 6, 4, 2, 50, 49, 3, 2, 2, 2, 51, 54, 3, 2, 2, 2, 52, 50, 3, 2, 2, 2, 52, 53, 3, 2, 2, 2, 53, 55, 3, 2, 2, 2, 54, 52, 3, 2, 2, 2, 55, 77, 7, 15, 2, 2, 56, 60, 7, 16, 2, 2, 57, 59, 5, 6, 4, 2, 58, 57, 3, 2, 2, 2, 59, 62, 3, 2, 2, 2, 60, 58, 3, 2, 2, 2, 60, 61, 3, 2, 2, 2, 61, 63, 3, 2, 2, 2, 62, 60, 3, 2, 2, 2, 63, 77, 7, 17, 2, 2, 64, 68, 7, 18, 2, 2, 65, 67, 5, 6, 4, 2, 66, 65, 3, 2, 2, 2, 67, 70, 3, 2, 2, 2, 68, 66, 3, 2, 2, 2, 68, 69, 3, 2, 2, 2, 69, 71, 3, 2, 2, 2, 70, 68, 3, 2, 2, 2, 71, 77, 7, 18, 2, 2, 72, 77, 7, 19, 2, 2, 73, 77, 7, 20, 2, 2, 74, 77, 7, 21, 2, 2, 75, 77, 7, 22, 2, 2, 76, 40, 3, 2, 2, 2, 76, 48, 3, 2, 2, 2, 76, 56, 3, 2, 2, 2, 76, 64, 3, 2, 2, 2, 76, 72, 3, 2, 2, 2, 76, 73, 3, 2, 2, 2, 76, 74, 3, 2, 2, 2, 76, 75, 3, 2, 2, 2, 77, 11, 3, 2, 2, 2, 78, 82, 7, 23, 2, 2, 79, 81, 5, 18, 10, 2, 80, 79, 3, 2, 2, 2, 81, 84, 3, 2, 2, 2, 82, 80, 3, 2, 2, 2, 82, 83, 3, 2, 2, 2, 83, 85, 3, 2, 2, 2, 84, 82, 3, 2, 2, 2, 85, 96, 7, 24, 2, 2, 86, 90, 7, 25, 2, 2, 87, 89, 5, 18, 10, 2, 88, 87, 3, 2, 2, 2, 89, 92, 3, 2, 2, 2, 90, 88, 3, 2, 2, 2, 90, 91, 3, 2, 2, 2, 91, 93, 3, 2, 2, 2, 92, 90, 3, 2, 2, 2, 93, 96, 7, 24, 2, 2, 94, 96, 7, 26, 2, 2, 95, 78, 3, 2, 2, 2, 95, 86, 3, 2, 2, 2, 95, 94, 3, 2, 2, 2, 96, 13, 3, 2, 2, 2, 97, 101, 7, 27, 2, 2, 98, 100, 5, 18, 10, 2, 99, 98, 3, 2, 2, 2, 100, 103, 3, 2, 2, 2, 101, 99, 3, 2, 2, 2, 101, 102, 3, 2, 2, 2, 102, 104, 3, 2, 2, 2, 103, 101, 3, 2, 2, 2, 104, 115, 7, 24, 2, 2, 105, 109, 7, 28, 2, 2, 106, 108, 5, 18, 10, 2, 107, 106, 3, 2, 2, 2, 108, 111, 3, 2, 2, 2, 109, 107, 3, 2, 2, 2, 109, 110, 3, 2, 2, 2, 110, 112, 3, 2, 2, 2, 111, 109, 3, 2, 2, 2, 112, 115, 7, 24, 2, 2, 113, 115, 7, 29, 2, 2, 114, 97, 3, 2, 2, 2, 114, 105, 3, 2, 2, 2, 114, 113, 3, 2, 2, 2, 115, 15, 3, 2, 2, 2, 116, 120, 7, 30, 2, 2, 117, 119, 5, 18, 10, 2, 118, 117, 3, 2, 2, 2, 119, 122, 3, 2, 2, 2, 120, 118, 3, 2, 2, 2, 120, 121, 3, 2, 2, 2, 121, 123, 3, 2, 2, 2, 122, 120, 3, 2, 2, 2, 123, 134, 7, 24, 2, 2, 124, 128, 7, 31, 2, 2, 125, 127, 5, 18, 10, 2, 126, 125, 3, 2, 2, 2, 127, 130, 3, 2, 2, 2, 128, 126, 3, 2, 2, 2, 128, 129, 3, 2, 2, 2, 129, 131, 3, 2, 2, 2, 130, 128, 3, 2, 2, 2, 131, 134, 7, 24, 2, 2, 132, 134, 7, 32, 2, 2, 133, 116, 3, 2, 2, 2, 133, 124, 3, 2, 2, 2, 133, 132, 3, 2, 2, 2, 134, 17, 3, 2, 2, 2, 135, 136, 9, 3, 2, 2, 136, 19, 3, 2, 2, 2, 18, 27, 36, 44, 52, 60, 68, 76, 82, 90, 95, 101, 109, 114, 120, 128, 133]
\ No newline at end of file
diff --git a/code/antlr4/.antlr/Search.tokens b/code/antlr4/.antlr/Search.tokens
new file mode 100644
index 0000000..372bf0c
--- /dev/null
+++ b/code/antlr4/.antlr/Search.tokens
@@ -0,0 +1,81 @@
+T__0=1
+T__1=2
+T__2=3
+T__3=4
+T__4=5
+T__5=6
+T__6=7
+T__7=8
+T__8=9
+T__9=10
+T__10=11
+T__11=12
+T__12=13
+T__13=14
+T__14=15
+T__15=16
+T__16=17
+T__17=18
+T__18=19
+T__19=20
+T__20=21
+T__21=22
+T__22=23
+T__23=24
+T__24=25
+T__25=26
+T__26=27
+T__27=28
+T__28=29
+T__29=30
+T__30=31
+T__31=32
+T__32=33
+T__33=34
+T__34=35
+T__35=36
+T__36=37
+T__37=38
+T__38=39
+T__39=40
+WS=41
+'->'=1
+'_'=2
+'if'=3
+'else'=4
+'for'=5
+'forEach'=6
+'while'=7
+'return'=8
+'NULL'=9
+'('=10
+')'=11
+'['=12
+']'=13
+'{'=14
+'}'=15
+'"'=16
+'='=17
+'.'=18
+','=19
+';'=20
+'#ID<'=21
+'>'=22
+'#ID<!'=23
+'#ID<.>'=24
+'#OP<'=25
+'#OP<!'=26
+'#OP<.>'=27
+'#LT<'=28
+'#LT<!'=29
+'#LT<.>'=30
+'0'=31
+'1'=32
+'2'=33
+'3'=34
+'4'=35
+'5'=36
+'6'=37
+'7'=38
+'8'=39
+'9'=40
diff --git a/code/antlr4/.antlr/SearchLexer.interp b/code/antlr4/.antlr/SearchLexer.interp
new file mode 100644
index 0000000..062f29e
--- /dev/null
+++ b/code/antlr4/.antlr/SearchLexer.interp
@@ -0,0 +1,140 @@
+token literal names:
+null
+'->'
+'_'
+'if'
+'else'
+'for'
+'forEach'
+'while'
+'return'
+'NULL'
+'('
+')'
+'['
+']'
+'{'
+'}'
+'"'
+'='
+'.'
+','
+';'
+'#ID<'
+'>'
+'#ID<!'
+'#ID<.>'
+'#OP<'
+'#OP<!'
+'#OP<.>'
+'#LT<'
+'#LT<!'
+'#LT<.>'
+'0'
+'1'
+'2'
+'3'
+'4'
+'5'
+'6'
+'7'
+'8'
+'9'
+null
+
+token symbolic names:
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+WS
+
+rule names:
+T__0
+T__1
+T__2
+T__3
+T__4
+T__5
+T__6
+T__7
+T__8
+T__9
+T__10
+T__11
+T__12
+T__13
+T__14
+T__15
+T__16
+T__17
+T__18
+T__19
+T__20
+T__21
+T__22
+T__23
+T__24
+T__25
+T__26
+T__27
+T__28
+T__29
+T__30
+T__31
+T__32
+T__33
+T__34
+T__35
+T__36
+T__37
+T__38
+T__39
+WS
+
+channel names:
+DEFAULT_TOKEN_CHANNEL
+HIDDEN
+
+mode names:
+DEFAULT_MODE
+
+atn:
+[3, 24715, 42794, 33075, 47597, 16764, 15335, 30598, 22884, 2, 43, 233, 8, 1, 4, 2, 9, 2, 4, 3, 9, 3, 4, 4, 9, 4, 4, 5, 9, 5, 4, 6, 9, 6, 4, 7, 9, 7, 4, 8, 9, 8, 4, 9, 9, 9, 4, 10, 9, 10, 4, 11, 9, 11, 4, 12, 9, 12, 4, 13, 9, 13, 4, 14, 9, 14, 4, 15, 9, 15, 4, 16, 9, 16, 4, 17, 9, 17, 4, 18, 9, 18, 4, 19, 9, 19, 4, 20, 9, 20, 4, 21, 9, 21, 4, 22, 9, 22, 4, 23, 9, 23, 4, 24, 9, 24, 4, 25, 9, 25, 4, 26, 9, 26, 4, 27, 9, 27, 4, 28, 9, 28, 4, 29, 9, 29, 4, 30, 9, 30, 4, 31, 9, 31, 4, 32, 9, 32, 4, 33, 9, 33, 4, 34, 9, 34, 4, 35, 9, 35, 4, 36, 9, 36, 4, 37, 9, 37, 4, 38, 9, 38, 4, 39, 9, 39, 4, 40, 9, 40, 4, 41, 9, 41, 4, 42, 9, 42, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 6, 3, 6, 3, 6, 3, 6, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 8, 3, 8, 3, 8, 3, 8, 3, 8, 3, 8, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3, 10, 3, 10, 3, 10, 3, 10, 3, 10, 3, 11, 3, 11, 3, 12, 3, 12, 3, 13, 3, 13, 3, 14, 3, 14, 3, 15, 3, 15, 3, 16, 3, 16, 3, 17, 3, 17, 3, 18, 3, 18, 3, 19, 3, 19, 3, 20, 3, 20, 3, 21, 3, 21, 3, 22, 3, 22, 3, 22, 3, 22, 3, 22, 3, 23, 3, 23, 3, 24, 3, 24, 3, 24, 3, 24, 3, 24, 3, 24, 3, 25, 3, 25, 3, 25, 3, 25, 3, 25, 3, 25, 3, 25, 3, 26, 3, 26, 3, 26, 3, 26, 3, 26, 3, 27, 3, 27, 3, 27, 3, 27, 3, 27, 3, 27, 3, 28, 3, 28, 3, 28, 3, 28, 3, 28, 3, 28, 3, 28, 3, 29, 3, 29, 3, 29, 3, 29, 3, 29, 3, 30, 3, 30, 3, 30, 3, 30, 3, 30, 3, 30, 3, 31, 3, 31, 3, 31, 3, 31, 3, 31, 3, 31, 3, 31, 3, 32, 3, 32, 3, 33, 3, 33, 3, 34, 3, 34, 3, 35, 3, 35, 3, 36, 3, 36, 3, 37, 3, 37, 3, 38, 3, 38, 3, 39, 3, 39, 3, 40, 3, 40, 3, 41, 3, 41, 3, 42, 6, 42, 228, 10, 42, 13, 42, 14, 42, 229, 3, 42, 3, 42, 2, 2, 43, 3, 3, 5, 4, 7, 5, 9, 6, 11, 7, 13, 8, 15, 9, 17, 10, 19, 11, 21, 12, 23, 13, 25, 14, 27, 15, 29, 16, 31, 17, 33, 18, 35, 19, 37, 20, 39, 21, 41, 22, 43, 23, 45, 24, 47, 25, 49, 26, 51, 27, 53, 28, 55, 29, 57, 30, 59, 31, 61, 32, 63, 33, 65, 34, 67, 35, 69, 36, 71, 37, 73, 38, 75, 39, 77, 40, 79, 41, 81, 42, 83, 43, 3, 2, 3, 5, 2, 11, 12, 15, 15, 34, 34, 2, 233, 2, 3, 3, 2, 2, 2, 2, 5, 3, 2, 2, 2, 2, 7, 3, 2, 2, 2, 2, 9, 3, 2, 2, 2, 2, 11, 3, 2, 2, 2, 2, 13, 3, 2, 2, 2, 2, 15, 3, 2, 2, 2, 2, 17, 3, 2, 2, 2, 2, 19, 3, 2, 2, 2, 2, 21, 3, 2, 2, 2, 2, 23, 3, 2, 2, 2, 2, 25, 3, 2, 2, 2, 2, 27, 3, 2, 2, 2, 2, 29, 3, 2, 2, 2, 2, 31, 3, 2, 2, 2, 2, 33, 3, 2, 2, 2, 2, 35, 3, 2, 2, 2, 2, 37, 3, 2, 2, 2, 2, 39, 3, 2, 2, 2, 2, 41, 3, 2, 2, 2, 2, 43, 3, 2, 2, 2, 2, 45, 3, 2, 2, 2, 2, 47, 3, 2, 2, 2, 2, 49, 3, 2, 2, 2, 2, 51, 3, 2, 2, 2, 2, 53, 3, 2, 2, 2, 2, 55, 3, 2, 2, 2, 2, 57, 3, 2, 2, 2, 2, 59, 3, 2, 2, 2, 2, 61, 3, 2, 2, 2, 2, 63, 3, 2, 2, 2, 2, 65, 3, 2, 2, 2, 2, 67, 3, 2, 2, 2, 2, 69, 3, 2, 2, 2, 2, 71, 3, 2, 2, 2, 2, 73, 3, 2, 2, 2, 2, 75, 3, 2, 2, 2, 2, 77, 3, 2, 2, 2, 2, 79, 3, 2, 2, 2, 2, 81, 3, 2, 2, 2, 2, 83, 3, 2, 2, 2, 3, 85, 3, 2, 2, 2, 5, 88, 3, 2, 2, 2, 7, 90, 3, 2, 2, 2, 9, 93, 3, 2, 2, 2, 11, 98, 3, 2, 2, 2, 13, 102, 3, 2, 2, 2, 15, 110, 3, 2, 2, 2, 17, 116, 3, 2, 2, 2, 19, 123, 3, 2, 2, 2, 21, 128, 3, 2, 2, 2, 23, 130, 3, 2, 2, 2, 25, 132, 3, 2, 2, 2, 27, 134, 3, 2, 2, 2, 29, 136, 3, 2, 2, 2, 31, 138, 3, 2, 2, 2, 33, 140, 3, 2, 2, 2, 35, 142, 3, 2, 2, 2, 37, 144, 3, 2, 2, 2, 39, 146, 3, 2, 2, 2, 41, 148, 3, 2, 2, 2, 43, 150, 3, 2, 2, 2, 45, 155, 3, 2, 2, 2, 47, 157, 3, 2, 2, 2, 49, 163, 3, 2, 2, 2, 51, 170, 3, 2, 2, 2, 53, 175, 3, 2, 2, 2, 55, 181, 3, 2, 2, 2, 57, 188, 3, 2, 2, 2, 59, 193, 3, 2, 2, 2, 61, 199, 3, 2, 2, 2, 63, 206, 3, 2, 2, 2, 65, 208, 3, 2, 2, 2, 67, 210, 3, 2, 2, 2, 69, 212, 3, 2, 2, 2, 71, 214, 3, 2, 2, 2, 73, 216, 3, 2, 2, 2, 75, 218, 3, 2, 2, 2, 77, 220, 3, 2, 2, 2, 79, 222, 3, 2, 2, 2, 81, 224, 3, 2, 2, 2, 83, 227, 3, 2, 2, 2, 85, 86, 7, 47, 2, 2, 86, 87, 7, 64, 2, 2, 87, 4, 3, 2, 2, 2, 88, 89, 7, 97, 2, 2, 89, 6, 3, 2, 2, 2, 90, 91, 7, 107, 2, 2, 91, 92, 7, 104, 2, 2, 92, 8, 3, 2, 2, 2, 93, 94, 7, 103, 2, 2, 94, 95, 7, 110, 2, 2, 95, 96, 7, 117, 2, 2, 96, 97, 7, 103, 2, 2, 97, 10, 3, 2, 2, 2, 98, 99, 7, 104, 2, 2, 99, 100, 7, 113, 2, 2, 100, 101, 7, 116, 2, 2, 101, 12, 3, 2, 2, 2, 102, 103, 7, 104, 2, 2, 103, 104, 7, 113, 2, 2, 104, 105, 7, 116, 2, 2, 105, 106, 7, 71, 2, 2, 106, 107, 7, 99, 2, 2, 107, 108, 7, 101, 2, 2, 108, 109, 7, 106, 2, 2, 109, 14, 3, 2, 2, 2, 110, 111, 7, 121, 2, 2, 111, 112, 7, 106, 2, 2, 112, 113, 7, 107, 2, 2, 113, 114, 7, 110, 2, 2, 114, 115, 7, 103, 2, 2, 115, 16, 3, 2, 2, 2, 116, 117, 7, 116, 2, 2, 117, 118, 7, 103, 2, 2, 118, 119, 7, 118, 2, 2, 119, 120, 7, 119, 2, 2, 120, 121, 7, 116, 2, 2, 121, 122, 7, 112, 2, 2, 122, 18, 3, 2, 2, 2, 123, 124, 7, 80, 2, 2, 124, 125, 7, 87, 2, 2, 125, 126, 7, 78, 2, 2, 126, 127, 7, 78, 2, 2, 127, 20, 3, 2, 2, 2, 128, 129, 7, 42, 2, 2, 129, 22, 3, 2, 2, 2, 130, 131, 7, 43, 2, 2, 131, 24, 3, 2, 2, 2, 132, 133, 7, 93, 2, 2, 133, 26, 3, 2, 2, 2, 134, 135, 7, 95, 2, 2, 135, 28, 3, 2, 2, 2, 136, 137, 7, 125, 2, 2, 137, 30, 3, 2, 2, 2, 138, 139, 7, 127, 2, 2, 139, 32, 3, 2, 2, 2, 140, 141, 7, 36, 2, 2, 141, 34, 3, 2, 2, 2, 142, 143, 7, 63, 2, 2, 143, 36, 3, 2, 2, 2, 144, 145, 7, 48, 2, 2, 145, 38, 3, 2, 2, 2, 146, 147, 7, 46, 2, 2, 147, 40, 3, 2, 2, 2, 148, 149, 7, 61, 2, 2, 149, 42, 3, 2, 2, 2, 150, 151, 7, 37, 2, 2, 151, 152, 7, 75, 2, 2, 152, 153, 7, 70, 2, 2, 153, 154, 7, 62, 2, 2, 154, 44, 3, 2, 2, 2, 155, 156, 7, 64, 2, 2, 156, 46, 3, 2, 2, 2, 157, 158, 7, 37, 2, 2, 158, 159, 7, 75, 2, 2, 159, 160, 7, 70, 2, 2, 160, 161, 7, 62, 2, 2, 161, 162, 7, 35, 2, 2, 162, 48, 3, 2, 2, 2, 163, 164, 7, 37, 2, 2, 164, 165, 7, 75, 2, 2, 165, 166, 7, 70, 2, 2, 166, 167, 7, 62, 2, 2, 167, 168, 7, 48, 2, 2, 168, 169, 7, 64, 2, 2, 169, 50, 3, 2, 2, 2, 170, 171, 7, 37, 2, 2, 171, 172, 7, 81, 2, 2, 172, 173, 7, 82, 2, 2, 173, 174, 7, 62, 2, 2, 174, 52, 3, 2, 2, 2, 175, 176, 7, 37, 2, 2, 176, 177, 7, 81, 2, 2, 177, 178, 7, 82, 2, 2, 178, 179, 7, 62, 2, 2, 179, 180, 7, 35, 2, 2, 180, 54, 3, 2, 2, 2, 181, 182, 7, 37, 2, 2, 182, 183, 7, 81, 2, 2, 183, 184, 7, 82, 2, 2, 184, 185, 7, 62, 2, 2, 185, 186, 7, 48, 2, 2, 186, 187, 7, 64, 2, 2, 187, 56, 3, 2, 2, 2, 188, 189, 7, 37, 2, 2, 189, 190, 7, 78, 2, 2, 190, 191, 7, 86, 2, 2, 191, 192, 7, 62, 2, 2, 192, 58, 3, 2, 2, 2, 193, 194, 7, 37, 2, 2, 194, 195, 7, 78, 2, 2, 195, 196, 7, 86, 2, 2, 196, 197, 7, 62, 2, 2, 197, 198, 7, 35, 2, 2, 198, 60, 3, 2, 2, 2, 199, 200, 7, 37, 2, 2, 200, 201, 7, 78, 2, 2, 201, 202, 7, 86, 2, 2, 202, 203, 7, 62, 2, 2, 203, 204, 7, 48, 2, 2, 204, 205, 7, 64, 2, 2, 205, 62, 3, 2, 2, 2, 206, 207, 7, 50, 2, 2, 207, 64, 3, 2, 2, 2, 208, 209, 7, 51, 2, 2, 209, 66, 3, 2, 2, 2, 210, 211, 7, 52, 2, 2, 211, 68, 3, 2, 2, 2, 212, 213, 7, 53, 2, 2, 213, 70, 3, 2, 2, 2, 214, 215, 7, 54, 2, 2, 215, 72, 3, 2, 2, 2, 216, 217, 7, 55, 2, 2, 217, 74, 3, 2, 2, 2, 218, 219, 7, 56, 2, 2, 219, 76, 3, 2, 2, 2, 220, 221, 7, 57, 2, 2, 221, 78, 3, 2, 2, 2, 222, 223, 7, 58, 2, 2, 223, 80, 3, 2, 2, 2, 224, 225, 7, 59, 2, 2, 225, 82, 3, 2, 2, 2, 226, 228, 9, 2, 2, 2, 227, 226, 3, 2, 2, 2, 228, 229, 3, 2, 2, 2, 229, 227, 3, 2, 2, 2, 229, 230, 3, 2, 2, 2, 230, 231, 3, 2, 2, 2, 231, 232, 8, 42, 2, 2, 232, 84, 3, 2, 2, 2, 4, 2, 229, 3, 8, 2, 2]
\ No newline at end of file
diff --git a/code/antlr4/.antlr/SearchLexer.java b/code/antlr4/.antlr/SearchLexer.java
new file mode 100644
index 0000000..fc4fc16
--- /dev/null
+++ b/code/antlr4/.antlr/SearchLexer.java
@@ -0,0 +1,188 @@
+// Generated from /home/luca/Desktop/Project/dSearch/code/antlr4/Search.g4 by ANTLR 4.7.1
+import org.antlr.v4.runtime.Lexer;
+import org.antlr.v4.runtime.CharStream;
+import org.antlr.v4.runtime.Token;
+import org.antlr.v4.runtime.TokenStream;
+import org.antlr.v4.runtime.*;
+import org.antlr.v4.runtime.atn.*;
+import org.antlr.v4.runtime.dfa.DFA;
+import org.antlr.v4.runtime.misc.*;
+
+@SuppressWarnings({"all", "warnings", "unchecked", "unused", "cast"})
+public class SearchLexer extends Lexer {
+	static { RuntimeMetaData.checkVersion("4.7.1", RuntimeMetaData.VERSION); }
+
+	protected static final DFA[] _decisionToDFA;
+	protected static final PredictionContextCache _sharedContextCache =
+		new PredictionContextCache();
+	public static final int
+		T__0=1, T__1=2, T__2=3, T__3=4, T__4=5, T__5=6, T__6=7, T__7=8, T__8=9, 
+		T__9=10, T__10=11, T__11=12, T__12=13, T__13=14, T__14=15, T__15=16, T__16=17, 
+		T__17=18, T__18=19, T__19=20, T__20=21, T__21=22, T__22=23, T__23=24, 
+		T__24=25, T__25=26, T__26=27, T__27=28, T__28=29, T__29=30, T__30=31, 
+		T__31=32, T__32=33, T__33=34, T__34=35, T__35=36, T__36=37, T__37=38, 
+		T__38=39, T__39=40, WS=41;
+	public static String[] channelNames = {
+		"DEFAULT_TOKEN_CHANNEL", "HIDDEN"
+	};
+
+	public static String[] modeNames = {
+		"DEFAULT_MODE"
+	};
+
+	public static final String[] ruleNames = {
+		"T__0", "T__1", "T__2", "T__3", "T__4", "T__5", "T__6", "T__7", "T__8", 
+		"T__9", "T__10", "T__11", "T__12", "T__13", "T__14", "T__15", "T__16", 
+		"T__17", "T__18", "T__19", "T__20", "T__21", "T__22", "T__23", "T__24", 
+		"T__25", "T__26", "T__27", "T__28", "T__29", "T__30", "T__31", "T__32", 
+		"T__33", "T__34", "T__35", "T__36", "T__37", "T__38", "T__39", "WS"
+	};
+
+	private static final String[] _LITERAL_NAMES = {
+		null, "'->'", "'_'", "'if'", "'else'", "'for'", "'forEach'", "'while'", 
+		"'return'", "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", 
+		"'='", "'.'", "','", "';'", "'#ID<'", "'>'", "'#ID<!'", "'#ID<.>'", "'#OP<'", 
+		"'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", "'#LT<.>'", "'0'", "'1'", 
+		"'2'", "'3'", "'4'", "'5'", "'6'", "'7'", "'8'", "'9'"
+	};
+	private static final String[] _SYMBOLIC_NAMES = {
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, "WS"
+	};
+	public static final Vocabulary VOCABULARY = new VocabularyImpl(_LITERAL_NAMES, _SYMBOLIC_NAMES);
+
+	/**
+	 * @deprecated Use {@link #VOCABULARY} instead.
+	 */
+	@Deprecated
+	public static final String[] tokenNames;
+	static {
+		tokenNames = new String[_SYMBOLIC_NAMES.length];
+		for (int i = 0; i < tokenNames.length; i++) {
+			tokenNames[i] = VOCABULARY.getLiteralName(i);
+			if (tokenNames[i] == null) {
+				tokenNames[i] = VOCABULARY.getSymbolicName(i);
+			}
+
+			if (tokenNames[i] == null) {
+				tokenNames[i] = "<INVALID>";
+			}
+		}
+	}
+
+	@Override
+	@Deprecated
+	public String[] getTokenNames() {
+		return tokenNames;
+	}
+
+	@Override
+
+	public Vocabulary getVocabulary() {
+		return VOCABULARY;
+	}
+
+
+	public SearchLexer(CharStream input) {
+		super(input);
+		_interp = new LexerATNSimulator(this,_ATN,_decisionToDFA,_sharedContextCache);
+	}
+
+	@Override
+	public String getGrammarFileName() { return "Search.g4"; }
+
+	@Override
+	public String[] getRuleNames() { return ruleNames; }
+
+	@Override
+	public String getSerializedATN() { return _serializedATN; }
+
+	@Override
+	public String[] getChannelNames() { return channelNames; }
+
+	@Override
+	public String[] getModeNames() { return modeNames; }
+
+	@Override
+	public ATN getATN() { return _ATN; }
+
+	public static final String _serializedATN =
+		"\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2+\u00e9\b\1\4\2\t"+
+		"\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13"+
+		"\t\13\4\f\t\f\4\r\t\r\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22"+
+		"\4\23\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30\4\31\t\31"+
+		"\4\32\t\32\4\33\t\33\4\34\t\34\4\35\t\35\4\36\t\36\4\37\t\37\4 \t \4!"+
+		"\t!\4\"\t\"\4#\t#\4$\t$\4%\t%\4&\t&\4\'\t\'\4(\t(\4)\t)\4*\t*\3\2\3\2"+
+		"\3\2\3\3\3\3\3\4\3\4\3\4\3\5\3\5\3\5\3\5\3\5\3\6\3\6\3\6\3\6\3\7\3\7\3"+
+		"\7\3\7\3\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\t\3\t\3\t\3\t\3\t\3\t"+
+		"\3\t\3\n\3\n\3\n\3\n\3\n\3\13\3\13\3\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17"+
+		"\3\20\3\20\3\21\3\21\3\22\3\22\3\23\3\23\3\24\3\24\3\25\3\25\3\26\3\26"+
+		"\3\26\3\26\3\26\3\27\3\27\3\30\3\30\3\30\3\30\3\30\3\30\3\31\3\31\3\31"+
+		"\3\31\3\31\3\31\3\31\3\32\3\32\3\32\3\32\3\32\3\33\3\33\3\33\3\33\3\33"+
+		"\3\33\3\34\3\34\3\34\3\34\3\34\3\34\3\34\3\35\3\35\3\35\3\35\3\35\3\36"+
+		"\3\36\3\36\3\36\3\36\3\36\3\37\3\37\3\37\3\37\3\37\3\37\3\37\3 \3 \3!"+
+		"\3!\3\"\3\"\3#\3#\3$\3$\3%\3%\3&\3&\3\'\3\'\3(\3(\3)\3)\3*\6*\u00e4\n"+
+		"*\r*\16*\u00e5\3*\3*\2\2+\3\3\5\4\7\5\t\6\13\7\r\b\17\t\21\n\23\13\25"+
+		"\f\27\r\31\16\33\17\35\20\37\21!\22#\23%\24\'\25)\26+\27-\30/\31\61\32"+
+		"\63\33\65\34\67\359\36;\37= ?!A\"C#E$G%I&K\'M(O)Q*S+\3\2\3\5\2\13\f\17"+
+		"\17\"\"\2\u00e9\2\3\3\2\2\2\2\5\3\2\2\2\2\7\3\2\2\2\2\t\3\2\2\2\2\13\3"+
+		"\2\2\2\2\r\3\2\2\2\2\17\3\2\2\2\2\21\3\2\2\2\2\23\3\2\2\2\2\25\3\2\2\2"+
+		"\2\27\3\2\2\2\2\31\3\2\2\2\2\33\3\2\2\2\2\35\3\2\2\2\2\37\3\2\2\2\2!\3"+
+		"\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2\'\3\2\2\2\2)\3\2\2\2\2+\3\2\2\2\2-\3\2"+
+		"\2\2\2/\3\2\2\2\2\61\3\2\2\2\2\63\3\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\2"+
+		"9\3\2\2\2\2;\3\2\2\2\2=\3\2\2\2\2?\3\2\2\2\2A\3\2\2\2\2C\3\2\2\2\2E\3"+
+		"\2\2\2\2G\3\2\2\2\2I\3\2\2\2\2K\3\2\2\2\2M\3\2\2\2\2O\3\2\2\2\2Q\3\2\2"+
+		"\2\2S\3\2\2\2\3U\3\2\2\2\5X\3\2\2\2\7Z\3\2\2\2\t]\3\2\2\2\13b\3\2\2\2"+
+		"\rf\3\2\2\2\17n\3\2\2\2\21t\3\2\2\2\23{\3\2\2\2\25\u0080\3\2\2\2\27\u0082"+
+		"\3\2\2\2\31\u0084\3\2\2\2\33\u0086\3\2\2\2\35\u0088\3\2\2\2\37\u008a\3"+
+		"\2\2\2!\u008c\3\2\2\2#\u008e\3\2\2\2%\u0090\3\2\2\2\'\u0092\3\2\2\2)\u0094"+
+		"\3\2\2\2+\u0096\3\2\2\2-\u009b\3\2\2\2/\u009d\3\2\2\2\61\u00a3\3\2\2\2"+
+		"\63\u00aa\3\2\2\2\65\u00af\3\2\2\2\67\u00b5\3\2\2\29\u00bc\3\2\2\2;\u00c1"+
+		"\3\2\2\2=\u00c7\3\2\2\2?\u00ce\3\2\2\2A\u00d0\3\2\2\2C\u00d2\3\2\2\2E"+
+		"\u00d4\3\2\2\2G\u00d6\3\2\2\2I\u00d8\3\2\2\2K\u00da\3\2\2\2M\u00dc\3\2"+
+		"\2\2O\u00de\3\2\2\2Q\u00e0\3\2\2\2S\u00e3\3\2\2\2UV\7/\2\2VW\7@\2\2W\4"+
+		"\3\2\2\2XY\7a\2\2Y\6\3\2\2\2Z[\7k\2\2[\\\7h\2\2\\\b\3\2\2\2]^\7g\2\2^"+
+		"_\7n\2\2_`\7u\2\2`a\7g\2\2a\n\3\2\2\2bc\7h\2\2cd\7q\2\2de\7t\2\2e\f\3"+
+		"\2\2\2fg\7h\2\2gh\7q\2\2hi\7t\2\2ij\7G\2\2jk\7c\2\2kl\7e\2\2lm\7j\2\2"+
+		"m\16\3\2\2\2no\7y\2\2op\7j\2\2pq\7k\2\2qr\7n\2\2rs\7g\2\2s\20\3\2\2\2"+
+		"tu\7t\2\2uv\7g\2\2vw\7v\2\2wx\7w\2\2xy\7t\2\2yz\7p\2\2z\22\3\2\2\2{|\7"+
+		"P\2\2|}\7W\2\2}~\7N\2\2~\177\7N\2\2\177\24\3\2\2\2\u0080\u0081\7*\2\2"+
+		"\u0081\26\3\2\2\2\u0082\u0083\7+\2\2\u0083\30\3\2\2\2\u0084\u0085\7]\2"+
+		"\2\u0085\32\3\2\2\2\u0086\u0087\7_\2\2\u0087\34\3\2\2\2\u0088\u0089\7"+
+		"}\2\2\u0089\36\3\2\2\2\u008a\u008b\7\177\2\2\u008b \3\2\2\2\u008c\u008d"+
+		"\7$\2\2\u008d\"\3\2\2\2\u008e\u008f\7?\2\2\u008f$\3\2\2\2\u0090\u0091"+
+		"\7\60\2\2\u0091&\3\2\2\2\u0092\u0093\7.\2\2\u0093(\3\2\2\2\u0094\u0095"+
+		"\7=\2\2\u0095*\3\2\2\2\u0096\u0097\7%\2\2\u0097\u0098\7K\2\2\u0098\u0099"+
+		"\7F\2\2\u0099\u009a\7>\2\2\u009a,\3\2\2\2\u009b\u009c\7@\2\2\u009c.\3"+
+		"\2\2\2\u009d\u009e\7%\2\2\u009e\u009f\7K\2\2\u009f\u00a0\7F\2\2\u00a0"+
+		"\u00a1\7>\2\2\u00a1\u00a2\7#\2\2\u00a2\60\3\2\2\2\u00a3\u00a4\7%\2\2\u00a4"+
+		"\u00a5\7K\2\2\u00a5\u00a6\7F\2\2\u00a6\u00a7\7>\2\2\u00a7\u00a8\7\60\2"+
+		"\2\u00a8\u00a9\7@\2\2\u00a9\62\3\2\2\2\u00aa\u00ab\7%\2\2\u00ab\u00ac"+
+		"\7Q\2\2\u00ac\u00ad\7R\2\2\u00ad\u00ae\7>\2\2\u00ae\64\3\2\2\2\u00af\u00b0"+
+		"\7%\2\2\u00b0\u00b1\7Q\2\2\u00b1\u00b2\7R\2\2\u00b2\u00b3\7>\2\2\u00b3"+
+		"\u00b4\7#\2\2\u00b4\66\3\2\2\2\u00b5\u00b6\7%\2\2\u00b6\u00b7\7Q\2\2\u00b7"+
+		"\u00b8\7R\2\2\u00b8\u00b9\7>\2\2\u00b9\u00ba\7\60\2\2\u00ba\u00bb\7@\2"+
+		"\2\u00bb8\3\2\2\2\u00bc\u00bd\7%\2\2\u00bd\u00be\7N\2\2\u00be\u00bf\7"+
+		"V\2\2\u00bf\u00c0\7>\2\2\u00c0:\3\2\2\2\u00c1\u00c2\7%\2\2\u00c2\u00c3"+
+		"\7N\2\2\u00c3\u00c4\7V\2\2\u00c4\u00c5\7>\2\2\u00c5\u00c6\7#\2\2\u00c6"+
+		"<\3\2\2\2\u00c7\u00c8\7%\2\2\u00c8\u00c9\7N\2\2\u00c9\u00ca\7V\2\2\u00ca"+
+		"\u00cb\7>\2\2\u00cb\u00cc\7\60\2\2\u00cc\u00cd\7@\2\2\u00cd>\3\2\2\2\u00ce"+
+		"\u00cf\7\62\2\2\u00cf@\3\2\2\2\u00d0\u00d1\7\63\2\2\u00d1B\3\2\2\2\u00d2"+
+		"\u00d3\7\64\2\2\u00d3D\3\2\2\2\u00d4\u00d5\7\65\2\2\u00d5F\3\2\2\2\u00d6"+
+		"\u00d7\7\66\2\2\u00d7H\3\2\2\2\u00d8\u00d9\7\67\2\2\u00d9J\3\2\2\2\u00da"+
+		"\u00db\78\2\2\u00dbL\3\2\2\2\u00dc\u00dd\79\2\2\u00ddN\3\2\2\2\u00de\u00df"+
+		"\7:\2\2\u00dfP\3\2\2\2\u00e0\u00e1\7;\2\2\u00e1R\3\2\2\2\u00e2\u00e4\t"+
+		"\2\2\2\u00e3\u00e2\3\2\2\2\u00e4\u00e5\3\2\2\2\u00e5\u00e3\3\2\2\2\u00e5"+
+		"\u00e6\3\2\2\2\u00e6\u00e7\3\2\2\2\u00e7\u00e8\b*\2\2\u00e8T\3\2\2\2\4"+
+		"\2\u00e5\3\b\2\2";
+	public static final ATN _ATN =
+		new ATNDeserializer().deserialize(_serializedATN.toCharArray());
+	static {
+		_decisionToDFA = new DFA[_ATN.getNumberOfDecisions()];
+		for (int i = 0; i < _ATN.getNumberOfDecisions(); i++) {
+			_decisionToDFA[i] = new DFA(_ATN.getDecisionState(i), i);
+		}
+	}
+}
\ No newline at end of file
diff --git a/code/antlr4/.antlr/SearchLexer.tokens b/code/antlr4/.antlr/SearchLexer.tokens
new file mode 100644
index 0000000..372bf0c
--- /dev/null
+++ b/code/antlr4/.antlr/SearchLexer.tokens
@@ -0,0 +1,81 @@
+T__0=1
+T__1=2
+T__2=3
+T__3=4
+T__4=5
+T__5=6
+T__6=7
+T__7=8
+T__8=9
+T__9=10
+T__10=11
+T__11=12
+T__12=13
+T__13=14
+T__14=15
+T__15=16
+T__16=17
+T__17=18
+T__18=19
+T__19=20
+T__20=21
+T__21=22
+T__22=23
+T__23=24
+T__24=25
+T__25=26
+T__26=27
+T__27=28
+T__28=29
+T__29=30
+T__30=31
+T__31=32
+T__32=33
+T__33=34
+T__34=35
+T__35=36
+T__36=37
+T__37=38
+T__38=39
+T__39=40
+WS=41
+'->'=1
+'_'=2
+'if'=3
+'else'=4
+'for'=5
+'forEach'=6
+'while'=7
+'return'=8
+'NULL'=9
+'('=10
+')'=11
+'['=12
+']'=13
+'{'=14
+'}'=15
+'"'=16
+'='=17
+'.'=18
+','=19
+';'=20
+'#ID<'=21
+'>'=22
+'#ID<!'=23
+'#ID<.>'=24
+'#OP<'=25
+'#OP<!'=26
+'#OP<.>'=27
+'#LT<'=28
+'#LT<!'=29
+'#LT<.>'=30
+'0'=31
+'1'=32
+'2'=33
+'3'=34
+'4'=35
+'5'=36
+'6'=37
+'7'=38
+'8'=39
+'9'=40
diff --git a/code/antlr4/.antlr/SearchParser.java b/code/antlr4/.antlr/SearchParser.java
new file mode 100644
index 0000000..139afe3
--- /dev/null
+++ b/code/antlr4/.antlr/SearchParser.java
@@ -0,0 +1,832 @@
+// Generated from /home/luca/Desktop/Project/dSearch/code/antlr4/Search.g4 by ANTLR 4.7.1
+import org.antlr.v4.runtime.atn.*;
+import org.antlr.v4.runtime.dfa.DFA;
+import org.antlr.v4.runtime.*;
+import org.antlr.v4.runtime.misc.*;
+import org.antlr.v4.runtime.tree.*;
+import java.util.List;
+import java.util.Iterator;
+import java.util.ArrayList;
+
+@SuppressWarnings({"all", "warnings", "unchecked", "unused", "cast"})
+public class SearchParser extends Parser {
+	static { RuntimeMetaData.checkVersion("4.7.1", RuntimeMetaData.VERSION); }
+
+	protected static final DFA[] _decisionToDFA;
+	protected static final PredictionContextCache _sharedContextCache =
+		new PredictionContextCache();
+	public static final int
+		T__0=1, T__1=2, T__2=3, T__3=4, T__4=5, T__5=6, T__6=7, T__7=8, T__8=9, 
+		T__9=10, T__10=11, T__11=12, T__12=13, T__13=14, T__14=15, T__15=16, T__16=17, 
+		T__17=18, T__18=19, T__19=20, T__20=21, T__21=22, T__22=23, T__23=24, 
+		T__24=25, T__25=26, T__26=27, T__27=28, T__28=29, T__29=30, T__30=31, 
+		T__31=32, T__32=33, T__33=34, T__34=35, T__35=36, T__36=37, T__37=38, 
+		T__38=39, T__39=40, WS=41;
+	public static final int
+		RULE_query = 0, RULE_code = 1, RULE_token = 2, RULE_keyword = 3, RULE_punctuator = 4, 
+		RULE_identifier = 5, RULE_operator = 6, RULE_literal = 7, RULE_digit = 8;
+	public static final String[] ruleNames = {
+		"query", "code", "token", "keyword", "punctuator", "identifier", "operator", 
+		"literal", "digit"
+	};
+
+	private static final String[] _LITERAL_NAMES = {
+		null, "'->'", "'_'", "'if'", "'else'", "'for'", "'forEach'", "'while'", 
+		"'return'", "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", 
+		"'='", "'.'", "','", "';'", "'#ID<'", "'>'", "'#ID<!'", "'#ID<.>'", "'#OP<'", 
+		"'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", "'#LT<.>'", "'0'", "'1'", 
+		"'2'", "'3'", "'4'", "'5'", "'6'", "'7'", "'8'", "'9'"
+	};
+	private static final String[] _SYMBOLIC_NAMES = {
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, "WS"
+	};
+	public static final Vocabulary VOCABULARY = new VocabularyImpl(_LITERAL_NAMES, _SYMBOLIC_NAMES);
+
+	/**
+	 * @deprecated Use {@link #VOCABULARY} instead.
+	 */
+	@Deprecated
+	public static final String[] tokenNames;
+	static {
+		tokenNames = new String[_SYMBOLIC_NAMES.length];
+		for (int i = 0; i < tokenNames.length; i++) {
+			tokenNames[i] = VOCABULARY.getLiteralName(i);
+			if (tokenNames[i] == null) {
+				tokenNames[i] = VOCABULARY.getSymbolicName(i);
+			}
+
+			if (tokenNames[i] == null) {
+				tokenNames[i] = "<INVALID>";
+			}
+		}
+	}
+
+	@Override
+	@Deprecated
+	public String[] getTokenNames() {
+		return tokenNames;
+	}
+
+	@Override
+
+	public Vocabulary getVocabulary() {
+		return VOCABULARY;
+	}
+
+	@Override
+	public String getGrammarFileName() { return "Search.g4"; }
+
+	@Override
+	public String[] getRuleNames() { return ruleNames; }
+
+	@Override
+	public String getSerializedATN() { return _serializedATN; }
+
+	@Override
+	public ATN getATN() { return _ATN; }
+
+	public SearchParser(TokenStream input) {
+		super(input);
+		_interp = new ParserATNSimulator(this,_ATN,_decisionToDFA,_sharedContextCache);
+	}
+	public static class QueryContext extends ParserRuleContext {
+		public List<CodeContext> code() {
+			return getRuleContexts(CodeContext.class);
+		}
+		public CodeContext code(int i) {
+			return getRuleContext(CodeContext.class,i);
+		}
+		public QueryContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_query; }
+	}
+
+	public final QueryContext query() throws RecognitionException {
+		QueryContext _localctx = new QueryContext(_ctx, getState());
+		enterRule(_localctx, 0, RULE_query);
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(18);
+			code();
+			setState(19);
+			match(T__0);
+			setState(20);
+			code();
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class CodeContext extends ParserRuleContext {
+		public List<TokenContext> token() {
+			return getRuleContexts(TokenContext.class);
+		}
+		public TokenContext token(int i) {
+			return getRuleContext(TokenContext.class,i);
+		}
+		public CodeContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_code; }
+	}
+
+	public final CodeContext code() throws RecognitionException {
+		CodeContext _localctx = new CodeContext(_ctx, getState());
+		enterRule(_localctx, 2, RULE_code);
+		int _la;
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(25);
+			_errHandler.sync(this);
+			_la = _input.LA(1);
+			while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+				{
+				{
+				setState(22);
+				token();
+				}
+				}
+				setState(27);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+			}
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class TokenContext extends ParserRuleContext {
+		public IdentifierContext identifier() {
+			return getRuleContext(IdentifierContext.class,0);
+		}
+		public KeywordContext keyword() {
+			return getRuleContext(KeywordContext.class,0);
+		}
+		public PunctuatorContext punctuator() {
+			return getRuleContext(PunctuatorContext.class,0);
+		}
+		public OperatorContext operator() {
+			return getRuleContext(OperatorContext.class,0);
+		}
+		public LiteralContext literal() {
+			return getRuleContext(LiteralContext.class,0);
+		}
+		public TokenContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_token; }
+	}
+
+	public final TokenContext token() throws RecognitionException {
+		TokenContext _localctx = new TokenContext(_ctx, getState());
+		enterRule(_localctx, 4, RULE_token);
+		try {
+			setState(34);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__20:
+			case T__22:
+			case T__23:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(28);
+				identifier();
+				}
+				break;
+			case T__2:
+			case T__3:
+			case T__4:
+			case T__5:
+			case T__6:
+			case T__7:
+			case T__8:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(29);
+				keyword();
+				}
+				break;
+			case T__9:
+			case T__11:
+			case T__13:
+			case T__15:
+			case T__16:
+			case T__17:
+			case T__18:
+			case T__19:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(30);
+				punctuator();
+				}
+				break;
+			case T__24:
+			case T__25:
+			case T__26:
+				enterOuterAlt(_localctx, 4);
+				{
+				setState(31);
+				operator();
+				}
+				break;
+			case T__27:
+			case T__28:
+			case T__29:
+				enterOuterAlt(_localctx, 5);
+				{
+				setState(32);
+				literal();
+				}
+				break;
+			case T__1:
+				enterOuterAlt(_localctx, 6);
+				{
+				setState(33);
+				match(T__1);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class KeywordContext extends ParserRuleContext {
+		public KeywordContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_keyword; }
+	}
+
+	public final KeywordContext keyword() throws RecognitionException {
+		KeywordContext _localctx = new KeywordContext(_ctx, getState());
+		enterRule(_localctx, 6, RULE_keyword);
+		int _la;
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(36);
+			_la = _input.LA(1);
+			if ( !((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8))) != 0)) ) {
+			_errHandler.recoverInline(this);
+			}
+			else {
+				if ( _input.LA(1)==Token.EOF ) matchedEOF = true;
+				_errHandler.reportMatch(this);
+				consume();
+			}
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class PunctuatorContext extends ParserRuleContext {
+		public List<TokenContext> token() {
+			return getRuleContexts(TokenContext.class);
+		}
+		public TokenContext token(int i) {
+			return getRuleContext(TokenContext.class,i);
+		}
+		public PunctuatorContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_punctuator; }
+	}
+
+	public final PunctuatorContext punctuator() throws RecognitionException {
+		PunctuatorContext _localctx = new PunctuatorContext(_ctx, getState());
+		enterRule(_localctx, 8, RULE_punctuator);
+		int _la;
+		try {
+			int _alt;
+			setState(74);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__9:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(38);
+				match(T__9);
+				setState(42);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+					{
+					{
+					setState(39);
+					token();
+					}
+					}
+					setState(44);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(45);
+				match(T__10);
+				}
+				break;
+			case T__11:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(46);
+				match(T__11);
+				setState(50);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+					{
+					{
+					setState(47);
+					token();
+					}
+					}
+					setState(52);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(53);
+				match(T__12);
+				}
+				break;
+			case T__13:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(54);
+				match(T__13);
+				setState(58);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+					{
+					{
+					setState(55);
+					token();
+					}
+					}
+					setState(60);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(61);
+				match(T__14);
+				}
+				break;
+			case T__15:
+				enterOuterAlt(_localctx, 4);
+				{
+				setState(62);
+				match(T__15);
+				setState(66);
+				_errHandler.sync(this);
+				_alt = getInterpreter().adaptivePredict(_input,5,_ctx);
+				while ( _alt!=2 && _alt!=org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER ) {
+					if ( _alt==1 ) {
+						{
+						{
+						setState(63);
+						token();
+						}
+						} 
+					}
+					setState(68);
+					_errHandler.sync(this);
+					_alt = getInterpreter().adaptivePredict(_input,5,_ctx);
+				}
+				setState(69);
+				match(T__15);
+				}
+				break;
+			case T__16:
+				enterOuterAlt(_localctx, 5);
+				{
+				setState(70);
+				match(T__16);
+				}
+				break;
+			case T__17:
+				enterOuterAlt(_localctx, 6);
+				{
+				setState(71);
+				match(T__17);
+				}
+				break;
+			case T__18:
+				enterOuterAlt(_localctx, 7);
+				{
+				setState(72);
+				match(T__18);
+				}
+				break;
+			case T__19:
+				enterOuterAlt(_localctx, 8);
+				{
+				setState(73);
+				match(T__19);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class IdentifierContext extends ParserRuleContext {
+		public List<DigitContext> digit() {
+			return getRuleContexts(DigitContext.class);
+		}
+		public DigitContext digit(int i) {
+			return getRuleContext(DigitContext.class,i);
+		}
+		public IdentifierContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_identifier; }
+	}
+
+	public final IdentifierContext identifier() throws RecognitionException {
+		IdentifierContext _localctx = new IdentifierContext(_ctx, getState());
+		enterRule(_localctx, 10, RULE_identifier);
+		int _la;
+		try {
+			setState(93);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__20:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(76);
+				match(T__20);
+				setState(80);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(77);
+					digit();
+					}
+					}
+					setState(82);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(83);
+				match(T__21);
+				}
+				break;
+			case T__22:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(84);
+				match(T__22);
+				setState(88);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(85);
+					digit();
+					}
+					}
+					setState(90);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(91);
+				match(T__21);
+				}
+				break;
+			case T__23:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(92);
+				match(T__23);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class OperatorContext extends ParserRuleContext {
+		public List<DigitContext> digit() {
+			return getRuleContexts(DigitContext.class);
+		}
+		public DigitContext digit(int i) {
+			return getRuleContext(DigitContext.class,i);
+		}
+		public OperatorContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_operator; }
+	}
+
+	public final OperatorContext operator() throws RecognitionException {
+		OperatorContext _localctx = new OperatorContext(_ctx, getState());
+		enterRule(_localctx, 12, RULE_operator);
+		int _la;
+		try {
+			setState(112);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__24:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(95);
+				match(T__24);
+				setState(99);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(96);
+					digit();
+					}
+					}
+					setState(101);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(102);
+				match(T__21);
+				}
+				break;
+			case T__25:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(103);
+				match(T__25);
+				setState(107);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(104);
+					digit();
+					}
+					}
+					setState(109);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(110);
+				match(T__21);
+				}
+				break;
+			case T__26:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(111);
+				match(T__26);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class LiteralContext extends ParserRuleContext {
+		public List<DigitContext> digit() {
+			return getRuleContexts(DigitContext.class);
+		}
+		public DigitContext digit(int i) {
+			return getRuleContext(DigitContext.class,i);
+		}
+		public LiteralContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_literal; }
+	}
+
+	public final LiteralContext literal() throws RecognitionException {
+		LiteralContext _localctx = new LiteralContext(_ctx, getState());
+		enterRule(_localctx, 14, RULE_literal);
+		int _la;
+		try {
+			setState(131);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__27:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(114);
+				match(T__27);
+				setState(118);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(115);
+					digit();
+					}
+					}
+					setState(120);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(121);
+				match(T__21);
+				}
+				break;
+			case T__28:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(122);
+				match(T__28);
+				setState(126);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(123);
+					digit();
+					}
+					}
+					setState(128);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(129);
+				match(T__21);
+				}
+				break;
+			case T__29:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(130);
+				match(T__29);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class DigitContext extends ParserRuleContext {
+		public DigitContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_digit; }
+	}
+
+	public final DigitContext digit() throws RecognitionException {
+		DigitContext _localctx = new DigitContext(_ctx, getState());
+		enterRule(_localctx, 16, RULE_digit);
+		int _la;
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(133);
+			_la = _input.LA(1);
+			if ( !((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) ) {
+			_errHandler.recoverInline(this);
+			}
+			else {
+				if ( _input.LA(1)==Token.EOF ) matchedEOF = true;
+				_errHandler.reportMatch(this);
+				consume();
+			}
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static final String _serializedATN =
+		"\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3+\u008a\4\2\t\2\4"+
+		"\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7\4\b\t\b\4\t\t\t\4\n\t\n\3\2\3\2"+
+		"\3\2\3\2\3\3\7\3\32\n\3\f\3\16\3\35\13\3\3\4\3\4\3\4\3\4\3\4\3\4\5\4%"+
+		"\n\4\3\5\3\5\3\6\3\6\7\6+\n\6\f\6\16\6.\13\6\3\6\3\6\3\6\7\6\63\n\6\f"+
+		"\6\16\6\66\13\6\3\6\3\6\3\6\7\6;\n\6\f\6\16\6>\13\6\3\6\3\6\3\6\7\6C\n"+
+		"\6\f\6\16\6F\13\6\3\6\3\6\3\6\3\6\3\6\5\6M\n\6\3\7\3\7\7\7Q\n\7\f\7\16"+
+		"\7T\13\7\3\7\3\7\3\7\7\7Y\n\7\f\7\16\7\\\13\7\3\7\3\7\5\7`\n\7\3\b\3\b"+
+		"\7\bd\n\b\f\b\16\bg\13\b\3\b\3\b\3\b\7\bl\n\b\f\b\16\bo\13\b\3\b\3\b\5"+
+		"\bs\n\b\3\t\3\t\7\tw\n\t\f\t\16\tz\13\t\3\t\3\t\3\t\7\t\177\n\t\f\t\16"+
+		"\t\u0082\13\t\3\t\3\t\5\t\u0086\n\t\3\n\3\n\3\n\2\2\13\2\4\6\b\n\f\16"+
+		"\20\22\2\4\3\2\5\13\3\2!*\2\u009d\2\24\3\2\2\2\4\33\3\2\2\2\6$\3\2\2\2"+
+		"\b&\3\2\2\2\nL\3\2\2\2\f_\3\2\2\2\16r\3\2\2\2\20\u0085\3\2\2\2\22\u0087"+
+		"\3\2\2\2\24\25\5\4\3\2\25\26\7\3\2\2\26\27\5\4\3\2\27\3\3\2\2\2\30\32"+
+		"\5\6\4\2\31\30\3\2\2\2\32\35\3\2\2\2\33\31\3\2\2\2\33\34\3\2\2\2\34\5"+
+		"\3\2\2\2\35\33\3\2\2\2\36%\5\f\7\2\37%\5\b\5\2 %\5\n\6\2!%\5\16\b\2\""+
+		"%\5\20\t\2#%\7\4\2\2$\36\3\2\2\2$\37\3\2\2\2$ \3\2\2\2$!\3\2\2\2$\"\3"+
+		"\2\2\2$#\3\2\2\2%\7\3\2\2\2&\'\t\2\2\2\'\t\3\2\2\2(,\7\f\2\2)+\5\6\4\2"+
+		"*)\3\2\2\2+.\3\2\2\2,*\3\2\2\2,-\3\2\2\2-/\3\2\2\2.,\3\2\2\2/M\7\r\2\2"+
+		"\60\64\7\16\2\2\61\63\5\6\4\2\62\61\3\2\2\2\63\66\3\2\2\2\64\62\3\2\2"+
+		"\2\64\65\3\2\2\2\65\67\3\2\2\2\66\64\3\2\2\2\67M\7\17\2\28<\7\20\2\29"+
+		";\5\6\4\2:9\3\2\2\2;>\3\2\2\2<:\3\2\2\2<=\3\2\2\2=?\3\2\2\2><\3\2\2\2"+
+		"?M\7\21\2\2@D\7\22\2\2AC\5\6\4\2BA\3\2\2\2CF\3\2\2\2DB\3\2\2\2DE\3\2\2"+
+		"\2EG\3\2\2\2FD\3\2\2\2GM\7\22\2\2HM\7\23\2\2IM\7\24\2\2JM\7\25\2\2KM\7"+
+		"\26\2\2L(\3\2\2\2L\60\3\2\2\2L8\3\2\2\2L@\3\2\2\2LH\3\2\2\2LI\3\2\2\2"+
+		"LJ\3\2\2\2LK\3\2\2\2M\13\3\2\2\2NR\7\27\2\2OQ\5\22\n\2PO\3\2\2\2QT\3\2"+
+		"\2\2RP\3\2\2\2RS\3\2\2\2SU\3\2\2\2TR\3\2\2\2U`\7\30\2\2VZ\7\31\2\2WY\5"+
+		"\22\n\2XW\3\2\2\2Y\\\3\2\2\2ZX\3\2\2\2Z[\3\2\2\2[]\3\2\2\2\\Z\3\2\2\2"+
+		"]`\7\30\2\2^`\7\32\2\2_N\3\2\2\2_V\3\2\2\2_^\3\2\2\2`\r\3\2\2\2ae\7\33"+
+		"\2\2bd\5\22\n\2cb\3\2\2\2dg\3\2\2\2ec\3\2\2\2ef\3\2\2\2fh\3\2\2\2ge\3"+
+		"\2\2\2hs\7\30\2\2im\7\34\2\2jl\5\22\n\2kj\3\2\2\2lo\3\2\2\2mk\3\2\2\2"+
+		"mn\3\2\2\2np\3\2\2\2om\3\2\2\2ps\7\30\2\2qs\7\35\2\2ra\3\2\2\2ri\3\2\2"+
+		"\2rq\3\2\2\2s\17\3\2\2\2tx\7\36\2\2uw\5\22\n\2vu\3\2\2\2wz\3\2\2\2xv\3"+
+		"\2\2\2xy\3\2\2\2y{\3\2\2\2zx\3\2\2\2{\u0086\7\30\2\2|\u0080\7\37\2\2}"+
+		"\177\5\22\n\2~}\3\2\2\2\177\u0082\3\2\2\2\u0080~\3\2\2\2\u0080\u0081\3"+
+		"\2\2\2\u0081\u0083\3\2\2\2\u0082\u0080\3\2\2\2\u0083\u0086\7\30\2\2\u0084"+
+		"\u0086\7 \2\2\u0085t\3\2\2\2\u0085|\3\2\2\2\u0085\u0084\3\2\2\2\u0086"+
+		"\21\3\2\2\2\u0087\u0088\t\3\2\2\u0088\23\3\2\2\2\22\33$,\64<DLRZ_emrx"+
+		"\u0080\u0085";
+	public static final ATN _ATN =
+		new ATNDeserializer().deserialize(_serializedATN.toCharArray());
+	static {
+		_decisionToDFA = new DFA[_ATN.getNumberOfDecisions()];
+		for (int i = 0; i < _ATN.getNumberOfDecisions(); i++) {
+			_decisionToDFA[i] = new DFA(_ATN.getDecisionState(i), i);
+		}
+	}
+}
\ No newline at end of file
diff --git a/code/antlr4/Search.g4 b/code/antlr4/Search.g4
index 1f7fd42..dfdb50c 100644
--- a/code/antlr4/Search.g4
+++ b/code/antlr4/Search.g4
@@ -1,58 +1,22 @@
 grammar Search;
 
-query: expr '->' expr;
-
-expr: token*;
-
-token: identifier 
-	| keyword 
-	| punctuator 
-	| op
-	| '_';
-
-identifier: '#ID<' digit* '>' | '#N<' digit* '>' | '#ID<.>' | '#N<.>' ;
-
-digit:  '0'
-	|'1'
-	|'2'
-	|'3'
-	|'4'
-	|'5'
-	|'6'
-	|'7'
-	|'8'
-	|'9';
-
-keyword: 'if' 
-	| 'else' 
-	| 'for' 
-	| 'forEach' 
-	| 'while' 
-	| 'return' 
-	| 'NULL';
-
-punctuator: '('token*')'
-	| '['token*']'
-	| '{'token*'}'
-	| '"'token*'"'
-	| '='
-	| '.'
-	| ','
-	| ';';
-
-op:     '+' 
-	| '−' 
-	| '*' 
-	| '/'
-	| '==' 
-	| '<' 
-	| '>' 
-	| '<='
-	| '>='
-	| '==' 
-	| '!=' 
-	| '&&'
-	| '||'
-	| '#OP<' digit* '>' ;
-
-WS:     [ \t\r\n]+ -> skip ;
+query: code '->' code;
+
+code: token*;
+
+token: identifier | keyword | punctuator | operator| literal| '_';
+
+keyword: 'if' | 'else' | 'for' | 'forEach' | 'while' | 'return' | 'NULL';
+
+punctuator: '('token*')' | '['token*']' | '{'token*'}'| '"'token*'"'| '='| '.'| ',' | ';';
+
+identifier: '#ID<' digit* '>' | '#ID<!' digit* '>' | '#ID<.>';
+
+operator: '#OP<' digit* '>' | '#OP<!' digit* '>' | '#OP<.>';
+
+literal: '#LT<' digit* '>' | '#LT<!' digit* '>' | '#LT<.>';
+
+digit:  '0' | '1' | '2' | '3' | '4' | '5' | '6' |'7' | '8' | '9';
+
+
+WS:     [ \t\r\n]+ -> skip ;
\ No newline at end of file
diff --git a/code/antlr4/SearchLexer.py b/code/antlr4/SearchLexer.py
index d1ff21d..440f5f6 100644
--- a/code/antlr4/SearchLexer.py
+++ b/code/antlr4/SearchLexer.py
@@ -7,101 +7,94 @@ import sys
 
 def serializedATN():
     with StringIO() as buf:
-        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2\62")
-        buf.write("\u00f8\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
+        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2+")
+        buf.write("\u00e9\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
         buf.write("\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r")
         buf.write("\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23")
         buf.write("\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30")
         buf.write("\4\31\t\31\4\32\t\32\4\33\t\33\4\34\t\34\4\35\t\35\4\36")
         buf.write("\t\36\4\37\t\37\4 \t \4!\t!\4\"\t\"\4#\t#\4$\t$\4%\t%")
-        buf.write("\4&\t&\4\'\t\'\4(\t(\4)\t)\4*\t*\4+\t+\4,\t,\4-\t-\4.")
-        buf.write("\t.\4/\t/\4\60\t\60\4\61\t\61\3\2\3\2\3\2\3\3\3\3\3\4")
-        buf.write("\3\4\3\4\3\4\3\4\3\5\3\5\3\6\3\6\3\6\3\6\3\7\3\7\3\7\3")
-        buf.write("\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\t\3\t\3\n\3\n")
-        buf.write("\3\13\3\13\3\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17\3\20\3")
-        buf.write("\20\3\21\3\21\3\22\3\22\3\23\3\23\3\23\3\24\3\24\3\24")
-        buf.write("\3\24\3\24\3\25\3\25\3\25\3\25\3\26\3\26\3\26\3\26\3\26")
-        buf.write("\3\26\3\26\3\26\3\27\3\27\3\27\3\27\3\27\3\27\3\30\3\30")
-        buf.write("\3\30\3\30\3\30\3\30\3\30\3\31\3\31\3\31\3\31\3\31\3\32")
-        buf.write("\3\32\3\33\3\33\3\34\3\34\3\35\3\35\3\36\3\36\3\37\3\37")
-        buf.write("\3 \3 \3!\3!\3\"\3\"\3#\3#\3$\3$\3%\3%\3&\3&\3\'\3\'\3")
-        buf.write("(\3(\3)\3)\3)\3*\3*\3+\3+\3+\3,\3,\3,\3-\3-\3-\3.\3.\3")
-        buf.write(".\3/\3/\3/\3\60\3\60\3\60\3\60\3\60\3\61\6\61\u00f3\n")
-        buf.write("\61\r\61\16\61\u00f4\3\61\3\61\2\2\62\3\3\5\4\7\5\t\6")
-        buf.write("\13\7\r\b\17\t\21\n\23\13\25\f\27\r\31\16\33\17\35\20")
-        buf.write("\37\21!\22#\23%\24\'\25)\26+\27-\30/\31\61\32\63\33\65")
-        buf.write("\34\67\359\36;\37= ?!A\"C#E$G%I&K\'M(O)Q*S+U,W-Y.[/]\60")
-        buf.write("_\61a\62\3\2\3\5\2\13\f\17\17\"\"\2\u00f8\2\3\3\2\2\2")
-        buf.write("\2\5\3\2\2\2\2\7\3\2\2\2\2\t\3\2\2\2\2\13\3\2\2\2\2\r")
-        buf.write("\3\2\2\2\2\17\3\2\2\2\2\21\3\2\2\2\2\23\3\2\2\2\2\25\3")
-        buf.write("\2\2\2\2\27\3\2\2\2\2\31\3\2\2\2\2\33\3\2\2\2\2\35\3\2")
-        buf.write("\2\2\2\37\3\2\2\2\2!\3\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2\'")
-        buf.write("\3\2\2\2\2)\3\2\2\2\2+\3\2\2\2\2-\3\2\2\2\2/\3\2\2\2\2")
-        buf.write("\61\3\2\2\2\2\63\3\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\29")
-        buf.write("\3\2\2\2\2;\3\2\2\2\2=\3\2\2\2\2?\3\2\2\2\2A\3\2\2\2\2")
-        buf.write("C\3\2\2\2\2E\3\2\2\2\2G\3\2\2\2\2I\3\2\2\2\2K\3\2\2\2")
-        buf.write("\2M\3\2\2\2\2O\3\2\2\2\2Q\3\2\2\2\2S\3\2\2\2\2U\3\2\2")
-        buf.write("\2\2W\3\2\2\2\2Y\3\2\2\2\2[\3\2\2\2\2]\3\2\2\2\2_\3\2")
-        buf.write("\2\2\2a\3\2\2\2\3c\3\2\2\2\5f\3\2\2\2\7h\3\2\2\2\tm\3")
-        buf.write("\2\2\2\13o\3\2\2\2\rs\3\2\2\2\17z\3\2\2\2\21\u0080\3\2")
-        buf.write("\2\2\23\u0082\3\2\2\2\25\u0084\3\2\2\2\27\u0086\3\2\2")
-        buf.write("\2\31\u0088\3\2\2\2\33\u008a\3\2\2\2\35\u008c\3\2\2\2")
-        buf.write("\37\u008e\3\2\2\2!\u0090\3\2\2\2#\u0092\3\2\2\2%\u0094")
-        buf.write("\3\2\2\2\'\u0097\3\2\2\2)\u009c\3\2\2\2+\u00a0\3\2\2\2")
-        buf.write("-\u00a8\3\2\2\2/\u00ae\3\2\2\2\61\u00b5\3\2\2\2\63\u00ba")
-        buf.write("\3\2\2\2\65\u00bc\3\2\2\2\67\u00be\3\2\2\29\u00c0\3\2")
-        buf.write("\2\2;\u00c2\3\2\2\2=\u00c4\3\2\2\2?\u00c6\3\2\2\2A\u00c8")
-        buf.write("\3\2\2\2C\u00ca\3\2\2\2E\u00cc\3\2\2\2G\u00ce\3\2\2\2")
-        buf.write("I\u00d0\3\2\2\2K\u00d2\3\2\2\2M\u00d4\3\2\2\2O\u00d6\3")
-        buf.write("\2\2\2Q\u00d8\3\2\2\2S\u00db\3\2\2\2U\u00dd\3\2\2\2W\u00e0")
-        buf.write("\3\2\2\2Y\u00e3\3\2\2\2[\u00e6\3\2\2\2]\u00e9\3\2\2\2")
-        buf.write("_\u00ec\3\2\2\2a\u00f2\3\2\2\2cd\7/\2\2de\7@\2\2e\4\3")
-        buf.write("\2\2\2fg\7a\2\2g\6\3\2\2\2hi\7%\2\2ij\7K\2\2jk\7F\2\2")
-        buf.write("kl\7>\2\2l\b\3\2\2\2mn\7@\2\2n\n\3\2\2\2op\7%\2\2pq\7")
-        buf.write("P\2\2qr\7>\2\2r\f\3\2\2\2st\7%\2\2tu\7K\2\2uv\7F\2\2v")
-        buf.write("w\7>\2\2wx\7\60\2\2xy\7@\2\2y\16\3\2\2\2z{\7%\2\2{|\7")
-        buf.write("P\2\2|}\7>\2\2}~\7\60\2\2~\177\7@\2\2\177\20\3\2\2\2\u0080")
-        buf.write("\u0081\7\62\2\2\u0081\22\3\2\2\2\u0082\u0083\7\63\2\2")
-        buf.write("\u0083\24\3\2\2\2\u0084\u0085\7\64\2\2\u0085\26\3\2\2")
-        buf.write("\2\u0086\u0087\7\65\2\2\u0087\30\3\2\2\2\u0088\u0089\7")
-        buf.write("\66\2\2\u0089\32\3\2\2\2\u008a\u008b\7\67\2\2\u008b\34")
-        buf.write("\3\2\2\2\u008c\u008d\78\2\2\u008d\36\3\2\2\2\u008e\u008f")
-        buf.write("\79\2\2\u008f \3\2\2\2\u0090\u0091\7:\2\2\u0091\"\3\2")
-        buf.write("\2\2\u0092\u0093\7;\2\2\u0093$\3\2\2\2\u0094\u0095\7k")
-        buf.write("\2\2\u0095\u0096\7h\2\2\u0096&\3\2\2\2\u0097\u0098\7g")
-        buf.write("\2\2\u0098\u0099\7n\2\2\u0099\u009a\7u\2\2\u009a\u009b")
-        buf.write("\7g\2\2\u009b(\3\2\2\2\u009c\u009d\7h\2\2\u009d\u009e")
-        buf.write("\7q\2\2\u009e\u009f\7t\2\2\u009f*\3\2\2\2\u00a0\u00a1")
-        buf.write("\7h\2\2\u00a1\u00a2\7q\2\2\u00a2\u00a3\7t\2\2\u00a3\u00a4")
-        buf.write("\7G\2\2\u00a4\u00a5\7c\2\2\u00a5\u00a6\7e\2\2\u00a6\u00a7")
-        buf.write("\7j\2\2\u00a7,\3\2\2\2\u00a8\u00a9\7y\2\2\u00a9\u00aa")
-        buf.write("\7j\2\2\u00aa\u00ab\7k\2\2\u00ab\u00ac\7n\2\2\u00ac\u00ad")
-        buf.write("\7g\2\2\u00ad.\3\2\2\2\u00ae\u00af\7t\2\2\u00af\u00b0")
-        buf.write("\7g\2\2\u00b0\u00b1\7v\2\2\u00b1\u00b2\7w\2\2\u00b2\u00b3")
-        buf.write("\7t\2\2\u00b3\u00b4\7p\2\2\u00b4\60\3\2\2\2\u00b5\u00b6")
-        buf.write("\7P\2\2\u00b6\u00b7\7W\2\2\u00b7\u00b8\7N\2\2\u00b8\u00b9")
-        buf.write("\7N\2\2\u00b9\62\3\2\2\2\u00ba\u00bb\7*\2\2\u00bb\64\3")
-        buf.write("\2\2\2\u00bc\u00bd\7+\2\2\u00bd\66\3\2\2\2\u00be\u00bf")
-        buf.write("\7]\2\2\u00bf8\3\2\2\2\u00c0\u00c1\7_\2\2\u00c1:\3\2\2")
-        buf.write("\2\u00c2\u00c3\7}\2\2\u00c3<\3\2\2\2\u00c4\u00c5\7\177")
-        buf.write("\2\2\u00c5>\3\2\2\2\u00c6\u00c7\7$\2\2\u00c7@\3\2\2\2")
-        buf.write("\u00c8\u00c9\7?\2\2\u00c9B\3\2\2\2\u00ca\u00cb\7\60\2")
-        buf.write("\2\u00cbD\3\2\2\2\u00cc\u00cd\7.\2\2\u00cdF\3\2\2\2\u00ce")
-        buf.write("\u00cf\7=\2\2\u00cfH\3\2\2\2\u00d0\u00d1\7-\2\2\u00d1")
-        buf.write("J\3\2\2\2\u00d2\u00d3\7\u2214\2\2\u00d3L\3\2\2\2\u00d4")
-        buf.write("\u00d5\7,\2\2\u00d5N\3\2\2\2\u00d6\u00d7\7\61\2\2\u00d7")
-        buf.write("P\3\2\2\2\u00d8\u00d9\7?\2\2\u00d9\u00da\7?\2\2\u00da")
-        buf.write("R\3\2\2\2\u00db\u00dc\7>\2\2\u00dcT\3\2\2\2\u00dd\u00de")
-        buf.write("\7>\2\2\u00de\u00df\7?\2\2\u00dfV\3\2\2\2\u00e0\u00e1")
-        buf.write("\7@\2\2\u00e1\u00e2\7?\2\2\u00e2X\3\2\2\2\u00e3\u00e4")
-        buf.write("\7#\2\2\u00e4\u00e5\7?\2\2\u00e5Z\3\2\2\2\u00e6\u00e7")
-        buf.write("\7(\2\2\u00e7\u00e8\7(\2\2\u00e8\\\3\2\2\2\u00e9\u00ea")
-        buf.write("\7~\2\2\u00ea\u00eb\7~\2\2\u00eb^\3\2\2\2\u00ec\u00ed")
-        buf.write("\7%\2\2\u00ed\u00ee\7Q\2\2\u00ee\u00ef\7R\2\2\u00ef\u00f0")
-        buf.write("\7>\2\2\u00f0`\3\2\2\2\u00f1\u00f3\t\2\2\2\u00f2\u00f1")
-        buf.write("\3\2\2\2\u00f3\u00f4\3\2\2\2\u00f4\u00f2\3\2\2\2\u00f4")
-        buf.write("\u00f5\3\2\2\2\u00f5\u00f6\3\2\2\2\u00f6\u00f7\b\61\2")
-        buf.write("\2\u00f7b\3\2\2\2\4\2\u00f4\3\b\2\2")
+        buf.write("\4&\t&\4\'\t\'\4(\t(\4)\t)\4*\t*\3\2\3\2\3\2\3\3\3\3\3")
+        buf.write("\4\3\4\3\4\3\5\3\5\3\5\3\5\3\5\3\6\3\6\3\6\3\6\3\7\3\7")
+        buf.write("\3\7\3\7\3\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\t\3")
+        buf.write("\t\3\t\3\t\3\t\3\t\3\t\3\n\3\n\3\n\3\n\3\n\3\13\3\13\3")
+        buf.write("\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17\3\20\3\20\3\21\3\21")
+        buf.write("\3\22\3\22\3\23\3\23\3\24\3\24\3\25\3\25\3\26\3\26\3\26")
+        buf.write("\3\26\3\26\3\27\3\27\3\30\3\30\3\30\3\30\3\30\3\30\3\31")
+        buf.write("\3\31\3\31\3\31\3\31\3\31\3\31\3\32\3\32\3\32\3\32\3\32")
+        buf.write("\3\33\3\33\3\33\3\33\3\33\3\33\3\34\3\34\3\34\3\34\3\34")
+        buf.write("\3\34\3\34\3\35\3\35\3\35\3\35\3\35\3\36\3\36\3\36\3\36")
+        buf.write("\3\36\3\36\3\37\3\37\3\37\3\37\3\37\3\37\3\37\3 \3 \3")
+        buf.write("!\3!\3\"\3\"\3#\3#\3$\3$\3%\3%\3&\3&\3\'\3\'\3(\3(\3)")
+        buf.write("\3)\3*\6*\u00e4\n*\r*\16*\u00e5\3*\3*\2\2+\3\3\5\4\7\5")
+        buf.write("\t\6\13\7\r\b\17\t\21\n\23\13\25\f\27\r\31\16\33\17\35")
+        buf.write("\20\37\21!\22#\23%\24\'\25)\26+\27-\30/\31\61\32\63\33")
+        buf.write("\65\34\67\359\36;\37= ?!A\"C#E$G%I&K\'M(O)Q*S+\3\2\3\5")
+        buf.write("\2\13\f\17\17\"\"\2\u00e9\2\3\3\2\2\2\2\5\3\2\2\2\2\7")
+        buf.write("\3\2\2\2\2\t\3\2\2\2\2\13\3\2\2\2\2\r\3\2\2\2\2\17\3\2")
+        buf.write("\2\2\2\21\3\2\2\2\2\23\3\2\2\2\2\25\3\2\2\2\2\27\3\2\2")
+        buf.write("\2\2\31\3\2\2\2\2\33\3\2\2\2\2\35\3\2\2\2\2\37\3\2\2\2")
+        buf.write("\2!\3\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2\'\3\2\2\2\2)\3\2\2")
+        buf.write("\2\2+\3\2\2\2\2-\3\2\2\2\2/\3\2\2\2\2\61\3\2\2\2\2\63")
+        buf.write("\3\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\29\3\2\2\2\2;\3\2\2")
+        buf.write("\2\2=\3\2\2\2\2?\3\2\2\2\2A\3\2\2\2\2C\3\2\2\2\2E\3\2")
+        buf.write("\2\2\2G\3\2\2\2\2I\3\2\2\2\2K\3\2\2\2\2M\3\2\2\2\2O\3")
+        buf.write("\2\2\2\2Q\3\2\2\2\2S\3\2\2\2\3U\3\2\2\2\5X\3\2\2\2\7Z")
+        buf.write("\3\2\2\2\t]\3\2\2\2\13b\3\2\2\2\rf\3\2\2\2\17n\3\2\2\2")
+        buf.write("\21t\3\2\2\2\23{\3\2\2\2\25\u0080\3\2\2\2\27\u0082\3\2")
+        buf.write("\2\2\31\u0084\3\2\2\2\33\u0086\3\2\2\2\35\u0088\3\2\2")
+        buf.write("\2\37\u008a\3\2\2\2!\u008c\3\2\2\2#\u008e\3\2\2\2%\u0090")
+        buf.write("\3\2\2\2\'\u0092\3\2\2\2)\u0094\3\2\2\2+\u0096\3\2\2\2")
+        buf.write("-\u009b\3\2\2\2/\u009d\3\2\2\2\61\u00a3\3\2\2\2\63\u00aa")
+        buf.write("\3\2\2\2\65\u00af\3\2\2\2\67\u00b5\3\2\2\29\u00bc\3\2")
+        buf.write("\2\2;\u00c1\3\2\2\2=\u00c7\3\2\2\2?\u00ce\3\2\2\2A\u00d0")
+        buf.write("\3\2\2\2C\u00d2\3\2\2\2E\u00d4\3\2\2\2G\u00d6\3\2\2\2")
+        buf.write("I\u00d8\3\2\2\2K\u00da\3\2\2\2M\u00dc\3\2\2\2O\u00de\3")
+        buf.write("\2\2\2Q\u00e0\3\2\2\2S\u00e3\3\2\2\2UV\7/\2\2VW\7@\2\2")
+        buf.write("W\4\3\2\2\2XY\7a\2\2Y\6\3\2\2\2Z[\7k\2\2[\\\7h\2\2\\\b")
+        buf.write("\3\2\2\2]^\7g\2\2^_\7n\2\2_`\7u\2\2`a\7g\2\2a\n\3\2\2")
+        buf.write("\2bc\7h\2\2cd\7q\2\2de\7t\2\2e\f\3\2\2\2fg\7h\2\2gh\7")
+        buf.write("q\2\2hi\7t\2\2ij\7G\2\2jk\7c\2\2kl\7e\2\2lm\7j\2\2m\16")
+        buf.write("\3\2\2\2no\7y\2\2op\7j\2\2pq\7k\2\2qr\7n\2\2rs\7g\2\2")
+        buf.write("s\20\3\2\2\2tu\7t\2\2uv\7g\2\2vw\7v\2\2wx\7w\2\2xy\7t")
+        buf.write("\2\2yz\7p\2\2z\22\3\2\2\2{|\7P\2\2|}\7W\2\2}~\7N\2\2~")
+        buf.write("\177\7N\2\2\177\24\3\2\2\2\u0080\u0081\7*\2\2\u0081\26")
+        buf.write("\3\2\2\2\u0082\u0083\7+\2\2\u0083\30\3\2\2\2\u0084\u0085")
+        buf.write("\7]\2\2\u0085\32\3\2\2\2\u0086\u0087\7_\2\2\u0087\34\3")
+        buf.write("\2\2\2\u0088\u0089\7}\2\2\u0089\36\3\2\2\2\u008a\u008b")
+        buf.write("\7\177\2\2\u008b \3\2\2\2\u008c\u008d\7$\2\2\u008d\"\3")
+        buf.write("\2\2\2\u008e\u008f\7?\2\2\u008f$\3\2\2\2\u0090\u0091\7")
+        buf.write("\60\2\2\u0091&\3\2\2\2\u0092\u0093\7.\2\2\u0093(\3\2\2")
+        buf.write("\2\u0094\u0095\7=\2\2\u0095*\3\2\2\2\u0096\u0097\7%\2")
+        buf.write("\2\u0097\u0098\7K\2\2\u0098\u0099\7F\2\2\u0099\u009a\7")
+        buf.write(">\2\2\u009a,\3\2\2\2\u009b\u009c\7@\2\2\u009c.\3\2\2\2")
+        buf.write("\u009d\u009e\7%\2\2\u009e\u009f\7K\2\2\u009f\u00a0\7F")
+        buf.write("\2\2\u00a0\u00a1\7>\2\2\u00a1\u00a2\7#\2\2\u00a2\60\3")
+        buf.write("\2\2\2\u00a3\u00a4\7%\2\2\u00a4\u00a5\7K\2\2\u00a5\u00a6")
+        buf.write("\7F\2\2\u00a6\u00a7\7>\2\2\u00a7\u00a8\7\60\2\2\u00a8")
+        buf.write("\u00a9\7@\2\2\u00a9\62\3\2\2\2\u00aa\u00ab\7%\2\2\u00ab")
+        buf.write("\u00ac\7Q\2\2\u00ac\u00ad\7R\2\2\u00ad\u00ae\7>\2\2\u00ae")
+        buf.write("\64\3\2\2\2\u00af\u00b0\7%\2\2\u00b0\u00b1\7Q\2\2\u00b1")
+        buf.write("\u00b2\7R\2\2\u00b2\u00b3\7>\2\2\u00b3\u00b4\7#\2\2\u00b4")
+        buf.write("\66\3\2\2\2\u00b5\u00b6\7%\2\2\u00b6\u00b7\7Q\2\2\u00b7")
+        buf.write("\u00b8\7R\2\2\u00b8\u00b9\7>\2\2\u00b9\u00ba\7\60\2\2")
+        buf.write("\u00ba\u00bb\7@\2\2\u00bb8\3\2\2\2\u00bc\u00bd\7%\2\2")
+        buf.write("\u00bd\u00be\7N\2\2\u00be\u00bf\7V\2\2\u00bf\u00c0\7>")
+        buf.write("\2\2\u00c0:\3\2\2\2\u00c1\u00c2\7%\2\2\u00c2\u00c3\7N")
+        buf.write("\2\2\u00c3\u00c4\7V\2\2\u00c4\u00c5\7>\2\2\u00c5\u00c6")
+        buf.write("\7#\2\2\u00c6<\3\2\2\2\u00c7\u00c8\7%\2\2\u00c8\u00c9")
+        buf.write("\7N\2\2\u00c9\u00ca\7V\2\2\u00ca\u00cb\7>\2\2\u00cb\u00cc")
+        buf.write("\7\60\2\2\u00cc\u00cd\7@\2\2\u00cd>\3\2\2\2\u00ce\u00cf")
+        buf.write("\7\62\2\2\u00cf@\3\2\2\2\u00d0\u00d1\7\63\2\2\u00d1B\3")
+        buf.write("\2\2\2\u00d2\u00d3\7\64\2\2\u00d3D\3\2\2\2\u00d4\u00d5")
+        buf.write("\7\65\2\2\u00d5F\3\2\2\2\u00d6\u00d7\7\66\2\2\u00d7H\3")
+        buf.write("\2\2\2\u00d8\u00d9\7\67\2\2\u00d9J\3\2\2\2\u00da\u00db")
+        buf.write("\78\2\2\u00dbL\3\2\2\2\u00dc\u00dd\79\2\2\u00ddN\3\2\2")
+        buf.write("\2\u00de\u00df\7:\2\2\u00dfP\3\2\2\2\u00e0\u00e1\7;\2")
+        buf.write("\2\u00e1R\3\2\2\2\u00e2\u00e4\t\2\2\2\u00e3\u00e2\3\2")
+        buf.write("\2\2\u00e4\u00e5\3\2\2\2\u00e5\u00e3\3\2\2\2\u00e5\u00e6")
+        buf.write("\3\2\2\2\u00e6\u00e7\3\2\2\2\u00e7\u00e8\b*\2\2\u00e8")
+        buf.write("T\3\2\2\2\4\2\u00e5\3\b\2\2")
         return buf.getvalue()
 
 
@@ -151,26 +144,19 @@ class SearchLexer(Lexer):
     T__37 = 38
     T__38 = 39
     T__39 = 40
-    T__40 = 41
-    T__41 = 42
-    T__42 = 43
-    T__43 = 44
-    T__44 = 45
-    T__45 = 46
-    T__46 = 47
-    WS = 48
+    WS = 41
 
     channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]
 
     modeNames = [ "DEFAULT_MODE" ]
 
     literalNames = [ "<INVALID>",
-            "'->'", "'_'", "'#ID<'", "'>'", "'#N<'", "'#ID<.>'", "'#N<.>'", 
-            "'0'", "'1'", "'2'", "'3'", "'4'", "'5'", "'6'", "'7'", "'8'", 
-            "'9'", "'if'", "'else'", "'for'", "'forEach'", "'while'", "'return'", 
-            "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", 
-            "'='", "'.'", "','", "';'", "'+'", "'\u2212'", "'*'", "'/'", 
-            "'=='", "'<'", "'<='", "'>='", "'!='", "'&&'", "'||'", "'#OP<'" ]
+            "'->'", "'_'", "'if'", "'else'", "'for'", "'forEach'", "'while'", 
+            "'return'", "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", 
+            "'\"'", "'='", "'.'", "','", "';'", "'#ID<'", "'>'", "'#ID<!'", 
+            "'#ID<.>'", "'#OP<'", "'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", 
+            "'#LT<.>'", "'0'", "'1'", "'2'", "'3'", "'4'", "'5'", "'6'", 
+            "'7'", "'8'", "'9'" ]
 
     symbolicNames = [ "<INVALID>",
             "WS" ]
@@ -181,8 +167,7 @@ class SearchLexer(Lexer):
                   "T__20", "T__21", "T__22", "T__23", "T__24", "T__25", 
                   "T__26", "T__27", "T__28", "T__29", "T__30", "T__31", 
                   "T__32", "T__33", "T__34", "T__35", "T__36", "T__37", 
-                  "T__38", "T__39", "T__40", "T__41", "T__42", "T__43", 
-                  "T__44", "T__45", "T__46", "WS" ]
+                  "T__38", "T__39", "WS" ]
 
     grammarFileName = "Search.g4"
 
diff --git a/code/antlr4/SearchListener.py b/code/antlr4/SearchListener.py
index 1879435..41f83c2 100644
--- a/code/antlr4/SearchListener.py
+++ b/code/antlr4/SearchListener.py
@@ -17,12 +17,12 @@ class SearchListener(ParseTreeListener):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#expr.
-    def enterExpr(self, ctx:SearchParser.ExprContext):
+    # Enter a parse tree produced by SearchParser#code.
+    def enterCode(self, ctx:SearchParser.CodeContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#expr.
-    def exitExpr(self, ctx:SearchParser.ExprContext):
+    # Exit a parse tree produced by SearchParser#code.
+    def exitCode(self, ctx:SearchParser.CodeContext):
         pass
 
 
@@ -35,48 +35,57 @@ class SearchListener(ParseTreeListener):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#identifier.
-    def enterIdentifier(self, ctx:SearchParser.IdentifierContext):
+    # Enter a parse tree produced by SearchParser#keyword.
+    def enterKeyword(self, ctx:SearchParser.KeywordContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#identifier.
-    def exitIdentifier(self, ctx:SearchParser.IdentifierContext):
+    # Exit a parse tree produced by SearchParser#keyword.
+    def exitKeyword(self, ctx:SearchParser.KeywordContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#digit.
-    def enterDigit(self, ctx:SearchParser.DigitContext):
+    # Enter a parse tree produced by SearchParser#punctuator.
+    def enterPunctuator(self, ctx:SearchParser.PunctuatorContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#digit.
-    def exitDigit(self, ctx:SearchParser.DigitContext):
+    # Exit a parse tree produced by SearchParser#punctuator.
+    def exitPunctuator(self, ctx:SearchParser.PunctuatorContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#keyword.
-    def enterKeyword(self, ctx:SearchParser.KeywordContext):
+    # Enter a parse tree produced by SearchParser#identifier.
+    def enterIdentifier(self, ctx:SearchParser.IdentifierContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#keyword.
-    def exitKeyword(self, ctx:SearchParser.KeywordContext):
+    # Exit a parse tree produced by SearchParser#identifier.
+    def exitIdentifier(self, ctx:SearchParser.IdentifierContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#punctuator.
-    def enterPunctuator(self, ctx:SearchParser.PunctuatorContext):
+    # Enter a parse tree produced by SearchParser#operator.
+    def enterOperator(self, ctx:SearchParser.OperatorContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#punctuator.
-    def exitPunctuator(self, ctx:SearchParser.PunctuatorContext):
+    # Exit a parse tree produced by SearchParser#operator.
+    def exitOperator(self, ctx:SearchParser.OperatorContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#op.
-    def enterOp(self, ctx:SearchParser.OpContext):
+    # Enter a parse tree produced by SearchParser#literal.
+    def enterLiteral(self, ctx:SearchParser.LiteralContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#op.
-    def exitOp(self, ctx:SearchParser.OpContext):
+    # Exit a parse tree produced by SearchParser#literal.
+    def exitLiteral(self, ctx:SearchParser.LiteralContext):
+        pass
+
+
+    # Enter a parse tree produced by SearchParser#digit.
+    def enterDigit(self, ctx:SearchParser.DigitContext):
+        pass
+
+    # Exit a parse tree produced by SearchParser#digit.
+    def exitDigit(self, ctx:SearchParser.DigitContext):
         pass
 
 
diff --git a/code/antlr4/SearchParser.py b/code/antlr4/SearchParser.py
index 64b4fa5..800cb84 100644
--- a/code/antlr4/SearchParser.py
+++ b/code/antlr4/SearchParser.py
@@ -7,48 +7,54 @@ import sys
 
 def serializedATN():
     with StringIO() as buf:
-        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3\62")
-        buf.write("y\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7\4\b")
-        buf.write("\t\b\4\t\t\t\3\2\3\2\3\2\3\2\3\3\7\3\30\n\3\f\3\16\3\33")
-        buf.write("\13\3\3\4\3\4\3\4\3\4\3\4\5\4\"\n\4\3\5\3\5\7\5&\n\5\f")
-        buf.write("\5\16\5)\13\5\3\5\3\5\3\5\7\5.\n\5\f\5\16\5\61\13\5\3")
-        buf.write("\5\3\5\3\5\5\5\66\n\5\3\6\3\6\3\7\3\7\3\b\3\b\7\b>\n\b")
-        buf.write("\f\b\16\bA\13\b\3\b\3\b\3\b\7\bF\n\b\f\b\16\bI\13\b\3")
-        buf.write("\b\3\b\3\b\7\bN\n\b\f\b\16\bQ\13\b\3\b\3\b\3\b\7\bV\n")
-        buf.write("\b\f\b\16\bY\13\b\3\b\3\b\3\b\3\b\3\b\5\b`\n\b\3\t\3\t")
-        buf.write("\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\7")
-        buf.write("\tq\n\t\f\t\16\tt\13\t\3\t\5\tw\n\t\3\t\2\2\n\2\4\6\b")
-        buf.write("\n\f\16\20\2\4\3\2\n\23\3\2\24\32\2\u0093\2\22\3\2\2\2")
-        buf.write("\4\31\3\2\2\2\6!\3\2\2\2\b\65\3\2\2\2\n\67\3\2\2\2\f9")
-        buf.write("\3\2\2\2\16_\3\2\2\2\20v\3\2\2\2\22\23\5\4\3\2\23\24\7")
-        buf.write("\3\2\2\24\25\5\4\3\2\25\3\3\2\2\2\26\30\5\6\4\2\27\26")
-        buf.write("\3\2\2\2\30\33\3\2\2\2\31\27\3\2\2\2\31\32\3\2\2\2\32")
-        buf.write("\5\3\2\2\2\33\31\3\2\2\2\34\"\5\b\5\2\35\"\5\f\7\2\36")
-        buf.write("\"\5\16\b\2\37\"\5\20\t\2 \"\7\4\2\2!\34\3\2\2\2!\35\3")
-        buf.write("\2\2\2!\36\3\2\2\2!\37\3\2\2\2! \3\2\2\2\"\7\3\2\2\2#")
-        buf.write("\'\7\5\2\2$&\5\n\6\2%$\3\2\2\2&)\3\2\2\2\'%\3\2\2\2\'")
-        buf.write("(\3\2\2\2(*\3\2\2\2)\'\3\2\2\2*\66\7\6\2\2+/\7\7\2\2,")
-        buf.write(".\5\n\6\2-,\3\2\2\2.\61\3\2\2\2/-\3\2\2\2/\60\3\2\2\2")
-        buf.write("\60\62\3\2\2\2\61/\3\2\2\2\62\66\7\6\2\2\63\66\7\b\2\2")
-        buf.write("\64\66\7\t\2\2\65#\3\2\2\2\65+\3\2\2\2\65\63\3\2\2\2\65")
-        buf.write("\64\3\2\2\2\66\t\3\2\2\2\678\t\2\2\28\13\3\2\2\29:\t\3")
-        buf.write("\2\2:\r\3\2\2\2;?\7\33\2\2<>\5\6\4\2=<\3\2\2\2>A\3\2\2")
-        buf.write("\2?=\3\2\2\2?@\3\2\2\2@B\3\2\2\2A?\3\2\2\2B`\7\34\2\2")
-        buf.write("CG\7\35\2\2DF\5\6\4\2ED\3\2\2\2FI\3\2\2\2GE\3\2\2\2GH")
-        buf.write("\3\2\2\2HJ\3\2\2\2IG\3\2\2\2J`\7\36\2\2KO\7\37\2\2LN\5")
-        buf.write("\6\4\2ML\3\2\2\2NQ\3\2\2\2OM\3\2\2\2OP\3\2\2\2PR\3\2\2")
-        buf.write("\2QO\3\2\2\2R`\7 \2\2SW\7!\2\2TV\5\6\4\2UT\3\2\2\2VY\3")
-        buf.write("\2\2\2WU\3\2\2\2WX\3\2\2\2XZ\3\2\2\2YW\3\2\2\2Z`\7!\2")
-        buf.write("\2[`\7\"\2\2\\`\7#\2\2]`\7$\2\2^`\7%\2\2_;\3\2\2\2_C\3")
-        buf.write("\2\2\2_K\3\2\2\2_S\3\2\2\2_[\3\2\2\2_\\\3\2\2\2_]\3\2")
-        buf.write("\2\2_^\3\2\2\2`\17\3\2\2\2aw\7&\2\2bw\7\'\2\2cw\7(\2\2")
-        buf.write("dw\7)\2\2ew\7*\2\2fw\7+\2\2gw\7\6\2\2hw\7,\2\2iw\7-\2")
-        buf.write("\2jw\7*\2\2kw\7.\2\2lw\7/\2\2mw\7\60\2\2nr\7\61\2\2oq")
-        buf.write("\5\n\6\2po\3\2\2\2qt\3\2\2\2rp\3\2\2\2rs\3\2\2\2su\3\2")
-        buf.write("\2\2tr\3\2\2\2uw\7\6\2\2va\3\2\2\2vb\3\2\2\2vc\3\2\2\2")
-        buf.write("vd\3\2\2\2ve\3\2\2\2vf\3\2\2\2vg\3\2\2\2vh\3\2\2\2vi\3")
-        buf.write("\2\2\2vj\3\2\2\2vk\3\2\2\2vl\3\2\2\2vm\3\2\2\2vn\3\2\2")
-        buf.write("\2w\21\3\2\2\2\16\31!\'/\65?GOW_rv")
+        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3+")
+        buf.write("\u008a\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7")
+        buf.write("\4\b\t\b\4\t\t\t\4\n\t\n\3\2\3\2\3\2\3\2\3\3\7\3\32\n")
+        buf.write("\3\f\3\16\3\35\13\3\3\4\3\4\3\4\3\4\3\4\3\4\5\4%\n\4\3")
+        buf.write("\5\3\5\3\6\3\6\7\6+\n\6\f\6\16\6.\13\6\3\6\3\6\3\6\7\6")
+        buf.write("\63\n\6\f\6\16\6\66\13\6\3\6\3\6\3\6\7\6;\n\6\f\6\16\6")
+        buf.write(">\13\6\3\6\3\6\3\6\7\6C\n\6\f\6\16\6F\13\6\3\6\3\6\3\6")
+        buf.write("\3\6\3\6\5\6M\n\6\3\7\3\7\7\7Q\n\7\f\7\16\7T\13\7\3\7")
+        buf.write("\3\7\3\7\7\7Y\n\7\f\7\16\7\\\13\7\3\7\3\7\5\7`\n\7\3\b")
+        buf.write("\3\b\7\bd\n\b\f\b\16\bg\13\b\3\b\3\b\3\b\7\bl\n\b\f\b")
+        buf.write("\16\bo\13\b\3\b\3\b\5\bs\n\b\3\t\3\t\7\tw\n\t\f\t\16\t")
+        buf.write("z\13\t\3\t\3\t\3\t\7\t\177\n\t\f\t\16\t\u0082\13\t\3\t")
+        buf.write("\3\t\5\t\u0086\n\t\3\n\3\n\3\n\2\2\13\2\4\6\b\n\f\16\20")
+        buf.write("\22\2\4\3\2\5\13\3\2!*\2\u009d\2\24\3\2\2\2\4\33\3\2\2")
+        buf.write("\2\6$\3\2\2\2\b&\3\2\2\2\nL\3\2\2\2\f_\3\2\2\2\16r\3\2")
+        buf.write("\2\2\20\u0085\3\2\2\2\22\u0087\3\2\2\2\24\25\5\4\3\2\25")
+        buf.write("\26\7\3\2\2\26\27\5\4\3\2\27\3\3\2\2\2\30\32\5\6\4\2\31")
+        buf.write("\30\3\2\2\2\32\35\3\2\2\2\33\31\3\2\2\2\33\34\3\2\2\2")
+        buf.write("\34\5\3\2\2\2\35\33\3\2\2\2\36%\5\f\7\2\37%\5\b\5\2 %")
+        buf.write("\5\n\6\2!%\5\16\b\2\"%\5\20\t\2#%\7\4\2\2$\36\3\2\2\2")
+        buf.write("$\37\3\2\2\2$ \3\2\2\2$!\3\2\2\2$\"\3\2\2\2$#\3\2\2\2")
+        buf.write("%\7\3\2\2\2&\'\t\2\2\2\'\t\3\2\2\2(,\7\f\2\2)+\5\6\4\2")
+        buf.write("*)\3\2\2\2+.\3\2\2\2,*\3\2\2\2,-\3\2\2\2-/\3\2\2\2.,\3")
+        buf.write("\2\2\2/M\7\r\2\2\60\64\7\16\2\2\61\63\5\6\4\2\62\61\3")
+        buf.write("\2\2\2\63\66\3\2\2\2\64\62\3\2\2\2\64\65\3\2\2\2\65\67")
+        buf.write("\3\2\2\2\66\64\3\2\2\2\67M\7\17\2\28<\7\20\2\29;\5\6\4")
+        buf.write("\2:9\3\2\2\2;>\3\2\2\2<:\3\2\2\2<=\3\2\2\2=?\3\2\2\2>")
+        buf.write("<\3\2\2\2?M\7\21\2\2@D\7\22\2\2AC\5\6\4\2BA\3\2\2\2CF")
+        buf.write("\3\2\2\2DB\3\2\2\2DE\3\2\2\2EG\3\2\2\2FD\3\2\2\2GM\7\22")
+        buf.write("\2\2HM\7\23\2\2IM\7\24\2\2JM\7\25\2\2KM\7\26\2\2L(\3\2")
+        buf.write("\2\2L\60\3\2\2\2L8\3\2\2\2L@\3\2\2\2LH\3\2\2\2LI\3\2\2")
+        buf.write("\2LJ\3\2\2\2LK\3\2\2\2M\13\3\2\2\2NR\7\27\2\2OQ\5\22\n")
+        buf.write("\2PO\3\2\2\2QT\3\2\2\2RP\3\2\2\2RS\3\2\2\2SU\3\2\2\2T")
+        buf.write("R\3\2\2\2U`\7\30\2\2VZ\7\31\2\2WY\5\22\n\2XW\3\2\2\2Y")
+        buf.write("\\\3\2\2\2ZX\3\2\2\2Z[\3\2\2\2[]\3\2\2\2\\Z\3\2\2\2]`")
+        buf.write("\7\30\2\2^`\7\32\2\2_N\3\2\2\2_V\3\2\2\2_^\3\2\2\2`\r")
+        buf.write("\3\2\2\2ae\7\33\2\2bd\5\22\n\2cb\3\2\2\2dg\3\2\2\2ec\3")
+        buf.write("\2\2\2ef\3\2\2\2fh\3\2\2\2ge\3\2\2\2hs\7\30\2\2im\7\34")
+        buf.write("\2\2jl\5\22\n\2kj\3\2\2\2lo\3\2\2\2mk\3\2\2\2mn\3\2\2")
+        buf.write("\2np\3\2\2\2om\3\2\2\2ps\7\30\2\2qs\7\35\2\2ra\3\2\2\2")
+        buf.write("ri\3\2\2\2rq\3\2\2\2s\17\3\2\2\2tx\7\36\2\2uw\5\22\n\2")
+        buf.write("vu\3\2\2\2wz\3\2\2\2xv\3\2\2\2xy\3\2\2\2y{\3\2\2\2zx\3")
+        buf.write("\2\2\2{\u0086\7\30\2\2|\u0080\7\37\2\2}\177\5\22\n\2~")
+        buf.write("}\3\2\2\2\177\u0082\3\2\2\2\u0080~\3\2\2\2\u0080\u0081")
+        buf.write("\3\2\2\2\u0081\u0083\3\2\2\2\u0082\u0080\3\2\2\2\u0083")
+        buf.write("\u0086\7\30\2\2\u0084\u0086\7 \2\2\u0085t\3\2\2\2\u0085")
+        buf.write("|\3\2\2\2\u0085\u0084\3\2\2\2\u0086\21\3\2\2\2\u0087\u0088")
+        buf.write("\t\3\2\2\u0088\23\3\2\2\2\22\33$,\64<DLRZ_emrx\u0080\u0085")
         return buf.getvalue()
 
 
@@ -62,14 +68,13 @@ class SearchParser ( Parser ):
 
     sharedContextCache = PredictionContextCache()
 
-    literalNames = [ "<INVALID>", "'->'", "'_'", "'#ID<'", "'>'", "'#N<'", 
-                     "'#ID<.>'", "'#N<.>'", "'0'", "'1'", "'2'", "'3'", 
-                     "'4'", "'5'", "'6'", "'7'", "'8'", "'9'", "'if'", "'else'", 
-                     "'for'", "'forEach'", "'while'", "'return'", "'NULL'", 
-                     "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", "'='", 
-                     "'.'", "','", "';'", "'+'", "'\u2212'", "'*'", "'/'", 
-                     "'=='", "'<'", "'<='", "'>='", "'!='", "'&&'", "'||'", 
-                     "'#OP<'" ]
+    literalNames = [ "<INVALID>", "'->'", "'_'", "'if'", "'else'", "'for'", 
+                     "'forEach'", "'while'", "'return'", "'NULL'", "'('", 
+                     "')'", "'['", "']'", "'{'", "'}'", "'\"'", "'='", "'.'", 
+                     "','", "';'", "'#ID<'", "'>'", "'#ID<!'", "'#ID<.>'", 
+                     "'#OP<'", "'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", 
+                     "'#LT<.>'", "'0'", "'1'", "'2'", "'3'", "'4'", "'5'", 
+                     "'6'", "'7'", "'8'", "'9'" ]
 
     symbolicNames = [ "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
@@ -81,21 +86,20 @@ class SearchParser ( Parser ):
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
-                      "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
-                      "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
-                      "WS" ]
+                      "<INVALID>", "WS" ]
 
     RULE_query = 0
-    RULE_expr = 1
+    RULE_code = 1
     RULE_token = 2
-    RULE_identifier = 3
-    RULE_digit = 4
-    RULE_keyword = 5
-    RULE_punctuator = 6
-    RULE_op = 7
+    RULE_keyword = 3
+    RULE_punctuator = 4
+    RULE_identifier = 5
+    RULE_operator = 6
+    RULE_literal = 7
+    RULE_digit = 8
 
-    ruleNames =  [ "query", "expr", "token", "identifier", "digit", "keyword", 
-                   "punctuator", "op" ]
+    ruleNames =  [ "query", "code", "token", "keyword", "punctuator", "identifier", 
+                   "operator", "literal", "digit" ]
 
     EOF = Token.EOF
     T__0=1
@@ -138,14 +142,7 @@ class SearchParser ( Parser ):
     T__37=38
     T__38=39
     T__39=40
-    T__40=41
-    T__41=42
-    T__42=43
-    T__43=44
-    T__44=45
-    T__45=46
-    T__46=47
-    WS=48
+    WS=41
 
     def __init__(self, input:TokenStream, output:TextIO = sys.stdout):
         super().__init__(input, output)
@@ -161,11 +158,11 @@ class SearchParser ( Parser ):
             super().__init__(parent, invokingState)
             self.parser = parser
 
-        def expr(self, i:int=None):
+        def code(self, i:int=None):
             if i is None:
-                return self.getTypedRuleContexts(SearchParser.ExprContext)
+                return self.getTypedRuleContexts(SearchParser.CodeContext)
             else:
-                return self.getTypedRuleContext(SearchParser.ExprContext,i)
+                return self.getTypedRuleContext(SearchParser.CodeContext,i)
 
 
         def getRuleIndex(self):
@@ -188,12 +185,12 @@ class SearchParser ( Parser ):
         self.enterRule(localctx, 0, self.RULE_query)
         try:
             self.enterOuterAlt(localctx, 1)
-            self.state = 16
-            self.expr()
-            self.state = 17
-            self.match(SearchParser.T__0)
             self.state = 18
-            self.expr()
+            self.code()
+            self.state = 19
+            self.match(SearchParser.T__0)
+            self.state = 20
+            self.code()
         except RecognitionException as re:
             localctx.exception = re
             self._errHandler.reportError(self, re)
@@ -202,7 +199,7 @@ class SearchParser ( Parser ):
             self.exitRule()
         return localctx
 
-    class ExprContext(ParserRuleContext):
+    class CodeContext(ParserRuleContext):
 
         def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
             super().__init__(parent, invokingState)
@@ -216,33 +213,33 @@ class SearchParser ( Parser ):
 
 
         def getRuleIndex(self):
-            return SearchParser.RULE_expr
+            return SearchParser.RULE_code
 
         def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterExpr" ):
-                listener.enterExpr(self)
+            if hasattr( listener, "enterCode" ):
+                listener.enterCode(self)
 
         def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitExpr" ):
-                listener.exitExpr(self)
+            if hasattr( listener, "exitCode" ):
+                listener.exitCode(self)
 
 
 
 
-    def expr(self):
+    def code(self):
 
-        localctx = SearchParser.ExprContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 2, self.RULE_expr)
+        localctx = SearchParser.CodeContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 2, self.RULE_code)
         self._la = 0 # Token type
         try:
             self.enterOuterAlt(localctx, 1)
-            self.state = 23
+            self.state = 25
             self._errHandler.sync(self)
             _la = self._input.LA(1)
-            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                self.state = 20
+            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                self.state = 22
                 self.token()
-                self.state = 25
+                self.state = 27
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
 
@@ -272,8 +269,12 @@ class SearchParser ( Parser ):
             return self.getTypedRuleContext(SearchParser.PunctuatorContext,0)
 
 
-        def op(self):
-            return self.getTypedRuleContext(SearchParser.OpContext,0)
+        def operator(self):
+            return self.getTypedRuleContext(SearchParser.OperatorContext,0)
+
+
+        def literal(self):
+            return self.getTypedRuleContext(SearchParser.LiteralContext,0)
 
 
         def getRuleIndex(self):
@@ -295,124 +296,38 @@ class SearchParser ( Parser ):
         localctx = SearchParser.TokenContext(self, self._ctx, self.state)
         self.enterRule(localctx, 4, self.RULE_token)
         try:
-            self.state = 31
+            self.state = 34
             self._errHandler.sync(self)
             token = self._input.LA(1)
-            if token in [SearchParser.T__2, SearchParser.T__4, SearchParser.T__5, SearchParser.T__6]:
+            if token in [SearchParser.T__20, SearchParser.T__22, SearchParser.T__23]:
                 self.enterOuterAlt(localctx, 1)
-                self.state = 26
+                self.state = 28
                 self.identifier()
                 pass
-            elif token in [SearchParser.T__17, SearchParser.T__18, SearchParser.T__19, SearchParser.T__20, SearchParser.T__21, SearchParser.T__22, SearchParser.T__23]:
+            elif token in [SearchParser.T__2, SearchParser.T__3, SearchParser.T__4, SearchParser.T__5, SearchParser.T__6, SearchParser.T__7, SearchParser.T__8]:
                 self.enterOuterAlt(localctx, 2)
-                self.state = 27
+                self.state = 29
                 self.keyword()
                 pass
-            elif token in [SearchParser.T__24, SearchParser.T__26, SearchParser.T__28, SearchParser.T__30, SearchParser.T__31, SearchParser.T__32, SearchParser.T__33, SearchParser.T__34]:
+            elif token in [SearchParser.T__9, SearchParser.T__11, SearchParser.T__13, SearchParser.T__15, SearchParser.T__16, SearchParser.T__17, SearchParser.T__18, SearchParser.T__19]:
                 self.enterOuterAlt(localctx, 3)
-                self.state = 28
+                self.state = 30
                 self.punctuator()
                 pass
-            elif token in [SearchParser.T__3, SearchParser.T__35, SearchParser.T__36, SearchParser.T__37, SearchParser.T__38, SearchParser.T__39, SearchParser.T__40, SearchParser.T__41, SearchParser.T__42, SearchParser.T__43, SearchParser.T__44, SearchParser.T__45, SearchParser.T__46]:
+            elif token in [SearchParser.T__24, SearchParser.T__25, SearchParser.T__26]:
                 self.enterOuterAlt(localctx, 4)
-                self.state = 29
-                self.op()
+                self.state = 31
+                self.operator()
                 pass
-            elif token in [SearchParser.T__1]:
+            elif token in [SearchParser.T__27, SearchParser.T__28, SearchParser.T__29]:
                 self.enterOuterAlt(localctx, 5)
-                self.state = 30
-                self.match(SearchParser.T__1)
+                self.state = 32
+                self.literal()
                 pass
-            else:
-                raise NoViableAltException(self)
-
-        except RecognitionException as re:
-            localctx.exception = re
-            self._errHandler.reportError(self, re)
-            self._errHandler.recover(self, re)
-        finally:
-            self.exitRule()
-        return localctx
-
-    class IdentifierContext(ParserRuleContext):
-
-        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
-            super().__init__(parent, invokingState)
-            self.parser = parser
-
-        def digit(self, i:int=None):
-            if i is None:
-                return self.getTypedRuleContexts(SearchParser.DigitContext)
-            else:
-                return self.getTypedRuleContext(SearchParser.DigitContext,i)
-
-
-        def getRuleIndex(self):
-            return SearchParser.RULE_identifier
-
-        def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterIdentifier" ):
-                listener.enterIdentifier(self)
-
-        def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitIdentifier" ):
-                listener.exitIdentifier(self)
-
-
-
-
-    def identifier(self):
-
-        localctx = SearchParser.IdentifierContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 6, self.RULE_identifier)
-        self._la = 0 # Token type
-        try:
-            self.state = 51
-            self._errHandler.sync(self)
-            token = self._input.LA(1)
-            if token in [SearchParser.T__2]:
-                self.enterOuterAlt(localctx, 1)
+            elif token in [SearchParser.T__1]:
+                self.enterOuterAlt(localctx, 6)
                 self.state = 33
-                self.match(SearchParser.T__2)
-                self.state = 37
-                self._errHandler.sync(self)
-                _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0):
-                    self.state = 34
-                    self.digit()
-                    self.state = 39
-                    self._errHandler.sync(self)
-                    _la = self._input.LA(1)
-
-                self.state = 40
-                self.match(SearchParser.T__3)
-                pass
-            elif token in [SearchParser.T__4]:
-                self.enterOuterAlt(localctx, 2)
-                self.state = 41
-                self.match(SearchParser.T__4)
-                self.state = 45
-                self._errHandler.sync(self)
-                _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0):
-                    self.state = 42
-                    self.digit()
-                    self.state = 47
-                    self._errHandler.sync(self)
-                    _la = self._input.LA(1)
-
-                self.state = 48
-                self.match(SearchParser.T__3)
-                pass
-            elif token in [SearchParser.T__5]:
-                self.enterOuterAlt(localctx, 3)
-                self.state = 49
-                self.match(SearchParser.T__5)
-                pass
-            elif token in [SearchParser.T__6]:
-                self.enterOuterAlt(localctx, 4)
-                self.state = 50
-                self.match(SearchParser.T__6)
+                self.match(SearchParser.T__1)
                 pass
             else:
                 raise NoViableAltException(self)
@@ -425,49 +340,6 @@ class SearchParser ( Parser ):
             self.exitRule()
         return localctx
 
-    class DigitContext(ParserRuleContext):
-
-        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
-            super().__init__(parent, invokingState)
-            self.parser = parser
-
-
-        def getRuleIndex(self):
-            return SearchParser.RULE_digit
-
-        def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterDigit" ):
-                listener.enterDigit(self)
-
-        def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitDigit" ):
-                listener.exitDigit(self)
-
-
-
-
-    def digit(self):
-
-        localctx = SearchParser.DigitContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 8, self.RULE_digit)
-        self._la = 0 # Token type
-        try:
-            self.enterOuterAlt(localctx, 1)
-            self.state = 53
-            _la = self._input.LA(1)
-            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0)):
-                self._errHandler.recoverInline(self)
-            else:
-                self._errHandler.reportMatch(self)
-                self.consume()
-        except RecognitionException as re:
-            localctx.exception = re
-            self._errHandler.reportError(self, re)
-            self._errHandler.recover(self, re)
-        finally:
-            self.exitRule()
-        return localctx
-
     class KeywordContext(ParserRuleContext):
 
         def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
@@ -492,13 +364,13 @@ class SearchParser ( Parser ):
     def keyword(self):
 
         localctx = SearchParser.KeywordContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 10, self.RULE_keyword)
+        self.enterRule(localctx, 6, self.RULE_keyword)
         self._la = 0 # Token type
         try:
             self.enterOuterAlt(localctx, 1)
-            self.state = 55
+            self.state = 36
             _la = self._input.LA(1)
-            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23))) != 0)):
+            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8))) != 0)):
                 self._errHandler.recoverInline(self)
             else:
                 self._errHandler.reportMatch(self)
@@ -541,100 +413,100 @@ class SearchParser ( Parser ):
     def punctuator(self):
 
         localctx = SearchParser.PunctuatorContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 12, self.RULE_punctuator)
+        self.enterRule(localctx, 8, self.RULE_punctuator)
         self._la = 0 # Token type
         try:
-            self.state = 93
+            self.state = 74
             self._errHandler.sync(self)
             token = self._input.LA(1)
-            if token in [SearchParser.T__24]:
+            if token in [SearchParser.T__9]:
                 self.enterOuterAlt(localctx, 1)
-                self.state = 57
-                self.match(SearchParser.T__24)
-                self.state = 61
+                self.state = 38
+                self.match(SearchParser.T__9)
+                self.state = 42
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                    self.state = 58
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                    self.state = 39
                     self.token()
-                    self.state = 63
+                    self.state = 44
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 64
-                self.match(SearchParser.T__25)
+                self.state = 45
+                self.match(SearchParser.T__10)
                 pass
-            elif token in [SearchParser.T__26]:
+            elif token in [SearchParser.T__11]:
                 self.enterOuterAlt(localctx, 2)
-                self.state = 65
-                self.match(SearchParser.T__26)
-                self.state = 69
+                self.state = 46
+                self.match(SearchParser.T__11)
+                self.state = 50
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                    self.state = 66
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                    self.state = 47
                     self.token()
-                    self.state = 71
+                    self.state = 52
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 72
-                self.match(SearchParser.T__27)
+                self.state = 53
+                self.match(SearchParser.T__12)
                 pass
-            elif token in [SearchParser.T__28]:
+            elif token in [SearchParser.T__13]:
                 self.enterOuterAlt(localctx, 3)
-                self.state = 73
-                self.match(SearchParser.T__28)
-                self.state = 77
+                self.state = 54
+                self.match(SearchParser.T__13)
+                self.state = 58
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                    self.state = 74
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                    self.state = 55
                     self.token()
-                    self.state = 79
+                    self.state = 60
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 80
-                self.match(SearchParser.T__29)
+                self.state = 61
+                self.match(SearchParser.T__14)
                 pass
-            elif token in [SearchParser.T__30]:
+            elif token in [SearchParser.T__15]:
                 self.enterOuterAlt(localctx, 4)
-                self.state = 81
-                self.match(SearchParser.T__30)
-                self.state = 85
+                self.state = 62
+                self.match(SearchParser.T__15)
+                self.state = 66
                 self._errHandler.sync(self)
-                _alt = self._interp.adaptivePredict(self._input,8,self._ctx)
+                _alt = self._interp.adaptivePredict(self._input,5,self._ctx)
                 while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                     if _alt==1:
-                        self.state = 82
+                        self.state = 63
                         self.token() 
-                    self.state = 87
+                    self.state = 68
                     self._errHandler.sync(self)
-                    _alt = self._interp.adaptivePredict(self._input,8,self._ctx)
+                    _alt = self._interp.adaptivePredict(self._input,5,self._ctx)
 
-                self.state = 88
-                self.match(SearchParser.T__30)
+                self.state = 69
+                self.match(SearchParser.T__15)
                 pass
-            elif token in [SearchParser.T__31]:
+            elif token in [SearchParser.T__16]:
                 self.enterOuterAlt(localctx, 5)
-                self.state = 89
-                self.match(SearchParser.T__31)
+                self.state = 70
+                self.match(SearchParser.T__16)
                 pass
-            elif token in [SearchParser.T__32]:
+            elif token in [SearchParser.T__17]:
                 self.enterOuterAlt(localctx, 6)
-                self.state = 90
-                self.match(SearchParser.T__32)
+                self.state = 71
+                self.match(SearchParser.T__17)
                 pass
-            elif token in [SearchParser.T__33]:
+            elif token in [SearchParser.T__18]:
                 self.enterOuterAlt(localctx, 7)
-                self.state = 91
-                self.match(SearchParser.T__33)
+                self.state = 72
+                self.match(SearchParser.T__18)
                 pass
-            elif token in [SearchParser.T__34]:
+            elif token in [SearchParser.T__19]:
                 self.enterOuterAlt(localctx, 8)
-                self.state = 92
-                self.match(SearchParser.T__34)
+                self.state = 73
+                self.match(SearchParser.T__19)
                 pass
             else:
                 raise NoViableAltException(self)
@@ -647,7 +519,7 @@ class SearchParser ( Parser ):
             self.exitRule()
         return localctx
 
-    class OpContext(ParserRuleContext):
+    class IdentifierContext(ParserRuleContext):
 
         def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
             super().__init__(parent, invokingState)
@@ -661,125 +533,285 @@ class SearchParser ( Parser ):
 
 
         def getRuleIndex(self):
-            return SearchParser.RULE_op
+            return SearchParser.RULE_identifier
 
         def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterOp" ):
-                listener.enterOp(self)
+            if hasattr( listener, "enterIdentifier" ):
+                listener.enterIdentifier(self)
 
         def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitOp" ):
-                listener.exitOp(self)
+            if hasattr( listener, "exitIdentifier" ):
+                listener.exitIdentifier(self)
 
 
 
 
-    def op(self):
+    def identifier(self):
 
-        localctx = SearchParser.OpContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 14, self.RULE_op)
+        localctx = SearchParser.IdentifierContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 10, self.RULE_identifier)
         self._la = 0 # Token type
         try:
-            self.state = 116
+            self.state = 93
             self._errHandler.sync(self)
-            la_ = self._interp.adaptivePredict(self._input,11,self._ctx)
-            if la_ == 1:
+            token = self._input.LA(1)
+            if token in [SearchParser.T__20]:
                 self.enterOuterAlt(localctx, 1)
-                self.state = 95
-                self.match(SearchParser.T__35)
-                pass
+                self.state = 76
+                self.match(SearchParser.T__20)
+                self.state = 80
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 77
+                    self.digit()
+                    self.state = 82
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 2:
-                self.enterOuterAlt(localctx, 2)
-                self.state = 96
-                self.match(SearchParser.T__36)
+                self.state = 83
+                self.match(SearchParser.T__21)
                 pass
+            elif token in [SearchParser.T__22]:
+                self.enterOuterAlt(localctx, 2)
+                self.state = 84
+                self.match(SearchParser.T__22)
+                self.state = 88
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 85
+                    self.digit()
+                    self.state = 90
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 3:
+                self.state = 91
+                self.match(SearchParser.T__21)
+                pass
+            elif token in [SearchParser.T__23]:
                 self.enterOuterAlt(localctx, 3)
-                self.state = 97
-                self.match(SearchParser.T__37)
+                self.state = 92
+                self.match(SearchParser.T__23)
                 pass
+            else:
+                raise NoViableAltException(self)
 
-            elif la_ == 4:
-                self.enterOuterAlt(localctx, 4)
-                self.state = 98
-                self.match(SearchParser.T__38)
-                pass
+        except RecognitionException as re:
+            localctx.exception = re
+            self._errHandler.reportError(self, re)
+            self._errHandler.recover(self, re)
+        finally:
+            self.exitRule()
+        return localctx
 
-            elif la_ == 5:
-                self.enterOuterAlt(localctx, 5)
-                self.state = 99
-                self.match(SearchParser.T__39)
-                pass
+    class OperatorContext(ParserRuleContext):
 
-            elif la_ == 6:
-                self.enterOuterAlt(localctx, 6)
-                self.state = 100
-                self.match(SearchParser.T__40)
-                pass
+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
+            super().__init__(parent, invokingState)
+            self.parser = parser
 
-            elif la_ == 7:
-                self.enterOuterAlt(localctx, 7)
-                self.state = 101
-                self.match(SearchParser.T__3)
-                pass
+        def digit(self, i:int=None):
+            if i is None:
+                return self.getTypedRuleContexts(SearchParser.DigitContext)
+            else:
+                return self.getTypedRuleContext(SearchParser.DigitContext,i)
+
+
+        def getRuleIndex(self):
+            return SearchParser.RULE_operator
+
+        def enterRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "enterOperator" ):
+                listener.enterOperator(self)
+
+        def exitRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "exitOperator" ):
+                listener.exitOperator(self)
+
+
+
+
+    def operator(self):
+
+        localctx = SearchParser.OperatorContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 12, self.RULE_operator)
+        self._la = 0 # Token type
+        try:
+            self.state = 112
+            self._errHandler.sync(self)
+            token = self._input.LA(1)
+            if token in [SearchParser.T__24]:
+                self.enterOuterAlt(localctx, 1)
+                self.state = 95
+                self.match(SearchParser.T__24)
+                self.state = 99
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 96
+                    self.digit()
+                    self.state = 101
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 8:
-                self.enterOuterAlt(localctx, 8)
                 self.state = 102
-                self.match(SearchParser.T__41)
+                self.match(SearchParser.T__21)
                 pass
-
-            elif la_ == 9:
-                self.enterOuterAlt(localctx, 9)
+            elif token in [SearchParser.T__25]:
+                self.enterOuterAlt(localctx, 2)
                 self.state = 103
-                self.match(SearchParser.T__42)
-                pass
+                self.match(SearchParser.T__25)
+                self.state = 107
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 104
+                    self.digit()
+                    self.state = 109
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 10:
-                self.enterOuterAlt(localctx, 10)
-                self.state = 104
-                self.match(SearchParser.T__39)
+                self.state = 110
+                self.match(SearchParser.T__21)
                 pass
-
-            elif la_ == 11:
-                self.enterOuterAlt(localctx, 11)
-                self.state = 105
-                self.match(SearchParser.T__43)
+            elif token in [SearchParser.T__26]:
+                self.enterOuterAlt(localctx, 3)
+                self.state = 111
+                self.match(SearchParser.T__26)
                 pass
+            else:
+                raise NoViableAltException(self)
 
-            elif la_ == 12:
-                self.enterOuterAlt(localctx, 12)
-                self.state = 106
-                self.match(SearchParser.T__44)
-                pass
+        except RecognitionException as re:
+            localctx.exception = re
+            self._errHandler.reportError(self, re)
+            self._errHandler.recover(self, re)
+        finally:
+            self.exitRule()
+        return localctx
+
+    class LiteralContext(ParserRuleContext):
+
+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
+            super().__init__(parent, invokingState)
+            self.parser = parser
+
+        def digit(self, i:int=None):
+            if i is None:
+                return self.getTypedRuleContexts(SearchParser.DigitContext)
+            else:
+                return self.getTypedRuleContext(SearchParser.DigitContext,i)
+
+
+        def getRuleIndex(self):
+            return SearchParser.RULE_literal
+
+        def enterRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "enterLiteral" ):
+                listener.enterLiteral(self)
+
+        def exitRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "exitLiteral" ):
+                listener.exitLiteral(self)
 
-            elif la_ == 13:
-                self.enterOuterAlt(localctx, 13)
-                self.state = 107
-                self.match(SearchParser.T__45)
-                pass
 
-            elif la_ == 14:
-                self.enterOuterAlt(localctx, 14)
-                self.state = 108
-                self.match(SearchParser.T__46)
-                self.state = 112
+
+
+    def literal(self):
+
+        localctx = SearchParser.LiteralContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 14, self.RULE_literal)
+        self._la = 0 # Token type
+        try:
+            self.state = 131
+            self._errHandler.sync(self)
+            token = self._input.LA(1)
+            if token in [SearchParser.T__27]:
+                self.enterOuterAlt(localctx, 1)
+                self.state = 114
+                self.match(SearchParser.T__27)
+                self.state = 118
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0):
-                    self.state = 109
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 115
                     self.digit()
-                    self.state = 114
+                    self.state = 120
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 115
-                self.match(SearchParser.T__3)
+                self.state = 121
+                self.match(SearchParser.T__21)
+                pass
+            elif token in [SearchParser.T__28]:
+                self.enterOuterAlt(localctx, 2)
+                self.state = 122
+                self.match(SearchParser.T__28)
+                self.state = 126
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 123
+                    self.digit()
+                    self.state = 128
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
+
+                self.state = 129
+                self.match(SearchParser.T__21)
+                pass
+            elif token in [SearchParser.T__29]:
+                self.enterOuterAlt(localctx, 3)
+                self.state = 130
+                self.match(SearchParser.T__29)
                 pass
+            else:
+                raise NoViableAltException(self)
+
+        except RecognitionException as re:
+            localctx.exception = re
+            self._errHandler.reportError(self, re)
+            self._errHandler.recover(self, re)
+        finally:
+            self.exitRule()
+        return localctx
+
+    class DigitContext(ParserRuleContext):
 
+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
+            super().__init__(parent, invokingState)
+            self.parser = parser
 
+
+        def getRuleIndex(self):
+            return SearchParser.RULE_digit
+
+        def enterRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "enterDigit" ):
+                listener.enterDigit(self)
+
+        def exitRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "exitDigit" ):
+                listener.exitDigit(self)
+
+
+
+
+    def digit(self):
+
+        localctx = SearchParser.DigitContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 16, self.RULE_digit)
+        self._la = 0 # Token type
+        try:
+            self.enterOuterAlt(localctx, 1)
+            self.state = 133
+            _la = self._input.LA(1)
+            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0)):
+                self._errHandler.recoverInline(self)
+            else:
+                self._errHandler.reportMatch(self)
+                self.consume()
         except RecognitionException as re:
             localctx.exception = re
             self._errHandler.reportError(self, re)
diff --git a/code/example.txt b/code/example.txt
index 56c4c47..a8ab280 100644
--- a/code/example.txt
+++ b/code/example.txt
@@ -1,21 +1,23 @@
-9for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<0>;#ID<.>#OP<.>){->for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<1>;#ID<.>#OP<.>){
-#ID<.>.#ID<.>(#N<0>,#N<1>);->#ID<.>.#ID<.>(#N<2>,#N<3>);
-#ID<.>.#ID<.>(#N<.>);->_
+for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<0>;#ID<.>#OP<.>){->for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<1>;#ID<.>#OP<.>){
+#ID<.>.#ID<.>(#LT<0>,#LT<1>);->#ID<.>.#ID<.>(#LT<!0>,#LT<!1>);
+#ID<.>.#ID<.>(#LT<.>);->_
 _->#ID<.>.#ID<.>();
-for(#ID<.>=#N<.>;#ID<.>#OP<0>#N<0>;#ID<.>#OP<.>){->for(#ID<.>=#N<.>;#ID<.>#OP<1>#N<1>;#ID<.>#OP<.>){
-for(#ID<.>=#N<.>;#ID<.>#OP<0>#N<0>;#ID<0>#OP<1>){->for(#ID<.>=#N<.>;#ID<.>#OP<2>#N<1>;#ID<1>#OP<3>){
-if(#ID<.>#OP<0>#N<.>){->if(#ID<.>#OP<1>#N<.>){
-if(#ID<.>#OP<.>#N<0>){->if(#ID<.>#OP<.>#N<1>){
-if(#ID<.>#OP<0>#N<.>){->if(#ID<.>#OP<1>#N<.>){
-#ID<.>.#ID<.>(#N<0>,#N<1>);->#ID<.>.#ID<.>(#N<2>,#N<3>);
-#ID<.>.#ID<.>(#N<.>);->_
-if(#ID<.>#OP<.>#N<0>){->if(#ID<.>#OP<.>#N<1>){
+for(#ID<.>=#LT<.>;#ID<.>#OP<0>#LT<0>;#ID<.>#OP<.>){->for(#ID<.>=#LT<.>;#ID<.>#OP<1>#LT<1>;#ID<.>#OP<.>){
+for(#ID<.>=#LT<.>;#ID<.>#OP<0>#LT<0>;#ID<0>#OP<1>){->for(#ID<.>=#LT<.>;#ID<.>#OP<2>#LT<1>;#ID<1>#OP<3>){
+if(#ID<.>#OP<0>#LT<.>){->if(#ID<.>#OP<1>#LT<.>){
+if(#ID<.>#OP<.>#LT<0>){->if(#ID<.>#OP<.>#LT<1>){
+if(#ID<.>#OP<0>#LT<.>){->if(#ID<.>#OP<1>#LT<.>){
+#ID<.>.#ID<.>(#LT<0>,#LT<1>);->#ID<.>.#ID<.>(#LT<2>,#LT<3>);
 
-if(#ID<.>#OP<0>#N<.>) -> if(#ID<.>#OP<1>#N<.>)
-if(#ID<.>#OP<.>#N<0>) -> if(#ID<.>#OP<.>#N<1>)
+if(#ID<.>#OP<.>#LT<0>){->if(#ID<.>#OP<.>#LT<1>){
 
-#ID<.>.#ID<.>(#N<100>,#N<21321>)->#ID<.>.#ID<.>(#N<23222>,,#N<2312313>
+if(#ID<.>#OP<0>#LT<.>) -> if(#ID<.>#OP<!0>#LT<.>)
+if(#ID<.>#OP<1>#LT<.>) -> if(#ID<.>#OP<1>#LT<.>)
+if(#ID<.>#OP<1>#LT<.>){ -> if(#ID<.>#OP<1>#LT<.>){
 
-if(#ID<.>#OP<0>#N<.>){ -> if(#ID<.>#OP<3>#N<.>){
-if(#ID<.>#OP<1>#N<.>) -> if(#ID<.>#OP<2>#N<.>)
-for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<1>;#ID<.>#OP<.>)->for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<2>;#ID<.>#OP<.>)
\ No newline at end of file
+#ID<.>.#ID<.>(#LT<100>,#LT<21321>)->#ID<.>.#ID<.>(#LT<23222>,,#LT<2312313>
+
+if(#ID<.>#OP<0>#LT<.>){ -> if(#ID<.>#OP<3>#LT<.>){
+if(#ID<.>#OP<1>#LT<.>) -> if(#ID<.>#OP<2>#LT<.>)
+for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<1>;#ID<.>#OP<.>)->for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<2>;#ID<.>#OP<.>)
+_ ->#ID<.>.#ID<.>(#LT<.>,#LT<.>);
diff --git a/code/git_changes.txt b/code/git_changes.txt
index b106a2d..3276ed5 100644
--- a/code/git_changes.txt
+++ b/code/git_changes.txt
@@ -7,12 +7,15 @@ index d58db74..f1c27f0 100644
  
     public static void main(String[] args) {
 
--        for(j=0;j<2;j++){
-+        for(j=0;j<3;j++){
+-              if(y>0){
++              if(y>5){
+
+-              if(y==0){
++              if(y!=0){
 
          Scanner s= new Scanner(System.in);
 
-         System.out.println("Geometry Area:\n1)Circle\n2)Rectangle\n3)Triangle\n");
+         System.out.println("Geometry Area:\n");
 
          switch(i) {
             case 1:
@@ -30,45 +33,27 @@ index d58db74..f1c27f0 100644
         }
 
 
-diff --git a/Area.java b/Area.java
+diff --git a/main.cpp b/main.cpp
 index d58db74..f1c27f0 100644
---- a/Area.java
-+++ b/Area.java
-@@ -3,24 +3,23 @@ import java.util.Scanner;
- public class Area {
+--- a/main.cpp
++++ b/maoin.cpp
+@@ -16,10 +16,10 @@ int main()
  
-    public static void main(String[] args) {
+    //add a call method
 
--        for(j=0;j>0;j++){
-+        for(j=0;j<1;j++){
+-    if(n>2)
++    if(n<2)
+      myfile << n;
 
--        for(j=0;j>0;i--){
-+        for(j=0;j<1;j++){
+-    while(i<1){
++    while(i>1){
+        cout << "The result is: " << sub(x2,x1) << endl; //swap arguments DONE
+        i++;
+    }
+@@ -32,7 +32,7 @@ int main()
 
-         Scanner s= new Scanner(System.in);
-
-         System.out.println("Geometry Area:\n1)Circle\n2)Rectangle\n3)Triangle\n");
 
--              if(x>0){
-+              if(x<0){
 
--              if(y>0){
-+              if(y>5){
-
--              if(y==0){
-+              if(y!=0){
-
-         switch(i) {
-            case 1:
--              Area.circle(6,7);
-+              Area.circle(5,5);
-              break;
-            case 2:
--              Area.rectangle(3);
-               Area.rectangle(2,1);
-              break;
-            default:
--              if(y>9){
-+              if(y>1){
-          }
-        }
+-    return 0;
++    return -1;
+}
diff --git a/code/git_functions.py b/code/git_functions.py
index 059745e..36e35a4 100644
--- a/code/git_functions.py
+++ b/code/git_functions.py
@@ -25,9 +25,9 @@ def git_clone():
 def git_log(repository):
     commit_log = []
 
-    command = "cd " + repository + "&& git log > git_log.txt"
+    command = "git log > ./test-changes/git_log.txt"
     os.system(command)
-    filename = repository + "/git_log.txt"
+    filename ="test-changes/git_log.txt"
 
     with open(filename) as fp:
         for line in fp:
@@ -45,9 +45,9 @@ def git_log(repository):
 #Compute the git diff
 def git_diff(commit_log, repository):
 
-    command = "echo '' > git_changes.txt"
+    command = "echo '' > ./test_changes/git_changes.txt"
     os.system(command)
 
     for i in commit_log:
-        command = "cd " + repository + "&& git diff " + i + " HEAD >> git_changes.txt"
+        command = "cd ./test-changes && git diff " + i + " HEAD >> git_changes.txt"
         os.system(command)
\ No newline at end of file
diff --git a/code/main.py b/code/main.py
index 2a8683c..c95c46d 100644
--- a/code/main.py
+++ b/code/main.py
@@ -19,7 +19,7 @@ def main():
             git_functions.git_diff(git_functions.git_log(repository), repository)
 
     #Insertion of the query
-    query = input("Insert a query: ")
+    query = input("Please, insert a query: ")
 
     start_time = time.time()
 
@@ -29,13 +29,26 @@ def main():
     #Computation of similarity in different ways(cosine distance and jaccard index)
     position = 0
     ngrams = 3
+
     #[0] cosine distance threshold [1] jaccard distance threshold
-    thresholds = [0.1, 0.1]
+    thresholds = [0.83, 0.8]
+    ranked_list = []
+
+    query_tokens, query_ngrams = my_functions.query_normalization(query,ngrams)
 
+    my_functions.dataset_csv(changes_list_real, changes_list_abstract)
+    
     for change in changes_list_abstract:
-        my_functions.similarity(query.replace(' ', '').replace('\n', ''), change, position, ngrams, thresholds, changes_list_real)
+        my_functions.similarity(query_tokens, query_ngrams, change, position, ngrams, thresholds, changes_list_real, ranked_list)
         position += 1
 
+    # sort list with key
+    ranked_list.sort(reverse=True, key=my_functions.takeSecond)
+
+    print("\nThe changes found are:\n ")
+    for i in ranked_list:
+        print(i[0] + ' cosine: ' + i[1] + ' jaccard: ' +  i[2])
+
     #Programs ends
     end = time.time()
     print("\nThe program ends in:", round(end - start_time,1), "seconds. Total changes in the repository: ", position) 
diff --git a/code/my_functions.py b/code/my_functions.py
index f025d9c..1d55af1 100644
--- a/code/my_functions.py
+++ b/code/my_functions.py
@@ -7,6 +7,8 @@ from math import*
 from decimal import Decimal
 import copy
 from collections import Counter
+import csv
+from itertools import zip_longest
 import antlr4 
 
 import sys
@@ -22,6 +24,10 @@ def diff(first, second):
     else:
         return [i for i in range(len(first)) if first[i] != second[i]]
 
+#Take second element for list sorting key
+def takeSecond(elem):
+    return elem[1]
+    
 #Compute ngram of a string
 def ngram(change, ngrams):
     ngrams_list = {}
@@ -64,7 +70,7 @@ def antlr4_AbstractGrammar_Tokenizer(query):
 
     return list_abstract_token
 
-#Exacrt the changes from the git diff file
+#Extract the changes from the git diff file
 def analyze_diff_file(filename):
     temporary_array = []
     changes_list = []
@@ -149,10 +155,10 @@ def scanner(changes_list):
                     else:
                         if token.isdigit():
                             if(count in diff1 and bool == False):
-                                old[count] = '#N<' + str(n_num) + '>'
+                                old[count] = '#LT<' + str(n_num) + '>'
                                 n_num = n_num + 1 
                             else:    
-                                old[count] = '#N<.>'
+                                old[count] = '#LT<.>'
                         else: 
                             if(count in diff1 and bool == False):
                                 old[count] = '#ID<' + str(n_id) + '>'
@@ -163,6 +169,9 @@ def scanner(changes_list):
             count = count + 1
 
         count = 0
+        n_op = 0
+        n_id = 0
+        n_num = 0
 
         for token in new:
             if token == 'if' or token == 'else' or token =='for' or token =='while' or token =='forEach' or token =='while' or token =='return' or token =='NULL':
@@ -182,10 +191,10 @@ def scanner(changes_list):
                     else:
                         if token.isdigit():
                             if(count in diff1 and bool == False):
-                                new[count] = '#N<' + str(n_num) + '>'
+                                new[count] = '#LT<' + str(n_num) + '>'
                                 n_num = n_num + 1 
                             else:    
-                                new[count] = '#N<.>'
+                                new[count] = '#LT<.>'
                         else: 
                             if(count in diff1 and bool == False):
                                 new[count] = '#ID<' + str(n_id) + '>'
@@ -219,15 +228,13 @@ def scanner(changes_list):
 #Compute cosine similarity
 def cosine_similarity_ngrams(a, b):
 
-    vec1 = Counter(a)
-    vec2 = Counter(b)
+    v1 = Counter(a)
+    v2 = Counter(b)
     
-    intersection = set(vec1.keys()) & set(vec2.keys())
-    numerator = sum([vec1[x] * vec2[x] for x in intersection])
+    intersection = set(v1.keys()) & set(v2.keys())
 
-    sum1 = sum([vec1[x]**2 for x in vec1.keys()])
-    sum2 = sum([vec2[x]**2 for x in vec2.keys()])
-    denominator = math.sqrt(sum1) * math.sqrt(sum2)
+    numerator = sum([v1[x] * v2[x] for x in intersection])
+    denominator = math.sqrt(sum([v1[x]**2 for x in v1.keys()])) * math.sqrt(sum([v2[x]**2 for x in v2.keys()]))
 
     if not denominator:
         return 0.0
@@ -240,22 +247,76 @@ def getNgrams(string, n):
 #Compute Jaccard index similarity
 def jaccard_similarity(x,y):
  
- intersection_cardinality = len(set.intersection(*[set(x), set(y)]))
- union_cardinality = len(set.union(*[set(x), set(y)]))
+    intersection = len(set.intersection(*[set(x), set(y)]))
+    union = len(set.union(*[set(x), set(y)]))
  
- return intersection_cardinality/float(union_cardinality)
+    return intersection/float(union)
 
 #Compute the similarity between query and one change using different similarity algorithm. Print the change if over thresholds 
-def similarity(query, change, position, ngram, thresholds, changes_list_real):
+def similarity(query_tokens, query_ngrams, change, position, ngram, thresholds, changes_list_real, ranked_list):
+
+    temporary_list = []
 
-    ngrams_list1 = getNgrams(query, ngram)
+    #ngrams_list1 = getNgrams(query, ngram)
     ngrams_list2 = getNgrams(change, ngram)
 
-    abstract_tokens1 = antlr4_AbstractGrammar_Tokenizer(query)
+    #abstract_tokens1 = antlr4_AbstractGrammar_Tokenizer(query)
     abstract_tokens2 = antlr4_AbstractGrammar_Tokenizer(change)
 
-    cosine_score = cosine_similarity_ngrams(ngrams_list1,ngrams_list2)
-    jaccard_score = jaccard_similarity(abstract_tokens1, abstract_tokens2)
+    cosine_score = cosine_similarity_ngrams(query_ngrams,ngrams_list2)
+    jaccard_score = jaccard_similarity(query_tokens, abstract_tokens2)
    
     if cosine_score > thresholds[0] and jaccard_score > thresholds[1] :
-        print(changes_list_real[position] + ' cosine: ' + str(round(cosine_score,2)) + ' jaccard: ' + str(round(jaccard_score,2)))#+ ' eucledian: ' + str(round(eucledian_score,2)))
+        
+        temporary_list.append(changes_list_real[position])
+        temporary_list.append(str(round(cosine_score,2)))
+        temporary_list.append(str(round(jaccard_score,2)))
+
+        ranked_list.append(temporary_list)
+
+#Query digits normalization and n-grams and tokens computation
+def query_normalization(query, ngrams):
+    query_normalize = []
+
+    id = 0
+    op = 0
+    lt = 0
+    n = 0
+    l = len(str(query))
+
+    for n in range(0, l):
+        if(query[n] == '-'):
+                id = 0
+                op = 0
+                lt = 0
+
+                query_normalize.append(query[n])
+        else:
+            if query[n].isdigit():
+                if(n > 1):
+                    if(query[n-2] == 'D'):
+                        query_normalize.append(str(id))
+                        id += 1
+                    else:
+                        if(query[n-2] == 'P'):
+                            query_normalize.append(str(op))
+                            op += 1
+                        else:
+                           # if(query[n-2] == 'T'):
+                                query_normalize.append(str(lt))
+                                lt += 1
+                else: 
+                    query_normalize.append(query[n])
+            else: 
+                    query_normalize.append(query[n])
+
+        
+        n += 1
+
+    query_n = ''.join(query_normalize).replace(' ', '').replace('\n', '')
+
+    query_tokens = antlr4_AbstractGrammar_Tokenizer(query_n)
+    query_ngrams = getNgrams(query_n, ngrams)
+    
+
+    return query_tokens, query_ngrams
diff --git a/code/tests.py b/code/tests.py
index 6e72061..9b25953 100644
--- a/code/tests.py
+++ b/code/tests.py
@@ -1,41 +1,32 @@
+ #  stream = antlr4.CommonTokenStream(lexer)
+   # parser = SearchParser(stream)
+   # tree = parser.query()
+    #printer = SearchPrintListener()
+   # walker = antlr4.ParseTreeWalker()
+    #walker.walk(printer, tree)
+  #  print(tree.toStringTree())
+    
 import antlr4 
 
 import sys
-# insert at 1, 0 is the script path (or '' in REPL)
-sys.path.insert(1, './antlr4')
-
+sys.path.insert(1, './code/antlr4')
 from SearchLexer import SearchLexer
 from SearchListener import SearchListener
 from SearchParser import SearchParser
 
-#echo "3 * 3 - 2 + 2 * 2" | python main.py
-
 class SearchPrintListener(SearchListener):
-    def enterSearch(self, ctx):
-        print("Search: %s" % ctx.ID())
+    def enterHi(self, ctx):
+        print("Hello: %s" % ctx.ID())
 
-def antlr4_AbstractGrammar_Tokenizer(query):
+def main(query):
     lexer = SearchLexer(antlr4.InputStream(query))
-    list_abstract_token = []
-    while(1):
-        token = lexer.nextToken()
-        if(token.text == '<EOF>'):
-            break
-        list_abstract_token.append(token.text)
-
-    
-    for i in list_abstract_token:
-       print(i)
-
-    return list_abstract_token
-  #  stream = antlr4.CommonTokenStream(lexer)
-   # parser = SearchParser(stream)
-   # tree = parser.query()
-    #printer = SearchPrintListener()
-   # walker = antlr4.ParseTreeWalker()
-    #walker.walk(printer, tree)
-  #  print(tree.toStringTree())
-    
+    stream = antlr4.CommonTokenStream(lexer)
+    parser = SearchParser(stream)
+    tree = parser.query()
+    printer = SearchPrintListener()
+    walker = antlr4.ParseTreeWalker()
+    walker.walk(printer, tree)
+    #print(tree.toStringTree())
 
 if __name__ == '__main__':
-    antlr4_AbstractGrammar_Tokenizer('if(#ID<.>#OP<0>#N<.>) -> if(#ID<.>#OP<3>#N<.>)')
+    main('if(#ID<.>#OP<1>#LT<.>){ -> if(#ID<.>#OP<1>#LT<.>){<')
diff --git a/.gitignore b/.gitignore
new file mode 100644
index 0000000..e645270
--- /dev/null
+++ b/.gitignore
@@ -0,0 +1,353 @@
+## Ignore Visual Studio temporary files, build results, and
+## files generated by popular Visual Studio add-ons.
+##
+## Get latest from https://github.com/github/gitignore/blob/master/VisualStudio.gitignore
+
+# User-specific files
+*.rsuser
+*.suo
+*.user
+*.userosscache
+*.sln.docstates
+
+# User-specific files (MonoDevelop/Xamarin Studio)
+*.userprefs
+
+# Mono auto generated files
+mono_crash.*
+
+# Build results
+[Dd]ebug/
+[Dd]ebugPublic/
+[Rr]elease/
+[Rr]eleases/
+x64/
+x86/
+[Aa][Rr][Mm]/
+[Aa][Rr][Mm]64/
+bld/
+[Bb]in/
+[Oo]bj/
+[Ll]og/
+[Ll]ogs/
+
+# Visual Studio 2015/2017 cache/options directory
+.vs/
+# Uncomment if you have tasks that create the project's static files in wwwroot
+#wwwroot/
+
+# Visual Studio 2017 auto generated files
+Generated\ Files/
+
+# MSTest test Results
+[Tt]est[Rr]esult*/
+[Bb]uild[Ll]og.*
+
+# NUnit
+*.VisualState.xml
+TestResult.xml
+nunit-*.xml
+
+# Build Results of an ATL Project
+[Dd]ebugPS/
+[Rr]eleasePS/
+dlldata.c
+
+# Benchmark Results
+BenchmarkDotNet.Artifacts/
+
+# .NET Core
+project.lock.json
+project.fragment.lock.json
+artifacts/
+
+# StyleCop
+StyleCopReport.xml
+
+# Files built by Visual Studio
+*_i.c
+*_p.c
+*_h.h
+*.ilk
+*.meta
+*.obj
+*.iobj
+*.pch
+*.pdb
+*.ipdb
+*.pgc
+*.pgd
+*.rsp
+*.sbr
+*.tlb
+*.tli
+*.tlh
+*.tmp
+*.tmp_proj
+*_wpftmp.csproj
+*.log
+*.vspscc
+*.vssscc
+.builds
+*.pidb
+*.svclog
+*.scc
+
+# Chutzpah Test files
+_Chutzpah*
+
+# Visual C++ cache files
+ipch/
+*.aps
+*.ncb
+*.opendb
+*.opensdf
+*.sdf
+*.cachefile
+*.VC.db
+*.VC.VC.opendb
+
+# Visual Studio profiler
+*.psess
+*.vsp
+*.vspx
+*.sap
+
+# Visual Studio Trace Files
+*.e2e
+
+# TFS 2012 Local Workspace
+$tf/
+
+# Guidance Automation Toolkit
+*.gpState
+
+# ReSharper is a .NET coding add-in
+_ReSharper*/
+*.[Rr]e[Ss]harper
+*.DotSettings.user
+
+# JustCode is a .NET coding add-in
+.JustCode
+
+# TeamCity is a build add-in
+_TeamCity*
+
+# DotCover is a Code Coverage Tool
+*.dotCover
+
+# AxoCover is a Code Coverage Tool
+.axoCover/*
+!.axoCover/settings.json
+
+# Visual Studio code coverage results
+*.coverage
+*.coveragexml
+
+# NCrunch
+_NCrunch_*
+.*crunch*.local.xml
+nCrunchTemp_*
+
+# MightyMoose
+*.mm.*
+AutoTest.Net/
+
+# Web workbench (sass)
+.sass-cache/
+
+# Installshield output folder
+[Ee]xpress/
+
+# DocProject is a documentation generator add-in
+DocProject/buildhelp/
+DocProject/Help/*.HxT
+DocProject/Help/*.HxC
+DocProject/Help/*.hhc
+DocProject/Help/*.hhk
+DocProject/Help/*.hhp
+DocProject/Help/Html2
+DocProject/Help/html
+
+# Click-Once directory
+publish/
+
+# Publish Web Output
+*.[Pp]ublish.xml
+*.azurePubxml
+# Note: Comment the next line if you want to checkin your web deploy settings,
+# but database connection strings (with potential passwords) will be unencrypted
+*.pubxml
+*.publishproj
+
+# Microsoft Azure Web App publish settings. Comment the next line if you want to
+# checkin your Azure Web App publish settings, but sensitive information contained
+# in these scripts will be unencrypted
+PublishScripts/
+
+# NuGet Packages
+*.nupkg
+# NuGet Symbol Packages
+*.snupkg
+# The packages folder can be ignored because of Package Restore
+**/[Pp]ackages/*
+# except build/, which is used as an MSBuild target.
+!**/[Pp]ackages/build/
+# Uncomment if necessary however generally it will be regenerated when needed
+#!**/[Pp]ackages/repositories.config
+# NuGet v3's project.json files produces more ignorable files
+*.nuget.props
+*.nuget.targets
+
+# Microsoft Azure Build Output
+csx/
+*.build.csdef
+
+# Microsoft Azure Emulator
+ecf/
+rcf/
+
+# Windows Store app package directories and files
+AppPackages/
+BundleArtifacts/
+Package.StoreAssociation.xml
+_pkginfo.txt
+*.appx
+*.appxbundle
+*.appxupload
+
+# Visual Studio cache files
+# files ending in .cache can be ignored
+*.[Cc]ache
+# but keep track of directories ending in .cache
+!?*.[Cc]ache/
+
+# Others
+ClientBin/
+~$*
+*~
+*.dbmdl
+*.dbproj.schemaview
+*.jfm
+*.pfx
+*.publishsettings
+orleans.codegen.cs
+
+# Including strong name files can present a security risk
+# (https://github.com/github/gitignore/pull/2483#issue-259490424)
+#*.snk
+
+# Since there are multiple workflows, uncomment next line to ignore bower_components
+# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
+#bower_components/
+
+# RIA/Silverlight projects
+Generated_Code/
+
+# Backup & report files from converting an old project file
+# to a newer Visual Studio version. Backup files are not needed,
+# because we have git ;-)
+_UpgradeReport_Files/
+Backup*/
+UpgradeLog*.XML
+UpgradeLog*.htm
+ServiceFabricBackup/
+*.rptproj.bak
+
+# SQL Server files
+*.mdf
+*.ldf
+*.ndf
+
+# Business Intelligence projects
+*.rdl.data
+*.bim.layout
+*.bim_*.settings
+*.rptproj.rsuser
+*- [Bb]ackup.rdl
+*- [Bb]ackup ([0-9]).rdl
+*- [Bb]ackup ([0-9][0-9]).rdl
+
+# Microsoft Fakes
+FakesAssemblies/
+
+# GhostDoc plugin setting file
+*.GhostDoc.xml
+
+# Node.js Tools for Visual Studio
+.ntvs_analysis.dat
+node_modules/
+
+# Visual Studio 6 build log
+*.plg
+
+# Visual Studio 6 workspace options file
+*.opt
+
+# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
+*.vbw
+
+# Visual Studio LightSwitch build output
+**/*.HTMLClient/GeneratedArtifacts
+**/*.DesktopClient/GeneratedArtifacts
+**/*.DesktopClient/ModelManifest.xml
+**/*.Server/GeneratedArtifacts
+**/*.Server/ModelManifest.xml
+_Pvt_Extensions
+
+# Paket dependency manager
+.paket/paket.exe
+paket-files/
+
+# FAKE - F# Make
+.fake/
+
+# CodeRush personal settings
+.cr/personal
+
+# Python Tools for Visual Studio (PTVS)
+__pycache__/
+*.pyc
+
+# Cake - Uncomment if you are using it
+# tools/**
+# !tools/packages.config
+
+# Tabs Studio
+*.tss
+
+# Telerik's JustMock configuration file
+*.jmconfig
+
+# BizTalk build output
+*.btp.cs
+*.btm.cs
+*.odx.cs
+*.xsd.cs
+
+# OpenCover UI analysis results
+OpenCover/
+
+# Azure Stream Analytics local run output
+ASALocalRun/
+
+# MSBuild Binary and Structured Log
+*.binlog
+
+# NVidia Nsight GPU debugger configuration file
+*.nvuser
+
+# MFractors (Xamarin productivity tool) working folder
+.mfractor/
+
+# Local History for Visual Studio
+.localhistory/
+
+# BeatPulse healthcheck temp database
+healthchecksdb
+
+# Backup folder for Package Reference Convert tool in Visual Studio 2017
+MigrationBackup/
+
+# Ionide (cross platform F# VS Code tools) working folder
+.ionide/
diff --git a/code/antlr4/.antlr/Search.interp b/code/antlr4/.antlr/Search.interp
new file mode 100644
index 0000000..b739ec4
--- /dev/null
+++ b/code/antlr4/.antlr/Search.interp
@@ -0,0 +1,102 @@
+token literal names:
+null
+'->'
+'_'
+'if'
+'else'
+'for'
+'forEach'
+'while'
+'return'
+'NULL'
+'('
+')'
+'['
+']'
+'{'
+'}'
+'"'
+'='
+'.'
+','
+';'
+'#ID<'
+'>'
+'#ID<!'
+'#ID<.>'
+'#OP<'
+'#OP<!'
+'#OP<.>'
+'#LT<'
+'#LT<!'
+'#LT<.>'
+'0'
+'1'
+'2'
+'3'
+'4'
+'5'
+'6'
+'7'
+'8'
+'9'
+null
+
+token symbolic names:
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+WS
+
+rule names:
+query
+code
+token
+keyword
+punctuator
+identifier
+operator
+literal
+digit
+
+
+atn:
+[3, 24715, 42794, 33075, 47597, 16764, 15335, 30598, 22884, 3, 43, 138, 4, 2, 9, 2, 4, 3, 9, 3, 4, 4, 9, 4, 4, 5, 9, 5, 4, 6, 9, 6, 4, 7, 9, 7, 4, 8, 9, 8, 4, 9, 9, 9, 4, 10, 9, 10, 3, 2, 3, 2, 3, 2, 3, 2, 3, 3, 7, 3, 26, 10, 3, 12, 3, 14, 3, 29, 11, 3, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 5, 4, 37, 10, 4, 3, 5, 3, 5, 3, 6, 3, 6, 7, 6, 43, 10, 6, 12, 6, 14, 6, 46, 11, 6, 3, 6, 3, 6, 3, 6, 7, 6, 51, 10, 6, 12, 6, 14, 6, 54, 11, 6, 3, 6, 3, 6, 3, 6, 7, 6, 59, 10, 6, 12, 6, 14, 6, 62, 11, 6, 3, 6, 3, 6, 3, 6, 7, 6, 67, 10, 6, 12, 6, 14, 6, 70, 11, 6, 3, 6, 3, 6, 3, 6, 3, 6, 3, 6, 5, 6, 77, 10, 6, 3, 7, 3, 7, 7, 7, 81, 10, 7, 12, 7, 14, 7, 84, 11, 7, 3, 7, 3, 7, 3, 7, 7, 7, 89, 10, 7, 12, 7, 14, 7, 92, 11, 7, 3, 7, 3, 7, 5, 7, 96, 10, 7, 3, 8, 3, 8, 7, 8, 100, 10, 8, 12, 8, 14, 8, 103, 11, 8, 3, 8, 3, 8, 3, 8, 7, 8, 108, 10, 8, 12, 8, 14, 8, 111, 11, 8, 3, 8, 3, 8, 5, 8, 115, 10, 8, 3, 9, 3, 9, 7, 9, 119, 10, 9, 12, 9, 14, 9, 122, 11, 9, 3, 9, 3, 9, 3, 9, 7, 9, 127, 10, 9, 12, 9, 14, 9, 130, 11, 9, 3, 9, 3, 9, 5, 9, 134, 10, 9, 3, 10, 3, 10, 3, 10, 2, 2, 11, 2, 4, 6, 8, 10, 12, 14, 16, 18, 2, 4, 3, 2, 5, 11, 3, 2, 33, 42, 2, 157, 2, 20, 3, 2, 2, 2, 4, 27, 3, 2, 2, 2, 6, 36, 3, 2, 2, 2, 8, 38, 3, 2, 2, 2, 10, 76, 3, 2, 2, 2, 12, 95, 3, 2, 2, 2, 14, 114, 3, 2, 2, 2, 16, 133, 3, 2, 2, 2, 18, 135, 3, 2, 2, 2, 20, 21, 5, 4, 3, 2, 21, 22, 7, 3, 2, 2, 22, 23, 5, 4, 3, 2, 23, 3, 3, 2, 2, 2, 24, 26, 5, 6, 4, 2, 25, 24, 3, 2, 2, 2, 26, 29, 3, 2, 2, 2, 27, 25, 3, 2, 2, 2, 27, 28, 3, 2, 2, 2, 28, 5, 3, 2, 2, 2, 29, 27, 3, 2, 2, 2, 30, 37, 5, 12, 7, 2, 31, 37, 5, 8, 5, 2, 32, 37, 5, 10, 6, 2, 33, 37, 5, 14, 8, 2, 34, 37, 5, 16, 9, 2, 35, 37, 7, 4, 2, 2, 36, 30, 3, 2, 2, 2, 36, 31, 3, 2, 2, 2, 36, 32, 3, 2, 2, 2, 36, 33, 3, 2, 2, 2, 36, 34, 3, 2, 2, 2, 36, 35, 3, 2, 2, 2, 37, 7, 3, 2, 2, 2, 38, 39, 9, 2, 2, 2, 39, 9, 3, 2, 2, 2, 40, 44, 7, 12, 2, 2, 41, 43, 5, 6, 4, 2, 42, 41, 3, 2, 2, 2, 43, 46, 3, 2, 2, 2, 44, 42, 3, 2, 2, 2, 44, 45, 3, 2, 2, 2, 45, 47, 3, 2, 2, 2, 46, 44, 3, 2, 2, 2, 47, 77, 7, 13, 2, 2, 48, 52, 7, 14, 2, 2, 49, 51, 5, 6, 4, 2, 50, 49, 3, 2, 2, 2, 51, 54, 3, 2, 2, 2, 52, 50, 3, 2, 2, 2, 52, 53, 3, 2, 2, 2, 53, 55, 3, 2, 2, 2, 54, 52, 3, 2, 2, 2, 55, 77, 7, 15, 2, 2, 56, 60, 7, 16, 2, 2, 57, 59, 5, 6, 4, 2, 58, 57, 3, 2, 2, 2, 59, 62, 3, 2, 2, 2, 60, 58, 3, 2, 2, 2, 60, 61, 3, 2, 2, 2, 61, 63, 3, 2, 2, 2, 62, 60, 3, 2, 2, 2, 63, 77, 7, 17, 2, 2, 64, 68, 7, 18, 2, 2, 65, 67, 5, 6, 4, 2, 66, 65, 3, 2, 2, 2, 67, 70, 3, 2, 2, 2, 68, 66, 3, 2, 2, 2, 68, 69, 3, 2, 2, 2, 69, 71, 3, 2, 2, 2, 70, 68, 3, 2, 2, 2, 71, 77, 7, 18, 2, 2, 72, 77, 7, 19, 2, 2, 73, 77, 7, 20, 2, 2, 74, 77, 7, 21, 2, 2, 75, 77, 7, 22, 2, 2, 76, 40, 3, 2, 2, 2, 76, 48, 3, 2, 2, 2, 76, 56, 3, 2, 2, 2, 76, 64, 3, 2, 2, 2, 76, 72, 3, 2, 2, 2, 76, 73, 3, 2, 2, 2, 76, 74, 3, 2, 2, 2, 76, 75, 3, 2, 2, 2, 77, 11, 3, 2, 2, 2, 78, 82, 7, 23, 2, 2, 79, 81, 5, 18, 10, 2, 80, 79, 3, 2, 2, 2, 81, 84, 3, 2, 2, 2, 82, 80, 3, 2, 2, 2, 82, 83, 3, 2, 2, 2, 83, 85, 3, 2, 2, 2, 84, 82, 3, 2, 2, 2, 85, 96, 7, 24, 2, 2, 86, 90, 7, 25, 2, 2, 87, 89, 5, 18, 10, 2, 88, 87, 3, 2, 2, 2, 89, 92, 3, 2, 2, 2, 90, 88, 3, 2, 2, 2, 90, 91, 3, 2, 2, 2, 91, 93, 3, 2, 2, 2, 92, 90, 3, 2, 2, 2, 93, 96, 7, 24, 2, 2, 94, 96, 7, 26, 2, 2, 95, 78, 3, 2, 2, 2, 95, 86, 3, 2, 2, 2, 95, 94, 3, 2, 2, 2, 96, 13, 3, 2, 2, 2, 97, 101, 7, 27, 2, 2, 98, 100, 5, 18, 10, 2, 99, 98, 3, 2, 2, 2, 100, 103, 3, 2, 2, 2, 101, 99, 3, 2, 2, 2, 101, 102, 3, 2, 2, 2, 102, 104, 3, 2, 2, 2, 103, 101, 3, 2, 2, 2, 104, 115, 7, 24, 2, 2, 105, 109, 7, 28, 2, 2, 106, 108, 5, 18, 10, 2, 107, 106, 3, 2, 2, 2, 108, 111, 3, 2, 2, 2, 109, 107, 3, 2, 2, 2, 109, 110, 3, 2, 2, 2, 110, 112, 3, 2, 2, 2, 111, 109, 3, 2, 2, 2, 112, 115, 7, 24, 2, 2, 113, 115, 7, 29, 2, 2, 114, 97, 3, 2, 2, 2, 114, 105, 3, 2, 2, 2, 114, 113, 3, 2, 2, 2, 115, 15, 3, 2, 2, 2, 116, 120, 7, 30, 2, 2, 117, 119, 5, 18, 10, 2, 118, 117, 3, 2, 2, 2, 119, 122, 3, 2, 2, 2, 120, 118, 3, 2, 2, 2, 120, 121, 3, 2, 2, 2, 121, 123, 3, 2, 2, 2, 122, 120, 3, 2, 2, 2, 123, 134, 7, 24, 2, 2, 124, 128, 7, 31, 2, 2, 125, 127, 5, 18, 10, 2, 126, 125, 3, 2, 2, 2, 127, 130, 3, 2, 2, 2, 128, 126, 3, 2, 2, 2, 128, 129, 3, 2, 2, 2, 129, 131, 3, 2, 2, 2, 130, 128, 3, 2, 2, 2, 131, 134, 7, 24, 2, 2, 132, 134, 7, 32, 2, 2, 133, 116, 3, 2, 2, 2, 133, 124, 3, 2, 2, 2, 133, 132, 3, 2, 2, 2, 134, 17, 3, 2, 2, 2, 135, 136, 9, 3, 2, 2, 136, 19, 3, 2, 2, 2, 18, 27, 36, 44, 52, 60, 68, 76, 82, 90, 95, 101, 109, 114, 120, 128, 133]
\ No newline at end of file
diff --git a/code/antlr4/.antlr/Search.tokens b/code/antlr4/.antlr/Search.tokens
new file mode 100644
index 0000000..372bf0c
--- /dev/null
+++ b/code/antlr4/.antlr/Search.tokens
@@ -0,0 +1,81 @@
+T__0=1
+T__1=2
+T__2=3
+T__3=4
+T__4=5
+T__5=6
+T__6=7
+T__7=8
+T__8=9
+T__9=10
+T__10=11
+T__11=12
+T__12=13
+T__13=14
+T__14=15
+T__15=16
+T__16=17
+T__17=18
+T__18=19
+T__19=20
+T__20=21
+T__21=22
+T__22=23
+T__23=24
+T__24=25
+T__25=26
+T__26=27
+T__27=28
+T__28=29
+T__29=30
+T__30=31
+T__31=32
+T__32=33
+T__33=34
+T__34=35
+T__35=36
+T__36=37
+T__37=38
+T__38=39
+T__39=40
+WS=41
+'->'=1
+'_'=2
+'if'=3
+'else'=4
+'for'=5
+'forEach'=6
+'while'=7
+'return'=8
+'NULL'=9
+'('=10
+')'=11
+'['=12
+']'=13
+'{'=14
+'}'=15
+'"'=16
+'='=17
+'.'=18
+','=19
+';'=20
+'#ID<'=21
+'>'=22
+'#ID<!'=23
+'#ID<.>'=24
+'#OP<'=25
+'#OP<!'=26
+'#OP<.>'=27
+'#LT<'=28
+'#LT<!'=29
+'#LT<.>'=30
+'0'=31
+'1'=32
+'2'=33
+'3'=34
+'4'=35
+'5'=36
+'6'=37
+'7'=38
+'8'=39
+'9'=40
diff --git a/code/antlr4/.antlr/SearchLexer.interp b/code/antlr4/.antlr/SearchLexer.interp
new file mode 100644
index 0000000..062f29e
--- /dev/null
+++ b/code/antlr4/.antlr/SearchLexer.interp
@@ -0,0 +1,140 @@
+token literal names:
+null
+'->'
+'_'
+'if'
+'else'
+'for'
+'forEach'
+'while'
+'return'
+'NULL'
+'('
+')'
+'['
+']'
+'{'
+'}'
+'"'
+'='
+'.'
+','
+';'
+'#ID<'
+'>'
+'#ID<!'
+'#ID<.>'
+'#OP<'
+'#OP<!'
+'#OP<.>'
+'#LT<'
+'#LT<!'
+'#LT<.>'
+'0'
+'1'
+'2'
+'3'
+'4'
+'5'
+'6'
+'7'
+'8'
+'9'
+null
+
+token symbolic names:
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+null
+WS
+
+rule names:
+T__0
+T__1
+T__2
+T__3
+T__4
+T__5
+T__6
+T__7
+T__8
+T__9
+T__10
+T__11
+T__12
+T__13
+T__14
+T__15
+T__16
+T__17
+T__18
+T__19
+T__20
+T__21
+T__22
+T__23
+T__24
+T__25
+T__26
+T__27
+T__28
+T__29
+T__30
+T__31
+T__32
+T__33
+T__34
+T__35
+T__36
+T__37
+T__38
+T__39
+WS
+
+channel names:
+DEFAULT_TOKEN_CHANNEL
+HIDDEN
+
+mode names:
+DEFAULT_MODE
+
+atn:
+[3, 24715, 42794, 33075, 47597, 16764, 15335, 30598, 22884, 2, 43, 233, 8, 1, 4, 2, 9, 2, 4, 3, 9, 3, 4, 4, 9, 4, 4, 5, 9, 5, 4, 6, 9, 6, 4, 7, 9, 7, 4, 8, 9, 8, 4, 9, 9, 9, 4, 10, 9, 10, 4, 11, 9, 11, 4, 12, 9, 12, 4, 13, 9, 13, 4, 14, 9, 14, 4, 15, 9, 15, 4, 16, 9, 16, 4, 17, 9, 17, 4, 18, 9, 18, 4, 19, 9, 19, 4, 20, 9, 20, 4, 21, 9, 21, 4, 22, 9, 22, 4, 23, 9, 23, 4, 24, 9, 24, 4, 25, 9, 25, 4, 26, 9, 26, 4, 27, 9, 27, 4, 28, 9, 28, 4, 29, 9, 29, 4, 30, 9, 30, 4, 31, 9, 31, 4, 32, 9, 32, 4, 33, 9, 33, 4, 34, 9, 34, 4, 35, 9, 35, 4, 36, 9, 36, 4, 37, 9, 37, 4, 38, 9, 38, 4, 39, 9, 39, 4, 40, 9, 40, 4, 41, 9, 41, 4, 42, 9, 42, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 6, 3, 6, 3, 6, 3, 6, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 7, 3, 8, 3, 8, 3, 8, 3, 8, 3, 8, 3, 8, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3, 9, 3, 10, 3, 10, 3, 10, 3, 10, 3, 10, 3, 11, 3, 11, 3, 12, 3, 12, 3, 13, 3, 13, 3, 14, 3, 14, 3, 15, 3, 15, 3, 16, 3, 16, 3, 17, 3, 17, 3, 18, 3, 18, 3, 19, 3, 19, 3, 20, 3, 20, 3, 21, 3, 21, 3, 22, 3, 22, 3, 22, 3, 22, 3, 22, 3, 23, 3, 23, 3, 24, 3, 24, 3, 24, 3, 24, 3, 24, 3, 24, 3, 25, 3, 25, 3, 25, 3, 25, 3, 25, 3, 25, 3, 25, 3, 26, 3, 26, 3, 26, 3, 26, 3, 26, 3, 27, 3, 27, 3, 27, 3, 27, 3, 27, 3, 27, 3, 28, 3, 28, 3, 28, 3, 28, 3, 28, 3, 28, 3, 28, 3, 29, 3, 29, 3, 29, 3, 29, 3, 29, 3, 30, 3, 30, 3, 30, 3, 30, 3, 30, 3, 30, 3, 31, 3, 31, 3, 31, 3, 31, 3, 31, 3, 31, 3, 31, 3, 32, 3, 32, 3, 33, 3, 33, 3, 34, 3, 34, 3, 35, 3, 35, 3, 36, 3, 36, 3, 37, 3, 37, 3, 38, 3, 38, 3, 39, 3, 39, 3, 40, 3, 40, 3, 41, 3, 41, 3, 42, 6, 42, 228, 10, 42, 13, 42, 14, 42, 229, 3, 42, 3, 42, 2, 2, 43, 3, 3, 5, 4, 7, 5, 9, 6, 11, 7, 13, 8, 15, 9, 17, 10, 19, 11, 21, 12, 23, 13, 25, 14, 27, 15, 29, 16, 31, 17, 33, 18, 35, 19, 37, 20, 39, 21, 41, 22, 43, 23, 45, 24, 47, 25, 49, 26, 51, 27, 53, 28, 55, 29, 57, 30, 59, 31, 61, 32, 63, 33, 65, 34, 67, 35, 69, 36, 71, 37, 73, 38, 75, 39, 77, 40, 79, 41, 81, 42, 83, 43, 3, 2, 3, 5, 2, 11, 12, 15, 15, 34, 34, 2, 233, 2, 3, 3, 2, 2, 2, 2, 5, 3, 2, 2, 2, 2, 7, 3, 2, 2, 2, 2, 9, 3, 2, 2, 2, 2, 11, 3, 2, 2, 2, 2, 13, 3, 2, 2, 2, 2, 15, 3, 2, 2, 2, 2, 17, 3, 2, 2, 2, 2, 19, 3, 2, 2, 2, 2, 21, 3, 2, 2, 2, 2, 23, 3, 2, 2, 2, 2, 25, 3, 2, 2, 2, 2, 27, 3, 2, 2, 2, 2, 29, 3, 2, 2, 2, 2, 31, 3, 2, 2, 2, 2, 33, 3, 2, 2, 2, 2, 35, 3, 2, 2, 2, 2, 37, 3, 2, 2, 2, 2, 39, 3, 2, 2, 2, 2, 41, 3, 2, 2, 2, 2, 43, 3, 2, 2, 2, 2, 45, 3, 2, 2, 2, 2, 47, 3, 2, 2, 2, 2, 49, 3, 2, 2, 2, 2, 51, 3, 2, 2, 2, 2, 53, 3, 2, 2, 2, 2, 55, 3, 2, 2, 2, 2, 57, 3, 2, 2, 2, 2, 59, 3, 2, 2, 2, 2, 61, 3, 2, 2, 2, 2, 63, 3, 2, 2, 2, 2, 65, 3, 2, 2, 2, 2, 67, 3, 2, 2, 2, 2, 69, 3, 2, 2, 2, 2, 71, 3, 2, 2, 2, 2, 73, 3, 2, 2, 2, 2, 75, 3, 2, 2, 2, 2, 77, 3, 2, 2, 2, 2, 79, 3, 2, 2, 2, 2, 81, 3, 2, 2, 2, 2, 83, 3, 2, 2, 2, 3, 85, 3, 2, 2, 2, 5, 88, 3, 2, 2, 2, 7, 90, 3, 2, 2, 2, 9, 93, 3, 2, 2, 2, 11, 98, 3, 2, 2, 2, 13, 102, 3, 2, 2, 2, 15, 110, 3, 2, 2, 2, 17, 116, 3, 2, 2, 2, 19, 123, 3, 2, 2, 2, 21, 128, 3, 2, 2, 2, 23, 130, 3, 2, 2, 2, 25, 132, 3, 2, 2, 2, 27, 134, 3, 2, 2, 2, 29, 136, 3, 2, 2, 2, 31, 138, 3, 2, 2, 2, 33, 140, 3, 2, 2, 2, 35, 142, 3, 2, 2, 2, 37, 144, 3, 2, 2, 2, 39, 146, 3, 2, 2, 2, 41, 148, 3, 2, 2, 2, 43, 150, 3, 2, 2, 2, 45, 155, 3, 2, 2, 2, 47, 157, 3, 2, 2, 2, 49, 163, 3, 2, 2, 2, 51, 170, 3, 2, 2, 2, 53, 175, 3, 2, 2, 2, 55, 181, 3, 2, 2, 2, 57, 188, 3, 2, 2, 2, 59, 193, 3, 2, 2, 2, 61, 199, 3, 2, 2, 2, 63, 206, 3, 2, 2, 2, 65, 208, 3, 2, 2, 2, 67, 210, 3, 2, 2, 2, 69, 212, 3, 2, 2, 2, 71, 214, 3, 2, 2, 2, 73, 216, 3, 2, 2, 2, 75, 218, 3, 2, 2, 2, 77, 220, 3, 2, 2, 2, 79, 222, 3, 2, 2, 2, 81, 224, 3, 2, 2, 2, 83, 227, 3, 2, 2, 2, 85, 86, 7, 47, 2, 2, 86, 87, 7, 64, 2, 2, 87, 4, 3, 2, 2, 2, 88, 89, 7, 97, 2, 2, 89, 6, 3, 2, 2, 2, 90, 91, 7, 107, 2, 2, 91, 92, 7, 104, 2, 2, 92, 8, 3, 2, 2, 2, 93, 94, 7, 103, 2, 2, 94, 95, 7, 110, 2, 2, 95, 96, 7, 117, 2, 2, 96, 97, 7, 103, 2, 2, 97, 10, 3, 2, 2, 2, 98, 99, 7, 104, 2, 2, 99, 100, 7, 113, 2, 2, 100, 101, 7, 116, 2, 2, 101, 12, 3, 2, 2, 2, 102, 103, 7, 104, 2, 2, 103, 104, 7, 113, 2, 2, 104, 105, 7, 116, 2, 2, 105, 106, 7, 71, 2, 2, 106, 107, 7, 99, 2, 2, 107, 108, 7, 101, 2, 2, 108, 109, 7, 106, 2, 2, 109, 14, 3, 2, 2, 2, 110, 111, 7, 121, 2, 2, 111, 112, 7, 106, 2, 2, 112, 113, 7, 107, 2, 2, 113, 114, 7, 110, 2, 2, 114, 115, 7, 103, 2, 2, 115, 16, 3, 2, 2, 2, 116, 117, 7, 116, 2, 2, 117, 118, 7, 103, 2, 2, 118, 119, 7, 118, 2, 2, 119, 120, 7, 119, 2, 2, 120, 121, 7, 116, 2, 2, 121, 122, 7, 112, 2, 2, 122, 18, 3, 2, 2, 2, 123, 124, 7, 80, 2, 2, 124, 125, 7, 87, 2, 2, 125, 126, 7, 78, 2, 2, 126, 127, 7, 78, 2, 2, 127, 20, 3, 2, 2, 2, 128, 129, 7, 42, 2, 2, 129, 22, 3, 2, 2, 2, 130, 131, 7, 43, 2, 2, 131, 24, 3, 2, 2, 2, 132, 133, 7, 93, 2, 2, 133, 26, 3, 2, 2, 2, 134, 135, 7, 95, 2, 2, 135, 28, 3, 2, 2, 2, 136, 137, 7, 125, 2, 2, 137, 30, 3, 2, 2, 2, 138, 139, 7, 127, 2, 2, 139, 32, 3, 2, 2, 2, 140, 141, 7, 36, 2, 2, 141, 34, 3, 2, 2, 2, 142, 143, 7, 63, 2, 2, 143, 36, 3, 2, 2, 2, 144, 145, 7, 48, 2, 2, 145, 38, 3, 2, 2, 2, 146, 147, 7, 46, 2, 2, 147, 40, 3, 2, 2, 2, 148, 149, 7, 61, 2, 2, 149, 42, 3, 2, 2, 2, 150, 151, 7, 37, 2, 2, 151, 152, 7, 75, 2, 2, 152, 153, 7, 70, 2, 2, 153, 154, 7, 62, 2, 2, 154, 44, 3, 2, 2, 2, 155, 156, 7, 64, 2, 2, 156, 46, 3, 2, 2, 2, 157, 158, 7, 37, 2, 2, 158, 159, 7, 75, 2, 2, 159, 160, 7, 70, 2, 2, 160, 161, 7, 62, 2, 2, 161, 162, 7, 35, 2, 2, 162, 48, 3, 2, 2, 2, 163, 164, 7, 37, 2, 2, 164, 165, 7, 75, 2, 2, 165, 166, 7, 70, 2, 2, 166, 167, 7, 62, 2, 2, 167, 168, 7, 48, 2, 2, 168, 169, 7, 64, 2, 2, 169, 50, 3, 2, 2, 2, 170, 171, 7, 37, 2, 2, 171, 172, 7, 81, 2, 2, 172, 173, 7, 82, 2, 2, 173, 174, 7, 62, 2, 2, 174, 52, 3, 2, 2, 2, 175, 176, 7, 37, 2, 2, 176, 177, 7, 81, 2, 2, 177, 178, 7, 82, 2, 2, 178, 179, 7, 62, 2, 2, 179, 180, 7, 35, 2, 2, 180, 54, 3, 2, 2, 2, 181, 182, 7, 37, 2, 2, 182, 183, 7, 81, 2, 2, 183, 184, 7, 82, 2, 2, 184, 185, 7, 62, 2, 2, 185, 186, 7, 48, 2, 2, 186, 187, 7, 64, 2, 2, 187, 56, 3, 2, 2, 2, 188, 189, 7, 37, 2, 2, 189, 190, 7, 78, 2, 2, 190, 191, 7, 86, 2, 2, 191, 192, 7, 62, 2, 2, 192, 58, 3, 2, 2, 2, 193, 194, 7, 37, 2, 2, 194, 195, 7, 78, 2, 2, 195, 196, 7, 86, 2, 2, 196, 197, 7, 62, 2, 2, 197, 198, 7, 35, 2, 2, 198, 60, 3, 2, 2, 2, 199, 200, 7, 37, 2, 2, 200, 201, 7, 78, 2, 2, 201, 202, 7, 86, 2, 2, 202, 203, 7, 62, 2, 2, 203, 204, 7, 48, 2, 2, 204, 205, 7, 64, 2, 2, 205, 62, 3, 2, 2, 2, 206, 207, 7, 50, 2, 2, 207, 64, 3, 2, 2, 2, 208, 209, 7, 51, 2, 2, 209, 66, 3, 2, 2, 2, 210, 211, 7, 52, 2, 2, 211, 68, 3, 2, 2, 2, 212, 213, 7, 53, 2, 2, 213, 70, 3, 2, 2, 2, 214, 215, 7, 54, 2, 2, 215, 72, 3, 2, 2, 2, 216, 217, 7, 55, 2, 2, 217, 74, 3, 2, 2, 2, 218, 219, 7, 56, 2, 2, 219, 76, 3, 2, 2, 2, 220, 221, 7, 57, 2, 2, 221, 78, 3, 2, 2, 2, 222, 223, 7, 58, 2, 2, 223, 80, 3, 2, 2, 2, 224, 225, 7, 59, 2, 2, 225, 82, 3, 2, 2, 2, 226, 228, 9, 2, 2, 2, 227, 226, 3, 2, 2, 2, 228, 229, 3, 2, 2, 2, 229, 227, 3, 2, 2, 2, 229, 230, 3, 2, 2, 2, 230, 231, 3, 2, 2, 2, 231, 232, 8, 42, 2, 2, 232, 84, 3, 2, 2, 2, 4, 2, 229, 3, 8, 2, 2]
\ No newline at end of file
diff --git a/code/antlr4/.antlr/SearchLexer.java b/code/antlr4/.antlr/SearchLexer.java
new file mode 100644
index 0000000..fc4fc16
--- /dev/null
+++ b/code/antlr4/.antlr/SearchLexer.java
@@ -0,0 +1,188 @@
+// Generated from /home/luca/Desktop/Project/dSearch/code/antlr4/Search.g4 by ANTLR 4.7.1
+import org.antlr.v4.runtime.Lexer;
+import org.antlr.v4.runtime.CharStream;
+import org.antlr.v4.runtime.Token;
+import org.antlr.v4.runtime.TokenStream;
+import org.antlr.v4.runtime.*;
+import org.antlr.v4.runtime.atn.*;
+import org.antlr.v4.runtime.dfa.DFA;
+import org.antlr.v4.runtime.misc.*;
+
+@SuppressWarnings({"all", "warnings", "unchecked", "unused", "cast"})
+public class SearchLexer extends Lexer {
+	static { RuntimeMetaData.checkVersion("4.7.1", RuntimeMetaData.VERSION); }
+
+	protected static final DFA[] _decisionToDFA;
+	protected static final PredictionContextCache _sharedContextCache =
+		new PredictionContextCache();
+	public static final int
+		T__0=1, T__1=2, T__2=3, T__3=4, T__4=5, T__5=6, T__6=7, T__7=8, T__8=9, 
+		T__9=10, T__10=11, T__11=12, T__12=13, T__13=14, T__14=15, T__15=16, T__16=17, 
+		T__17=18, T__18=19, T__19=20, T__20=21, T__21=22, T__22=23, T__23=24, 
+		T__24=25, T__25=26, T__26=27, T__27=28, T__28=29, T__29=30, T__30=31, 
+		T__31=32, T__32=33, T__33=34, T__34=35, T__35=36, T__36=37, T__37=38, 
+		T__38=39, T__39=40, WS=41;
+	public static String[] channelNames = {
+		"DEFAULT_TOKEN_CHANNEL", "HIDDEN"
+	};
+
+	public static String[] modeNames = {
+		"DEFAULT_MODE"
+	};
+
+	public static final String[] ruleNames = {
+		"T__0", "T__1", "T__2", "T__3", "T__4", "T__5", "T__6", "T__7", "T__8", 
+		"T__9", "T__10", "T__11", "T__12", "T__13", "T__14", "T__15", "T__16", 
+		"T__17", "T__18", "T__19", "T__20", "T__21", "T__22", "T__23", "T__24", 
+		"T__25", "T__26", "T__27", "T__28", "T__29", "T__30", "T__31", "T__32", 
+		"T__33", "T__34", "T__35", "T__36", "T__37", "T__38", "T__39", "WS"
+	};
+
+	private static final String[] _LITERAL_NAMES = {
+		null, "'->'", "'_'", "'if'", "'else'", "'for'", "'forEach'", "'while'", 
+		"'return'", "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", 
+		"'='", "'.'", "','", "';'", "'#ID<'", "'>'", "'#ID<!'", "'#ID<.>'", "'#OP<'", 
+		"'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", "'#LT<.>'", "'0'", "'1'", 
+		"'2'", "'3'", "'4'", "'5'", "'6'", "'7'", "'8'", "'9'"
+	};
+	private static final String[] _SYMBOLIC_NAMES = {
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, "WS"
+	};
+	public static final Vocabulary VOCABULARY = new VocabularyImpl(_LITERAL_NAMES, _SYMBOLIC_NAMES);
+
+	/**
+	 * @deprecated Use {@link #VOCABULARY} instead.
+	 */
+	@Deprecated
+	public static final String[] tokenNames;
+	static {
+		tokenNames = new String[_SYMBOLIC_NAMES.length];
+		for (int i = 0; i < tokenNames.length; i++) {
+			tokenNames[i] = VOCABULARY.getLiteralName(i);
+			if (tokenNames[i] == null) {
+				tokenNames[i] = VOCABULARY.getSymbolicName(i);
+			}
+
+			if (tokenNames[i] == null) {
+				tokenNames[i] = "<INVALID>";
+			}
+		}
+	}
+
+	@Override
+	@Deprecated
+	public String[] getTokenNames() {
+		return tokenNames;
+	}
+
+	@Override
+
+	public Vocabulary getVocabulary() {
+		return VOCABULARY;
+	}
+
+
+	public SearchLexer(CharStream input) {
+		super(input);
+		_interp = new LexerATNSimulator(this,_ATN,_decisionToDFA,_sharedContextCache);
+	}
+
+	@Override
+	public String getGrammarFileName() { return "Search.g4"; }
+
+	@Override
+	public String[] getRuleNames() { return ruleNames; }
+
+	@Override
+	public String getSerializedATN() { return _serializedATN; }
+
+	@Override
+	public String[] getChannelNames() { return channelNames; }
+
+	@Override
+	public String[] getModeNames() { return modeNames; }
+
+	@Override
+	public ATN getATN() { return _ATN; }
+
+	public static final String _serializedATN =
+		"\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2+\u00e9\b\1\4\2\t"+
+		"\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13"+
+		"\t\13\4\f\t\f\4\r\t\r\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22"+
+		"\4\23\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30\4\31\t\31"+
+		"\4\32\t\32\4\33\t\33\4\34\t\34\4\35\t\35\4\36\t\36\4\37\t\37\4 \t \4!"+
+		"\t!\4\"\t\"\4#\t#\4$\t$\4%\t%\4&\t&\4\'\t\'\4(\t(\4)\t)\4*\t*\3\2\3\2"+
+		"\3\2\3\3\3\3\3\4\3\4\3\4\3\5\3\5\3\5\3\5\3\5\3\6\3\6\3\6\3\6\3\7\3\7\3"+
+		"\7\3\7\3\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\t\3\t\3\t\3\t\3\t\3\t"+
+		"\3\t\3\n\3\n\3\n\3\n\3\n\3\13\3\13\3\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17"+
+		"\3\20\3\20\3\21\3\21\3\22\3\22\3\23\3\23\3\24\3\24\3\25\3\25\3\26\3\26"+
+		"\3\26\3\26\3\26\3\27\3\27\3\30\3\30\3\30\3\30\3\30\3\30\3\31\3\31\3\31"+
+		"\3\31\3\31\3\31\3\31\3\32\3\32\3\32\3\32\3\32\3\33\3\33\3\33\3\33\3\33"+
+		"\3\33\3\34\3\34\3\34\3\34\3\34\3\34\3\34\3\35\3\35\3\35\3\35\3\35\3\36"+
+		"\3\36\3\36\3\36\3\36\3\36\3\37\3\37\3\37\3\37\3\37\3\37\3\37\3 \3 \3!"+
+		"\3!\3\"\3\"\3#\3#\3$\3$\3%\3%\3&\3&\3\'\3\'\3(\3(\3)\3)\3*\6*\u00e4\n"+
+		"*\r*\16*\u00e5\3*\3*\2\2+\3\3\5\4\7\5\t\6\13\7\r\b\17\t\21\n\23\13\25"+
+		"\f\27\r\31\16\33\17\35\20\37\21!\22#\23%\24\'\25)\26+\27-\30/\31\61\32"+
+		"\63\33\65\34\67\359\36;\37= ?!A\"C#E$G%I&K\'M(O)Q*S+\3\2\3\5\2\13\f\17"+
+		"\17\"\"\2\u00e9\2\3\3\2\2\2\2\5\3\2\2\2\2\7\3\2\2\2\2\t\3\2\2\2\2\13\3"+
+		"\2\2\2\2\r\3\2\2\2\2\17\3\2\2\2\2\21\3\2\2\2\2\23\3\2\2\2\2\25\3\2\2\2"+
+		"\2\27\3\2\2\2\2\31\3\2\2\2\2\33\3\2\2\2\2\35\3\2\2\2\2\37\3\2\2\2\2!\3"+
+		"\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2\'\3\2\2\2\2)\3\2\2\2\2+\3\2\2\2\2-\3\2"+
+		"\2\2\2/\3\2\2\2\2\61\3\2\2\2\2\63\3\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\2"+
+		"9\3\2\2\2\2;\3\2\2\2\2=\3\2\2\2\2?\3\2\2\2\2A\3\2\2\2\2C\3\2\2\2\2E\3"+
+		"\2\2\2\2G\3\2\2\2\2I\3\2\2\2\2K\3\2\2\2\2M\3\2\2\2\2O\3\2\2\2\2Q\3\2\2"+
+		"\2\2S\3\2\2\2\3U\3\2\2\2\5X\3\2\2\2\7Z\3\2\2\2\t]\3\2\2\2\13b\3\2\2\2"+
+		"\rf\3\2\2\2\17n\3\2\2\2\21t\3\2\2\2\23{\3\2\2\2\25\u0080\3\2\2\2\27\u0082"+
+		"\3\2\2\2\31\u0084\3\2\2\2\33\u0086\3\2\2\2\35\u0088\3\2\2\2\37\u008a\3"+
+		"\2\2\2!\u008c\3\2\2\2#\u008e\3\2\2\2%\u0090\3\2\2\2\'\u0092\3\2\2\2)\u0094"+
+		"\3\2\2\2+\u0096\3\2\2\2-\u009b\3\2\2\2/\u009d\3\2\2\2\61\u00a3\3\2\2\2"+
+		"\63\u00aa\3\2\2\2\65\u00af\3\2\2\2\67\u00b5\3\2\2\29\u00bc\3\2\2\2;\u00c1"+
+		"\3\2\2\2=\u00c7\3\2\2\2?\u00ce\3\2\2\2A\u00d0\3\2\2\2C\u00d2\3\2\2\2E"+
+		"\u00d4\3\2\2\2G\u00d6\3\2\2\2I\u00d8\3\2\2\2K\u00da\3\2\2\2M\u00dc\3\2"+
+		"\2\2O\u00de\3\2\2\2Q\u00e0\3\2\2\2S\u00e3\3\2\2\2UV\7/\2\2VW\7@\2\2W\4"+
+		"\3\2\2\2XY\7a\2\2Y\6\3\2\2\2Z[\7k\2\2[\\\7h\2\2\\\b\3\2\2\2]^\7g\2\2^"+
+		"_\7n\2\2_`\7u\2\2`a\7g\2\2a\n\3\2\2\2bc\7h\2\2cd\7q\2\2de\7t\2\2e\f\3"+
+		"\2\2\2fg\7h\2\2gh\7q\2\2hi\7t\2\2ij\7G\2\2jk\7c\2\2kl\7e\2\2lm\7j\2\2"+
+		"m\16\3\2\2\2no\7y\2\2op\7j\2\2pq\7k\2\2qr\7n\2\2rs\7g\2\2s\20\3\2\2\2"+
+		"tu\7t\2\2uv\7g\2\2vw\7v\2\2wx\7w\2\2xy\7t\2\2yz\7p\2\2z\22\3\2\2\2{|\7"+
+		"P\2\2|}\7W\2\2}~\7N\2\2~\177\7N\2\2\177\24\3\2\2\2\u0080\u0081\7*\2\2"+
+		"\u0081\26\3\2\2\2\u0082\u0083\7+\2\2\u0083\30\3\2\2\2\u0084\u0085\7]\2"+
+		"\2\u0085\32\3\2\2\2\u0086\u0087\7_\2\2\u0087\34\3\2\2\2\u0088\u0089\7"+
+		"}\2\2\u0089\36\3\2\2\2\u008a\u008b\7\177\2\2\u008b \3\2\2\2\u008c\u008d"+
+		"\7$\2\2\u008d\"\3\2\2\2\u008e\u008f\7?\2\2\u008f$\3\2\2\2\u0090\u0091"+
+		"\7\60\2\2\u0091&\3\2\2\2\u0092\u0093\7.\2\2\u0093(\3\2\2\2\u0094\u0095"+
+		"\7=\2\2\u0095*\3\2\2\2\u0096\u0097\7%\2\2\u0097\u0098\7K\2\2\u0098\u0099"+
+		"\7F\2\2\u0099\u009a\7>\2\2\u009a,\3\2\2\2\u009b\u009c\7@\2\2\u009c.\3"+
+		"\2\2\2\u009d\u009e\7%\2\2\u009e\u009f\7K\2\2\u009f\u00a0\7F\2\2\u00a0"+
+		"\u00a1\7>\2\2\u00a1\u00a2\7#\2\2\u00a2\60\3\2\2\2\u00a3\u00a4\7%\2\2\u00a4"+
+		"\u00a5\7K\2\2\u00a5\u00a6\7F\2\2\u00a6\u00a7\7>\2\2\u00a7\u00a8\7\60\2"+
+		"\2\u00a8\u00a9\7@\2\2\u00a9\62\3\2\2\2\u00aa\u00ab\7%\2\2\u00ab\u00ac"+
+		"\7Q\2\2\u00ac\u00ad\7R\2\2\u00ad\u00ae\7>\2\2\u00ae\64\3\2\2\2\u00af\u00b0"+
+		"\7%\2\2\u00b0\u00b1\7Q\2\2\u00b1\u00b2\7R\2\2\u00b2\u00b3\7>\2\2\u00b3"+
+		"\u00b4\7#\2\2\u00b4\66\3\2\2\2\u00b5\u00b6\7%\2\2\u00b6\u00b7\7Q\2\2\u00b7"+
+		"\u00b8\7R\2\2\u00b8\u00b9\7>\2\2\u00b9\u00ba\7\60\2\2\u00ba\u00bb\7@\2"+
+		"\2\u00bb8\3\2\2\2\u00bc\u00bd\7%\2\2\u00bd\u00be\7N\2\2\u00be\u00bf\7"+
+		"V\2\2\u00bf\u00c0\7>\2\2\u00c0:\3\2\2\2\u00c1\u00c2\7%\2\2\u00c2\u00c3"+
+		"\7N\2\2\u00c3\u00c4\7V\2\2\u00c4\u00c5\7>\2\2\u00c5\u00c6\7#\2\2\u00c6"+
+		"<\3\2\2\2\u00c7\u00c8\7%\2\2\u00c8\u00c9\7N\2\2\u00c9\u00ca\7V\2\2\u00ca"+
+		"\u00cb\7>\2\2\u00cb\u00cc\7\60\2\2\u00cc\u00cd\7@\2\2\u00cd>\3\2\2\2\u00ce"+
+		"\u00cf\7\62\2\2\u00cf@\3\2\2\2\u00d0\u00d1\7\63\2\2\u00d1B\3\2\2\2\u00d2"+
+		"\u00d3\7\64\2\2\u00d3D\3\2\2\2\u00d4\u00d5\7\65\2\2\u00d5F\3\2\2\2\u00d6"+
+		"\u00d7\7\66\2\2\u00d7H\3\2\2\2\u00d8\u00d9\7\67\2\2\u00d9J\3\2\2\2\u00da"+
+		"\u00db\78\2\2\u00dbL\3\2\2\2\u00dc\u00dd\79\2\2\u00ddN\3\2\2\2\u00de\u00df"+
+		"\7:\2\2\u00dfP\3\2\2\2\u00e0\u00e1\7;\2\2\u00e1R\3\2\2\2\u00e2\u00e4\t"+
+		"\2\2\2\u00e3\u00e2\3\2\2\2\u00e4\u00e5\3\2\2\2\u00e5\u00e3\3\2\2\2\u00e5"+
+		"\u00e6\3\2\2\2\u00e6\u00e7\3\2\2\2\u00e7\u00e8\b*\2\2\u00e8T\3\2\2\2\4"+
+		"\2\u00e5\3\b\2\2";
+	public static final ATN _ATN =
+		new ATNDeserializer().deserialize(_serializedATN.toCharArray());
+	static {
+		_decisionToDFA = new DFA[_ATN.getNumberOfDecisions()];
+		for (int i = 0; i < _ATN.getNumberOfDecisions(); i++) {
+			_decisionToDFA[i] = new DFA(_ATN.getDecisionState(i), i);
+		}
+	}
+}
\ No newline at end of file
diff --git a/code/antlr4/.antlr/SearchLexer.tokens b/code/antlr4/.antlr/SearchLexer.tokens
new file mode 100644
index 0000000..372bf0c
--- /dev/null
+++ b/code/antlr4/.antlr/SearchLexer.tokens
@@ -0,0 +1,81 @@
+T__0=1
+T__1=2
+T__2=3
+T__3=4
+T__4=5
+T__5=6
+T__6=7
+T__7=8
+T__8=9
+T__9=10
+T__10=11
+T__11=12
+T__12=13
+T__13=14
+T__14=15
+T__15=16
+T__16=17
+T__17=18
+T__18=19
+T__19=20
+T__20=21
+T__21=22
+T__22=23
+T__23=24
+T__24=25
+T__25=26
+T__26=27
+T__27=28
+T__28=29
+T__29=30
+T__30=31
+T__31=32
+T__32=33
+T__33=34
+T__34=35
+T__35=36
+T__36=37
+T__37=38
+T__38=39
+T__39=40
+WS=41
+'->'=1
+'_'=2
+'if'=3
+'else'=4
+'for'=5
+'forEach'=6
+'while'=7
+'return'=8
+'NULL'=9
+'('=10
+')'=11
+'['=12
+']'=13
+'{'=14
+'}'=15
+'"'=16
+'='=17
+'.'=18
+','=19
+';'=20
+'#ID<'=21
+'>'=22
+'#ID<!'=23
+'#ID<.>'=24
+'#OP<'=25
+'#OP<!'=26
+'#OP<.>'=27
+'#LT<'=28
+'#LT<!'=29
+'#LT<.>'=30
+'0'=31
+'1'=32
+'2'=33
+'3'=34
+'4'=35
+'5'=36
+'6'=37
+'7'=38
+'8'=39
+'9'=40
diff --git a/code/antlr4/.antlr/SearchParser.java b/code/antlr4/.antlr/SearchParser.java
new file mode 100644
index 0000000..139afe3
--- /dev/null
+++ b/code/antlr4/.antlr/SearchParser.java
@@ -0,0 +1,832 @@
+// Generated from /home/luca/Desktop/Project/dSearch/code/antlr4/Search.g4 by ANTLR 4.7.1
+import org.antlr.v4.runtime.atn.*;
+import org.antlr.v4.runtime.dfa.DFA;
+import org.antlr.v4.runtime.*;
+import org.antlr.v4.runtime.misc.*;
+import org.antlr.v4.runtime.tree.*;
+import java.util.List;
+import java.util.Iterator;
+import java.util.ArrayList;
+
+@SuppressWarnings({"all", "warnings", "unchecked", "unused", "cast"})
+public class SearchParser extends Parser {
+	static { RuntimeMetaData.checkVersion("4.7.1", RuntimeMetaData.VERSION); }
+
+	protected static final DFA[] _decisionToDFA;
+	protected static final PredictionContextCache _sharedContextCache =
+		new PredictionContextCache();
+	public static final int
+		T__0=1, T__1=2, T__2=3, T__3=4, T__4=5, T__5=6, T__6=7, T__7=8, T__8=9, 
+		T__9=10, T__10=11, T__11=12, T__12=13, T__13=14, T__14=15, T__15=16, T__16=17, 
+		T__17=18, T__18=19, T__19=20, T__20=21, T__21=22, T__22=23, T__23=24, 
+		T__24=25, T__25=26, T__26=27, T__27=28, T__28=29, T__29=30, T__30=31, 
+		T__31=32, T__32=33, T__33=34, T__34=35, T__35=36, T__36=37, T__37=38, 
+		T__38=39, T__39=40, WS=41;
+	public static final int
+		RULE_query = 0, RULE_code = 1, RULE_token = 2, RULE_keyword = 3, RULE_punctuator = 4, 
+		RULE_identifier = 5, RULE_operator = 6, RULE_literal = 7, RULE_digit = 8;
+	public static final String[] ruleNames = {
+		"query", "code", "token", "keyword", "punctuator", "identifier", "operator", 
+		"literal", "digit"
+	};
+
+	private static final String[] _LITERAL_NAMES = {
+		null, "'->'", "'_'", "'if'", "'else'", "'for'", "'forEach'", "'while'", 
+		"'return'", "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", 
+		"'='", "'.'", "','", "';'", "'#ID<'", "'>'", "'#ID<!'", "'#ID<.>'", "'#OP<'", 
+		"'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", "'#LT<.>'", "'0'", "'1'", 
+		"'2'", "'3'", "'4'", "'5'", "'6'", "'7'", "'8'", "'9'"
+	};
+	private static final String[] _SYMBOLIC_NAMES = {
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, null, null, null, null, null, null, null, 
+		null, null, null, null, null, "WS"
+	};
+	public static final Vocabulary VOCABULARY = new VocabularyImpl(_LITERAL_NAMES, _SYMBOLIC_NAMES);
+
+	/**
+	 * @deprecated Use {@link #VOCABULARY} instead.
+	 */
+	@Deprecated
+	public static final String[] tokenNames;
+	static {
+		tokenNames = new String[_SYMBOLIC_NAMES.length];
+		for (int i = 0; i < tokenNames.length; i++) {
+			tokenNames[i] = VOCABULARY.getLiteralName(i);
+			if (tokenNames[i] == null) {
+				tokenNames[i] = VOCABULARY.getSymbolicName(i);
+			}
+
+			if (tokenNames[i] == null) {
+				tokenNames[i] = "<INVALID>";
+			}
+		}
+	}
+
+	@Override
+	@Deprecated
+	public String[] getTokenNames() {
+		return tokenNames;
+	}
+
+	@Override
+
+	public Vocabulary getVocabulary() {
+		return VOCABULARY;
+	}
+
+	@Override
+	public String getGrammarFileName() { return "Search.g4"; }
+
+	@Override
+	public String[] getRuleNames() { return ruleNames; }
+
+	@Override
+	public String getSerializedATN() { return _serializedATN; }
+
+	@Override
+	public ATN getATN() { return _ATN; }
+
+	public SearchParser(TokenStream input) {
+		super(input);
+		_interp = new ParserATNSimulator(this,_ATN,_decisionToDFA,_sharedContextCache);
+	}
+	public static class QueryContext extends ParserRuleContext {
+		public List<CodeContext> code() {
+			return getRuleContexts(CodeContext.class);
+		}
+		public CodeContext code(int i) {
+			return getRuleContext(CodeContext.class,i);
+		}
+		public QueryContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_query; }
+	}
+
+	public final QueryContext query() throws RecognitionException {
+		QueryContext _localctx = new QueryContext(_ctx, getState());
+		enterRule(_localctx, 0, RULE_query);
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(18);
+			code();
+			setState(19);
+			match(T__0);
+			setState(20);
+			code();
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class CodeContext extends ParserRuleContext {
+		public List<TokenContext> token() {
+			return getRuleContexts(TokenContext.class);
+		}
+		public TokenContext token(int i) {
+			return getRuleContext(TokenContext.class,i);
+		}
+		public CodeContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_code; }
+	}
+
+	public final CodeContext code() throws RecognitionException {
+		CodeContext _localctx = new CodeContext(_ctx, getState());
+		enterRule(_localctx, 2, RULE_code);
+		int _la;
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(25);
+			_errHandler.sync(this);
+			_la = _input.LA(1);
+			while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+				{
+				{
+				setState(22);
+				token();
+				}
+				}
+				setState(27);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+			}
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class TokenContext extends ParserRuleContext {
+		public IdentifierContext identifier() {
+			return getRuleContext(IdentifierContext.class,0);
+		}
+		public KeywordContext keyword() {
+			return getRuleContext(KeywordContext.class,0);
+		}
+		public PunctuatorContext punctuator() {
+			return getRuleContext(PunctuatorContext.class,0);
+		}
+		public OperatorContext operator() {
+			return getRuleContext(OperatorContext.class,0);
+		}
+		public LiteralContext literal() {
+			return getRuleContext(LiteralContext.class,0);
+		}
+		public TokenContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_token; }
+	}
+
+	public final TokenContext token() throws RecognitionException {
+		TokenContext _localctx = new TokenContext(_ctx, getState());
+		enterRule(_localctx, 4, RULE_token);
+		try {
+			setState(34);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__20:
+			case T__22:
+			case T__23:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(28);
+				identifier();
+				}
+				break;
+			case T__2:
+			case T__3:
+			case T__4:
+			case T__5:
+			case T__6:
+			case T__7:
+			case T__8:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(29);
+				keyword();
+				}
+				break;
+			case T__9:
+			case T__11:
+			case T__13:
+			case T__15:
+			case T__16:
+			case T__17:
+			case T__18:
+			case T__19:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(30);
+				punctuator();
+				}
+				break;
+			case T__24:
+			case T__25:
+			case T__26:
+				enterOuterAlt(_localctx, 4);
+				{
+				setState(31);
+				operator();
+				}
+				break;
+			case T__27:
+			case T__28:
+			case T__29:
+				enterOuterAlt(_localctx, 5);
+				{
+				setState(32);
+				literal();
+				}
+				break;
+			case T__1:
+				enterOuterAlt(_localctx, 6);
+				{
+				setState(33);
+				match(T__1);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class KeywordContext extends ParserRuleContext {
+		public KeywordContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_keyword; }
+	}
+
+	public final KeywordContext keyword() throws RecognitionException {
+		KeywordContext _localctx = new KeywordContext(_ctx, getState());
+		enterRule(_localctx, 6, RULE_keyword);
+		int _la;
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(36);
+			_la = _input.LA(1);
+			if ( !((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8))) != 0)) ) {
+			_errHandler.recoverInline(this);
+			}
+			else {
+				if ( _input.LA(1)==Token.EOF ) matchedEOF = true;
+				_errHandler.reportMatch(this);
+				consume();
+			}
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class PunctuatorContext extends ParserRuleContext {
+		public List<TokenContext> token() {
+			return getRuleContexts(TokenContext.class);
+		}
+		public TokenContext token(int i) {
+			return getRuleContext(TokenContext.class,i);
+		}
+		public PunctuatorContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_punctuator; }
+	}
+
+	public final PunctuatorContext punctuator() throws RecognitionException {
+		PunctuatorContext _localctx = new PunctuatorContext(_ctx, getState());
+		enterRule(_localctx, 8, RULE_punctuator);
+		int _la;
+		try {
+			int _alt;
+			setState(74);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__9:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(38);
+				match(T__9);
+				setState(42);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+					{
+					{
+					setState(39);
+					token();
+					}
+					}
+					setState(44);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(45);
+				match(T__10);
+				}
+				break;
+			case T__11:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(46);
+				match(T__11);
+				setState(50);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+					{
+					{
+					setState(47);
+					token();
+					}
+					}
+					setState(52);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(53);
+				match(T__12);
+				}
+				break;
+			case T__13:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(54);
+				match(T__13);
+				setState(58);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__1) | (1L << T__2) | (1L << T__3) | (1L << T__4) | (1L << T__5) | (1L << T__6) | (1L << T__7) | (1L << T__8) | (1L << T__9) | (1L << T__11) | (1L << T__13) | (1L << T__15) | (1L << T__16) | (1L << T__17) | (1L << T__18) | (1L << T__19) | (1L << T__20) | (1L << T__22) | (1L << T__23) | (1L << T__24) | (1L << T__25) | (1L << T__26) | (1L << T__27) | (1L << T__28) | (1L << T__29))) != 0)) {
+					{
+					{
+					setState(55);
+					token();
+					}
+					}
+					setState(60);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(61);
+				match(T__14);
+				}
+				break;
+			case T__15:
+				enterOuterAlt(_localctx, 4);
+				{
+				setState(62);
+				match(T__15);
+				setState(66);
+				_errHandler.sync(this);
+				_alt = getInterpreter().adaptivePredict(_input,5,_ctx);
+				while ( _alt!=2 && _alt!=org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER ) {
+					if ( _alt==1 ) {
+						{
+						{
+						setState(63);
+						token();
+						}
+						} 
+					}
+					setState(68);
+					_errHandler.sync(this);
+					_alt = getInterpreter().adaptivePredict(_input,5,_ctx);
+				}
+				setState(69);
+				match(T__15);
+				}
+				break;
+			case T__16:
+				enterOuterAlt(_localctx, 5);
+				{
+				setState(70);
+				match(T__16);
+				}
+				break;
+			case T__17:
+				enterOuterAlt(_localctx, 6);
+				{
+				setState(71);
+				match(T__17);
+				}
+				break;
+			case T__18:
+				enterOuterAlt(_localctx, 7);
+				{
+				setState(72);
+				match(T__18);
+				}
+				break;
+			case T__19:
+				enterOuterAlt(_localctx, 8);
+				{
+				setState(73);
+				match(T__19);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class IdentifierContext extends ParserRuleContext {
+		public List<DigitContext> digit() {
+			return getRuleContexts(DigitContext.class);
+		}
+		public DigitContext digit(int i) {
+			return getRuleContext(DigitContext.class,i);
+		}
+		public IdentifierContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_identifier; }
+	}
+
+	public final IdentifierContext identifier() throws RecognitionException {
+		IdentifierContext _localctx = new IdentifierContext(_ctx, getState());
+		enterRule(_localctx, 10, RULE_identifier);
+		int _la;
+		try {
+			setState(93);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__20:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(76);
+				match(T__20);
+				setState(80);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(77);
+					digit();
+					}
+					}
+					setState(82);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(83);
+				match(T__21);
+				}
+				break;
+			case T__22:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(84);
+				match(T__22);
+				setState(88);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(85);
+					digit();
+					}
+					}
+					setState(90);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(91);
+				match(T__21);
+				}
+				break;
+			case T__23:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(92);
+				match(T__23);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class OperatorContext extends ParserRuleContext {
+		public List<DigitContext> digit() {
+			return getRuleContexts(DigitContext.class);
+		}
+		public DigitContext digit(int i) {
+			return getRuleContext(DigitContext.class,i);
+		}
+		public OperatorContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_operator; }
+	}
+
+	public final OperatorContext operator() throws RecognitionException {
+		OperatorContext _localctx = new OperatorContext(_ctx, getState());
+		enterRule(_localctx, 12, RULE_operator);
+		int _la;
+		try {
+			setState(112);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__24:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(95);
+				match(T__24);
+				setState(99);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(96);
+					digit();
+					}
+					}
+					setState(101);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(102);
+				match(T__21);
+				}
+				break;
+			case T__25:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(103);
+				match(T__25);
+				setState(107);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(104);
+					digit();
+					}
+					}
+					setState(109);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(110);
+				match(T__21);
+				}
+				break;
+			case T__26:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(111);
+				match(T__26);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class LiteralContext extends ParserRuleContext {
+		public List<DigitContext> digit() {
+			return getRuleContexts(DigitContext.class);
+		}
+		public DigitContext digit(int i) {
+			return getRuleContext(DigitContext.class,i);
+		}
+		public LiteralContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_literal; }
+	}
+
+	public final LiteralContext literal() throws RecognitionException {
+		LiteralContext _localctx = new LiteralContext(_ctx, getState());
+		enterRule(_localctx, 14, RULE_literal);
+		int _la;
+		try {
+			setState(131);
+			_errHandler.sync(this);
+			switch (_input.LA(1)) {
+			case T__27:
+				enterOuterAlt(_localctx, 1);
+				{
+				setState(114);
+				match(T__27);
+				setState(118);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(115);
+					digit();
+					}
+					}
+					setState(120);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(121);
+				match(T__21);
+				}
+				break;
+			case T__28:
+				enterOuterAlt(_localctx, 2);
+				{
+				setState(122);
+				match(T__28);
+				setState(126);
+				_errHandler.sync(this);
+				_la = _input.LA(1);
+				while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) {
+					{
+					{
+					setState(123);
+					digit();
+					}
+					}
+					setState(128);
+					_errHandler.sync(this);
+					_la = _input.LA(1);
+				}
+				setState(129);
+				match(T__21);
+				}
+				break;
+			case T__29:
+				enterOuterAlt(_localctx, 3);
+				{
+				setState(130);
+				match(T__29);
+				}
+				break;
+			default:
+				throw new NoViableAltException(this);
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static class DigitContext extends ParserRuleContext {
+		public DigitContext(ParserRuleContext parent, int invokingState) {
+			super(parent, invokingState);
+		}
+		@Override public int getRuleIndex() { return RULE_digit; }
+	}
+
+	public final DigitContext digit() throws RecognitionException {
+		DigitContext _localctx = new DigitContext(_ctx, getState());
+		enterRule(_localctx, 16, RULE_digit);
+		int _la;
+		try {
+			enterOuterAlt(_localctx, 1);
+			{
+			setState(133);
+			_la = _input.LA(1);
+			if ( !((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << T__30) | (1L << T__31) | (1L << T__32) | (1L << T__33) | (1L << T__34) | (1L << T__35) | (1L << T__36) | (1L << T__37) | (1L << T__38) | (1L << T__39))) != 0)) ) {
+			_errHandler.recoverInline(this);
+			}
+			else {
+				if ( _input.LA(1)==Token.EOF ) matchedEOF = true;
+				_errHandler.reportMatch(this);
+				consume();
+			}
+			}
+		}
+		catch (RecognitionException re) {
+			_localctx.exception = re;
+			_errHandler.reportError(this, re);
+			_errHandler.recover(this, re);
+		}
+		finally {
+			exitRule();
+		}
+		return _localctx;
+	}
+
+	public static final String _serializedATN =
+		"\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3+\u008a\4\2\t\2\4"+
+		"\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7\4\b\t\b\4\t\t\t\4\n\t\n\3\2\3\2"+
+		"\3\2\3\2\3\3\7\3\32\n\3\f\3\16\3\35\13\3\3\4\3\4\3\4\3\4\3\4\3\4\5\4%"+
+		"\n\4\3\5\3\5\3\6\3\6\7\6+\n\6\f\6\16\6.\13\6\3\6\3\6\3\6\7\6\63\n\6\f"+
+		"\6\16\6\66\13\6\3\6\3\6\3\6\7\6;\n\6\f\6\16\6>\13\6\3\6\3\6\3\6\7\6C\n"+
+		"\6\f\6\16\6F\13\6\3\6\3\6\3\6\3\6\3\6\5\6M\n\6\3\7\3\7\7\7Q\n\7\f\7\16"+
+		"\7T\13\7\3\7\3\7\3\7\7\7Y\n\7\f\7\16\7\\\13\7\3\7\3\7\5\7`\n\7\3\b\3\b"+
+		"\7\bd\n\b\f\b\16\bg\13\b\3\b\3\b\3\b\7\bl\n\b\f\b\16\bo\13\b\3\b\3\b\5"+
+		"\bs\n\b\3\t\3\t\7\tw\n\t\f\t\16\tz\13\t\3\t\3\t\3\t\7\t\177\n\t\f\t\16"+
+		"\t\u0082\13\t\3\t\3\t\5\t\u0086\n\t\3\n\3\n\3\n\2\2\13\2\4\6\b\n\f\16"+
+		"\20\22\2\4\3\2\5\13\3\2!*\2\u009d\2\24\3\2\2\2\4\33\3\2\2\2\6$\3\2\2\2"+
+		"\b&\3\2\2\2\nL\3\2\2\2\f_\3\2\2\2\16r\3\2\2\2\20\u0085\3\2\2\2\22\u0087"+
+		"\3\2\2\2\24\25\5\4\3\2\25\26\7\3\2\2\26\27\5\4\3\2\27\3\3\2\2\2\30\32"+
+		"\5\6\4\2\31\30\3\2\2\2\32\35\3\2\2\2\33\31\3\2\2\2\33\34\3\2\2\2\34\5"+
+		"\3\2\2\2\35\33\3\2\2\2\36%\5\f\7\2\37%\5\b\5\2 %\5\n\6\2!%\5\16\b\2\""+
+		"%\5\20\t\2#%\7\4\2\2$\36\3\2\2\2$\37\3\2\2\2$ \3\2\2\2$!\3\2\2\2$\"\3"+
+		"\2\2\2$#\3\2\2\2%\7\3\2\2\2&\'\t\2\2\2\'\t\3\2\2\2(,\7\f\2\2)+\5\6\4\2"+
+		"*)\3\2\2\2+.\3\2\2\2,*\3\2\2\2,-\3\2\2\2-/\3\2\2\2.,\3\2\2\2/M\7\r\2\2"+
+		"\60\64\7\16\2\2\61\63\5\6\4\2\62\61\3\2\2\2\63\66\3\2\2\2\64\62\3\2\2"+
+		"\2\64\65\3\2\2\2\65\67\3\2\2\2\66\64\3\2\2\2\67M\7\17\2\28<\7\20\2\29"+
+		";\5\6\4\2:9\3\2\2\2;>\3\2\2\2<:\3\2\2\2<=\3\2\2\2=?\3\2\2\2><\3\2\2\2"+
+		"?M\7\21\2\2@D\7\22\2\2AC\5\6\4\2BA\3\2\2\2CF\3\2\2\2DB\3\2\2\2DE\3\2\2"+
+		"\2EG\3\2\2\2FD\3\2\2\2GM\7\22\2\2HM\7\23\2\2IM\7\24\2\2JM\7\25\2\2KM\7"+
+		"\26\2\2L(\3\2\2\2L\60\3\2\2\2L8\3\2\2\2L@\3\2\2\2LH\3\2\2\2LI\3\2\2\2"+
+		"LJ\3\2\2\2LK\3\2\2\2M\13\3\2\2\2NR\7\27\2\2OQ\5\22\n\2PO\3\2\2\2QT\3\2"+
+		"\2\2RP\3\2\2\2RS\3\2\2\2SU\3\2\2\2TR\3\2\2\2U`\7\30\2\2VZ\7\31\2\2WY\5"+
+		"\22\n\2XW\3\2\2\2Y\\\3\2\2\2ZX\3\2\2\2Z[\3\2\2\2[]\3\2\2\2\\Z\3\2\2\2"+
+		"]`\7\30\2\2^`\7\32\2\2_N\3\2\2\2_V\3\2\2\2_^\3\2\2\2`\r\3\2\2\2ae\7\33"+
+		"\2\2bd\5\22\n\2cb\3\2\2\2dg\3\2\2\2ec\3\2\2\2ef\3\2\2\2fh\3\2\2\2ge\3"+
+		"\2\2\2hs\7\30\2\2im\7\34\2\2jl\5\22\n\2kj\3\2\2\2lo\3\2\2\2mk\3\2\2\2"+
+		"mn\3\2\2\2np\3\2\2\2om\3\2\2\2ps\7\30\2\2qs\7\35\2\2ra\3\2\2\2ri\3\2\2"+
+		"\2rq\3\2\2\2s\17\3\2\2\2tx\7\36\2\2uw\5\22\n\2vu\3\2\2\2wz\3\2\2\2xv\3"+
+		"\2\2\2xy\3\2\2\2y{\3\2\2\2zx\3\2\2\2{\u0086\7\30\2\2|\u0080\7\37\2\2}"+
+		"\177\5\22\n\2~}\3\2\2\2\177\u0082\3\2\2\2\u0080~\3\2\2\2\u0080\u0081\3"+
+		"\2\2\2\u0081\u0083\3\2\2\2\u0082\u0080\3\2\2\2\u0083\u0086\7\30\2\2\u0084"+
+		"\u0086\7 \2\2\u0085t\3\2\2\2\u0085|\3\2\2\2\u0085\u0084\3\2\2\2\u0086"+
+		"\21\3\2\2\2\u0087\u0088\t\3\2\2\u0088\23\3\2\2\2\22\33$,\64<DLRZ_emrx"+
+		"\u0080\u0085";
+	public static final ATN _ATN =
+		new ATNDeserializer().deserialize(_serializedATN.toCharArray());
+	static {
+		_decisionToDFA = new DFA[_ATN.getNumberOfDecisions()];
+		for (int i = 0; i < _ATN.getNumberOfDecisions(); i++) {
+			_decisionToDFA[i] = new DFA(_ATN.getDecisionState(i), i);
+		}
+	}
+}
\ No newline at end of file
diff --git a/code/antlr4/Search.g4 b/code/antlr4/Search.g4
index 1f7fd42..dfdb50c 100644
--- a/code/antlr4/Search.g4
+++ b/code/antlr4/Search.g4
@@ -1,58 +1,22 @@
 grammar Search;
 
-query: expr '->' expr;
-
-expr: token*;
-
-token: identifier 
-	| keyword 
-	| punctuator 
-	| op
-	| '_';
-
-identifier: '#ID<' digit* '>' | '#N<' digit* '>' | '#ID<.>' | '#N<.>' ;
-
-digit:  '0'
-	|'1'
-	|'2'
-	|'3'
-	|'4'
-	|'5'
-	|'6'
-	|'7'
-	|'8'
-	|'9';
-
-keyword: 'if' 
-	| 'else' 
-	| 'for' 
-	| 'forEach' 
-	| 'while' 
-	| 'return' 
-	| 'NULL';
-
-punctuator: '('token*')'
-	| '['token*']'
-	| '{'token*'}'
-	| '"'token*'"'
-	| '='
-	| '.'
-	| ','
-	| ';';
-
-op:     '+' 
-	| '−' 
-	| '*' 
-	| '/'
-	| '==' 
-	| '<' 
-	| '>' 
-	| '<='
-	| '>='
-	| '==' 
-	| '!=' 
-	| '&&'
-	| '||'
-	| '#OP<' digit* '>' ;
-
-WS:     [ \t\r\n]+ -> skip ;
+query: code '->' code;
+
+code: token*;
+
+token: identifier | keyword | punctuator | operator| literal| '_';
+
+keyword: 'if' | 'else' | 'for' | 'forEach' | 'while' | 'return' | 'NULL';
+
+punctuator: '('token*')' | '['token*']' | '{'token*'}'| '"'token*'"'| '='| '.'| ',' | ';';
+
+identifier: '#ID<' digit* '>' | '#ID<!' digit* '>' | '#ID<.>';
+
+operator: '#OP<' digit* '>' | '#OP<!' digit* '>' | '#OP<.>';
+
+literal: '#LT<' digit* '>' | '#LT<!' digit* '>' | '#LT<.>';
+
+digit:  '0' | '1' | '2' | '3' | '4' | '5' | '6' |'7' | '8' | '9';
+
+
+WS:     [ \t\r\n]+ -> skip ;
\ No newline at end of file
diff --git a/code/antlr4/SearchLexer.py b/code/antlr4/SearchLexer.py
index d1ff21d..440f5f6 100644
--- a/code/antlr4/SearchLexer.py
+++ b/code/antlr4/SearchLexer.py
@@ -7,101 +7,94 @@ import sys
 
 def serializedATN():
     with StringIO() as buf:
-        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2\62")
-        buf.write("\u00f8\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
+        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2+")
+        buf.write("\u00e9\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
         buf.write("\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r")
         buf.write("\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23")
         buf.write("\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30")
         buf.write("\4\31\t\31\4\32\t\32\4\33\t\33\4\34\t\34\4\35\t\35\4\36")
         buf.write("\t\36\4\37\t\37\4 \t \4!\t!\4\"\t\"\4#\t#\4$\t$\4%\t%")
-        buf.write("\4&\t&\4\'\t\'\4(\t(\4)\t)\4*\t*\4+\t+\4,\t,\4-\t-\4.")
-        buf.write("\t.\4/\t/\4\60\t\60\4\61\t\61\3\2\3\2\3\2\3\3\3\3\3\4")
-        buf.write("\3\4\3\4\3\4\3\4\3\5\3\5\3\6\3\6\3\6\3\6\3\7\3\7\3\7\3")
-        buf.write("\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\t\3\t\3\n\3\n")
-        buf.write("\3\13\3\13\3\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17\3\20\3")
-        buf.write("\20\3\21\3\21\3\22\3\22\3\23\3\23\3\23\3\24\3\24\3\24")
-        buf.write("\3\24\3\24\3\25\3\25\3\25\3\25\3\26\3\26\3\26\3\26\3\26")
-        buf.write("\3\26\3\26\3\26\3\27\3\27\3\27\3\27\3\27\3\27\3\30\3\30")
-        buf.write("\3\30\3\30\3\30\3\30\3\30\3\31\3\31\3\31\3\31\3\31\3\32")
-        buf.write("\3\32\3\33\3\33\3\34\3\34\3\35\3\35\3\36\3\36\3\37\3\37")
-        buf.write("\3 \3 \3!\3!\3\"\3\"\3#\3#\3$\3$\3%\3%\3&\3&\3\'\3\'\3")
-        buf.write("(\3(\3)\3)\3)\3*\3*\3+\3+\3+\3,\3,\3,\3-\3-\3-\3.\3.\3")
-        buf.write(".\3/\3/\3/\3\60\3\60\3\60\3\60\3\60\3\61\6\61\u00f3\n")
-        buf.write("\61\r\61\16\61\u00f4\3\61\3\61\2\2\62\3\3\5\4\7\5\t\6")
-        buf.write("\13\7\r\b\17\t\21\n\23\13\25\f\27\r\31\16\33\17\35\20")
-        buf.write("\37\21!\22#\23%\24\'\25)\26+\27-\30/\31\61\32\63\33\65")
-        buf.write("\34\67\359\36;\37= ?!A\"C#E$G%I&K\'M(O)Q*S+U,W-Y.[/]\60")
-        buf.write("_\61a\62\3\2\3\5\2\13\f\17\17\"\"\2\u00f8\2\3\3\2\2\2")
-        buf.write("\2\5\3\2\2\2\2\7\3\2\2\2\2\t\3\2\2\2\2\13\3\2\2\2\2\r")
-        buf.write("\3\2\2\2\2\17\3\2\2\2\2\21\3\2\2\2\2\23\3\2\2\2\2\25\3")
-        buf.write("\2\2\2\2\27\3\2\2\2\2\31\3\2\2\2\2\33\3\2\2\2\2\35\3\2")
-        buf.write("\2\2\2\37\3\2\2\2\2!\3\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2\'")
-        buf.write("\3\2\2\2\2)\3\2\2\2\2+\3\2\2\2\2-\3\2\2\2\2/\3\2\2\2\2")
-        buf.write("\61\3\2\2\2\2\63\3\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\29")
-        buf.write("\3\2\2\2\2;\3\2\2\2\2=\3\2\2\2\2?\3\2\2\2\2A\3\2\2\2\2")
-        buf.write("C\3\2\2\2\2E\3\2\2\2\2G\3\2\2\2\2I\3\2\2\2\2K\3\2\2\2")
-        buf.write("\2M\3\2\2\2\2O\3\2\2\2\2Q\3\2\2\2\2S\3\2\2\2\2U\3\2\2")
-        buf.write("\2\2W\3\2\2\2\2Y\3\2\2\2\2[\3\2\2\2\2]\3\2\2\2\2_\3\2")
-        buf.write("\2\2\2a\3\2\2\2\3c\3\2\2\2\5f\3\2\2\2\7h\3\2\2\2\tm\3")
-        buf.write("\2\2\2\13o\3\2\2\2\rs\3\2\2\2\17z\3\2\2\2\21\u0080\3\2")
-        buf.write("\2\2\23\u0082\3\2\2\2\25\u0084\3\2\2\2\27\u0086\3\2\2")
-        buf.write("\2\31\u0088\3\2\2\2\33\u008a\3\2\2\2\35\u008c\3\2\2\2")
-        buf.write("\37\u008e\3\2\2\2!\u0090\3\2\2\2#\u0092\3\2\2\2%\u0094")
-        buf.write("\3\2\2\2\'\u0097\3\2\2\2)\u009c\3\2\2\2+\u00a0\3\2\2\2")
-        buf.write("-\u00a8\3\2\2\2/\u00ae\3\2\2\2\61\u00b5\3\2\2\2\63\u00ba")
-        buf.write("\3\2\2\2\65\u00bc\3\2\2\2\67\u00be\3\2\2\29\u00c0\3\2")
-        buf.write("\2\2;\u00c2\3\2\2\2=\u00c4\3\2\2\2?\u00c6\3\2\2\2A\u00c8")
-        buf.write("\3\2\2\2C\u00ca\3\2\2\2E\u00cc\3\2\2\2G\u00ce\3\2\2\2")
-        buf.write("I\u00d0\3\2\2\2K\u00d2\3\2\2\2M\u00d4\3\2\2\2O\u00d6\3")
-        buf.write("\2\2\2Q\u00d8\3\2\2\2S\u00db\3\2\2\2U\u00dd\3\2\2\2W\u00e0")
-        buf.write("\3\2\2\2Y\u00e3\3\2\2\2[\u00e6\3\2\2\2]\u00e9\3\2\2\2")
-        buf.write("_\u00ec\3\2\2\2a\u00f2\3\2\2\2cd\7/\2\2de\7@\2\2e\4\3")
-        buf.write("\2\2\2fg\7a\2\2g\6\3\2\2\2hi\7%\2\2ij\7K\2\2jk\7F\2\2")
-        buf.write("kl\7>\2\2l\b\3\2\2\2mn\7@\2\2n\n\3\2\2\2op\7%\2\2pq\7")
-        buf.write("P\2\2qr\7>\2\2r\f\3\2\2\2st\7%\2\2tu\7K\2\2uv\7F\2\2v")
-        buf.write("w\7>\2\2wx\7\60\2\2xy\7@\2\2y\16\3\2\2\2z{\7%\2\2{|\7")
-        buf.write("P\2\2|}\7>\2\2}~\7\60\2\2~\177\7@\2\2\177\20\3\2\2\2\u0080")
-        buf.write("\u0081\7\62\2\2\u0081\22\3\2\2\2\u0082\u0083\7\63\2\2")
-        buf.write("\u0083\24\3\2\2\2\u0084\u0085\7\64\2\2\u0085\26\3\2\2")
-        buf.write("\2\u0086\u0087\7\65\2\2\u0087\30\3\2\2\2\u0088\u0089\7")
-        buf.write("\66\2\2\u0089\32\3\2\2\2\u008a\u008b\7\67\2\2\u008b\34")
-        buf.write("\3\2\2\2\u008c\u008d\78\2\2\u008d\36\3\2\2\2\u008e\u008f")
-        buf.write("\79\2\2\u008f \3\2\2\2\u0090\u0091\7:\2\2\u0091\"\3\2")
-        buf.write("\2\2\u0092\u0093\7;\2\2\u0093$\3\2\2\2\u0094\u0095\7k")
-        buf.write("\2\2\u0095\u0096\7h\2\2\u0096&\3\2\2\2\u0097\u0098\7g")
-        buf.write("\2\2\u0098\u0099\7n\2\2\u0099\u009a\7u\2\2\u009a\u009b")
-        buf.write("\7g\2\2\u009b(\3\2\2\2\u009c\u009d\7h\2\2\u009d\u009e")
-        buf.write("\7q\2\2\u009e\u009f\7t\2\2\u009f*\3\2\2\2\u00a0\u00a1")
-        buf.write("\7h\2\2\u00a1\u00a2\7q\2\2\u00a2\u00a3\7t\2\2\u00a3\u00a4")
-        buf.write("\7G\2\2\u00a4\u00a5\7c\2\2\u00a5\u00a6\7e\2\2\u00a6\u00a7")
-        buf.write("\7j\2\2\u00a7,\3\2\2\2\u00a8\u00a9\7y\2\2\u00a9\u00aa")
-        buf.write("\7j\2\2\u00aa\u00ab\7k\2\2\u00ab\u00ac\7n\2\2\u00ac\u00ad")
-        buf.write("\7g\2\2\u00ad.\3\2\2\2\u00ae\u00af\7t\2\2\u00af\u00b0")
-        buf.write("\7g\2\2\u00b0\u00b1\7v\2\2\u00b1\u00b2\7w\2\2\u00b2\u00b3")
-        buf.write("\7t\2\2\u00b3\u00b4\7p\2\2\u00b4\60\3\2\2\2\u00b5\u00b6")
-        buf.write("\7P\2\2\u00b6\u00b7\7W\2\2\u00b7\u00b8\7N\2\2\u00b8\u00b9")
-        buf.write("\7N\2\2\u00b9\62\3\2\2\2\u00ba\u00bb\7*\2\2\u00bb\64\3")
-        buf.write("\2\2\2\u00bc\u00bd\7+\2\2\u00bd\66\3\2\2\2\u00be\u00bf")
-        buf.write("\7]\2\2\u00bf8\3\2\2\2\u00c0\u00c1\7_\2\2\u00c1:\3\2\2")
-        buf.write("\2\u00c2\u00c3\7}\2\2\u00c3<\3\2\2\2\u00c4\u00c5\7\177")
-        buf.write("\2\2\u00c5>\3\2\2\2\u00c6\u00c7\7$\2\2\u00c7@\3\2\2\2")
-        buf.write("\u00c8\u00c9\7?\2\2\u00c9B\3\2\2\2\u00ca\u00cb\7\60\2")
-        buf.write("\2\u00cbD\3\2\2\2\u00cc\u00cd\7.\2\2\u00cdF\3\2\2\2\u00ce")
-        buf.write("\u00cf\7=\2\2\u00cfH\3\2\2\2\u00d0\u00d1\7-\2\2\u00d1")
-        buf.write("J\3\2\2\2\u00d2\u00d3\7\u2214\2\2\u00d3L\3\2\2\2\u00d4")
-        buf.write("\u00d5\7,\2\2\u00d5N\3\2\2\2\u00d6\u00d7\7\61\2\2\u00d7")
-        buf.write("P\3\2\2\2\u00d8\u00d9\7?\2\2\u00d9\u00da\7?\2\2\u00da")
-        buf.write("R\3\2\2\2\u00db\u00dc\7>\2\2\u00dcT\3\2\2\2\u00dd\u00de")
-        buf.write("\7>\2\2\u00de\u00df\7?\2\2\u00dfV\3\2\2\2\u00e0\u00e1")
-        buf.write("\7@\2\2\u00e1\u00e2\7?\2\2\u00e2X\3\2\2\2\u00e3\u00e4")
-        buf.write("\7#\2\2\u00e4\u00e5\7?\2\2\u00e5Z\3\2\2\2\u00e6\u00e7")
-        buf.write("\7(\2\2\u00e7\u00e8\7(\2\2\u00e8\\\3\2\2\2\u00e9\u00ea")
-        buf.write("\7~\2\2\u00ea\u00eb\7~\2\2\u00eb^\3\2\2\2\u00ec\u00ed")
-        buf.write("\7%\2\2\u00ed\u00ee\7Q\2\2\u00ee\u00ef\7R\2\2\u00ef\u00f0")
-        buf.write("\7>\2\2\u00f0`\3\2\2\2\u00f1\u00f3\t\2\2\2\u00f2\u00f1")
-        buf.write("\3\2\2\2\u00f3\u00f4\3\2\2\2\u00f4\u00f2\3\2\2\2\u00f4")
-        buf.write("\u00f5\3\2\2\2\u00f5\u00f6\3\2\2\2\u00f6\u00f7\b\61\2")
-        buf.write("\2\u00f7b\3\2\2\2\4\2\u00f4\3\b\2\2")
+        buf.write("\4&\t&\4\'\t\'\4(\t(\4)\t)\4*\t*\3\2\3\2\3\2\3\3\3\3\3")
+        buf.write("\4\3\4\3\4\3\5\3\5\3\5\3\5\3\5\3\6\3\6\3\6\3\6\3\7\3\7")
+        buf.write("\3\7\3\7\3\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\t\3")
+        buf.write("\t\3\t\3\t\3\t\3\t\3\t\3\n\3\n\3\n\3\n\3\n\3\13\3\13\3")
+        buf.write("\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17\3\20\3\20\3\21\3\21")
+        buf.write("\3\22\3\22\3\23\3\23\3\24\3\24\3\25\3\25\3\26\3\26\3\26")
+        buf.write("\3\26\3\26\3\27\3\27\3\30\3\30\3\30\3\30\3\30\3\30\3\31")
+        buf.write("\3\31\3\31\3\31\3\31\3\31\3\31\3\32\3\32\3\32\3\32\3\32")
+        buf.write("\3\33\3\33\3\33\3\33\3\33\3\33\3\34\3\34\3\34\3\34\3\34")
+        buf.write("\3\34\3\34\3\35\3\35\3\35\3\35\3\35\3\36\3\36\3\36\3\36")
+        buf.write("\3\36\3\36\3\37\3\37\3\37\3\37\3\37\3\37\3\37\3 \3 \3")
+        buf.write("!\3!\3\"\3\"\3#\3#\3$\3$\3%\3%\3&\3&\3\'\3\'\3(\3(\3)")
+        buf.write("\3)\3*\6*\u00e4\n*\r*\16*\u00e5\3*\3*\2\2+\3\3\5\4\7\5")
+        buf.write("\t\6\13\7\r\b\17\t\21\n\23\13\25\f\27\r\31\16\33\17\35")
+        buf.write("\20\37\21!\22#\23%\24\'\25)\26+\27-\30/\31\61\32\63\33")
+        buf.write("\65\34\67\359\36;\37= ?!A\"C#E$G%I&K\'M(O)Q*S+\3\2\3\5")
+        buf.write("\2\13\f\17\17\"\"\2\u00e9\2\3\3\2\2\2\2\5\3\2\2\2\2\7")
+        buf.write("\3\2\2\2\2\t\3\2\2\2\2\13\3\2\2\2\2\r\3\2\2\2\2\17\3\2")
+        buf.write("\2\2\2\21\3\2\2\2\2\23\3\2\2\2\2\25\3\2\2\2\2\27\3\2\2")
+        buf.write("\2\2\31\3\2\2\2\2\33\3\2\2\2\2\35\3\2\2\2\2\37\3\2\2\2")
+        buf.write("\2!\3\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2\'\3\2\2\2\2)\3\2\2")
+        buf.write("\2\2+\3\2\2\2\2-\3\2\2\2\2/\3\2\2\2\2\61\3\2\2\2\2\63")
+        buf.write("\3\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\29\3\2\2\2\2;\3\2\2")
+        buf.write("\2\2=\3\2\2\2\2?\3\2\2\2\2A\3\2\2\2\2C\3\2\2\2\2E\3\2")
+        buf.write("\2\2\2G\3\2\2\2\2I\3\2\2\2\2K\3\2\2\2\2M\3\2\2\2\2O\3")
+        buf.write("\2\2\2\2Q\3\2\2\2\2S\3\2\2\2\3U\3\2\2\2\5X\3\2\2\2\7Z")
+        buf.write("\3\2\2\2\t]\3\2\2\2\13b\3\2\2\2\rf\3\2\2\2\17n\3\2\2\2")
+        buf.write("\21t\3\2\2\2\23{\3\2\2\2\25\u0080\3\2\2\2\27\u0082\3\2")
+        buf.write("\2\2\31\u0084\3\2\2\2\33\u0086\3\2\2\2\35\u0088\3\2\2")
+        buf.write("\2\37\u008a\3\2\2\2!\u008c\3\2\2\2#\u008e\3\2\2\2%\u0090")
+        buf.write("\3\2\2\2\'\u0092\3\2\2\2)\u0094\3\2\2\2+\u0096\3\2\2\2")
+        buf.write("-\u009b\3\2\2\2/\u009d\3\2\2\2\61\u00a3\3\2\2\2\63\u00aa")
+        buf.write("\3\2\2\2\65\u00af\3\2\2\2\67\u00b5\3\2\2\29\u00bc\3\2")
+        buf.write("\2\2;\u00c1\3\2\2\2=\u00c7\3\2\2\2?\u00ce\3\2\2\2A\u00d0")
+        buf.write("\3\2\2\2C\u00d2\3\2\2\2E\u00d4\3\2\2\2G\u00d6\3\2\2\2")
+        buf.write("I\u00d8\3\2\2\2K\u00da\3\2\2\2M\u00dc\3\2\2\2O\u00de\3")
+        buf.write("\2\2\2Q\u00e0\3\2\2\2S\u00e3\3\2\2\2UV\7/\2\2VW\7@\2\2")
+        buf.write("W\4\3\2\2\2XY\7a\2\2Y\6\3\2\2\2Z[\7k\2\2[\\\7h\2\2\\\b")
+        buf.write("\3\2\2\2]^\7g\2\2^_\7n\2\2_`\7u\2\2`a\7g\2\2a\n\3\2\2")
+        buf.write("\2bc\7h\2\2cd\7q\2\2de\7t\2\2e\f\3\2\2\2fg\7h\2\2gh\7")
+        buf.write("q\2\2hi\7t\2\2ij\7G\2\2jk\7c\2\2kl\7e\2\2lm\7j\2\2m\16")
+        buf.write("\3\2\2\2no\7y\2\2op\7j\2\2pq\7k\2\2qr\7n\2\2rs\7g\2\2")
+        buf.write("s\20\3\2\2\2tu\7t\2\2uv\7g\2\2vw\7v\2\2wx\7w\2\2xy\7t")
+        buf.write("\2\2yz\7p\2\2z\22\3\2\2\2{|\7P\2\2|}\7W\2\2}~\7N\2\2~")
+        buf.write("\177\7N\2\2\177\24\3\2\2\2\u0080\u0081\7*\2\2\u0081\26")
+        buf.write("\3\2\2\2\u0082\u0083\7+\2\2\u0083\30\3\2\2\2\u0084\u0085")
+        buf.write("\7]\2\2\u0085\32\3\2\2\2\u0086\u0087\7_\2\2\u0087\34\3")
+        buf.write("\2\2\2\u0088\u0089\7}\2\2\u0089\36\3\2\2\2\u008a\u008b")
+        buf.write("\7\177\2\2\u008b \3\2\2\2\u008c\u008d\7$\2\2\u008d\"\3")
+        buf.write("\2\2\2\u008e\u008f\7?\2\2\u008f$\3\2\2\2\u0090\u0091\7")
+        buf.write("\60\2\2\u0091&\3\2\2\2\u0092\u0093\7.\2\2\u0093(\3\2\2")
+        buf.write("\2\u0094\u0095\7=\2\2\u0095*\3\2\2\2\u0096\u0097\7%\2")
+        buf.write("\2\u0097\u0098\7K\2\2\u0098\u0099\7F\2\2\u0099\u009a\7")
+        buf.write(">\2\2\u009a,\3\2\2\2\u009b\u009c\7@\2\2\u009c.\3\2\2\2")
+        buf.write("\u009d\u009e\7%\2\2\u009e\u009f\7K\2\2\u009f\u00a0\7F")
+        buf.write("\2\2\u00a0\u00a1\7>\2\2\u00a1\u00a2\7#\2\2\u00a2\60\3")
+        buf.write("\2\2\2\u00a3\u00a4\7%\2\2\u00a4\u00a5\7K\2\2\u00a5\u00a6")
+        buf.write("\7F\2\2\u00a6\u00a7\7>\2\2\u00a7\u00a8\7\60\2\2\u00a8")
+        buf.write("\u00a9\7@\2\2\u00a9\62\3\2\2\2\u00aa\u00ab\7%\2\2\u00ab")
+        buf.write("\u00ac\7Q\2\2\u00ac\u00ad\7R\2\2\u00ad\u00ae\7>\2\2\u00ae")
+        buf.write("\64\3\2\2\2\u00af\u00b0\7%\2\2\u00b0\u00b1\7Q\2\2\u00b1")
+        buf.write("\u00b2\7R\2\2\u00b2\u00b3\7>\2\2\u00b3\u00b4\7#\2\2\u00b4")
+        buf.write("\66\3\2\2\2\u00b5\u00b6\7%\2\2\u00b6\u00b7\7Q\2\2\u00b7")
+        buf.write("\u00b8\7R\2\2\u00b8\u00b9\7>\2\2\u00b9\u00ba\7\60\2\2")
+        buf.write("\u00ba\u00bb\7@\2\2\u00bb8\3\2\2\2\u00bc\u00bd\7%\2\2")
+        buf.write("\u00bd\u00be\7N\2\2\u00be\u00bf\7V\2\2\u00bf\u00c0\7>")
+        buf.write("\2\2\u00c0:\3\2\2\2\u00c1\u00c2\7%\2\2\u00c2\u00c3\7N")
+        buf.write("\2\2\u00c3\u00c4\7V\2\2\u00c4\u00c5\7>\2\2\u00c5\u00c6")
+        buf.write("\7#\2\2\u00c6<\3\2\2\2\u00c7\u00c8\7%\2\2\u00c8\u00c9")
+        buf.write("\7N\2\2\u00c9\u00ca\7V\2\2\u00ca\u00cb\7>\2\2\u00cb\u00cc")
+        buf.write("\7\60\2\2\u00cc\u00cd\7@\2\2\u00cd>\3\2\2\2\u00ce\u00cf")
+        buf.write("\7\62\2\2\u00cf@\3\2\2\2\u00d0\u00d1\7\63\2\2\u00d1B\3")
+        buf.write("\2\2\2\u00d2\u00d3\7\64\2\2\u00d3D\3\2\2\2\u00d4\u00d5")
+        buf.write("\7\65\2\2\u00d5F\3\2\2\2\u00d6\u00d7\7\66\2\2\u00d7H\3")
+        buf.write("\2\2\2\u00d8\u00d9\7\67\2\2\u00d9J\3\2\2\2\u00da\u00db")
+        buf.write("\78\2\2\u00dbL\3\2\2\2\u00dc\u00dd\79\2\2\u00ddN\3\2\2")
+        buf.write("\2\u00de\u00df\7:\2\2\u00dfP\3\2\2\2\u00e0\u00e1\7;\2")
+        buf.write("\2\u00e1R\3\2\2\2\u00e2\u00e4\t\2\2\2\u00e3\u00e2\3\2")
+        buf.write("\2\2\u00e4\u00e5\3\2\2\2\u00e5\u00e3\3\2\2\2\u00e5\u00e6")
+        buf.write("\3\2\2\2\u00e6\u00e7\3\2\2\2\u00e7\u00e8\b*\2\2\u00e8")
+        buf.write("T\3\2\2\2\4\2\u00e5\3\b\2\2")
         return buf.getvalue()
 
 
@@ -151,26 +144,19 @@ class SearchLexer(Lexer):
     T__37 = 38
     T__38 = 39
     T__39 = 40
-    T__40 = 41
-    T__41 = 42
-    T__42 = 43
-    T__43 = 44
-    T__44 = 45
-    T__45 = 46
-    T__46 = 47
-    WS = 48
+    WS = 41
 
     channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]
 
     modeNames = [ "DEFAULT_MODE" ]
 
     literalNames = [ "<INVALID>",
-            "'->'", "'_'", "'#ID<'", "'>'", "'#N<'", "'#ID<.>'", "'#N<.>'", 
-            "'0'", "'1'", "'2'", "'3'", "'4'", "'5'", "'6'", "'7'", "'8'", 
-            "'9'", "'if'", "'else'", "'for'", "'forEach'", "'while'", "'return'", 
-            "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", 
-            "'='", "'.'", "','", "';'", "'+'", "'\u2212'", "'*'", "'/'", 
-            "'=='", "'<'", "'<='", "'>='", "'!='", "'&&'", "'||'", "'#OP<'" ]
+            "'->'", "'_'", "'if'", "'else'", "'for'", "'forEach'", "'while'", 
+            "'return'", "'NULL'", "'('", "')'", "'['", "']'", "'{'", "'}'", 
+            "'\"'", "'='", "'.'", "','", "';'", "'#ID<'", "'>'", "'#ID<!'", 
+            "'#ID<.>'", "'#OP<'", "'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", 
+            "'#LT<.>'", "'0'", "'1'", "'2'", "'3'", "'4'", "'5'", "'6'", 
+            "'7'", "'8'", "'9'" ]
 
     symbolicNames = [ "<INVALID>",
             "WS" ]
@@ -181,8 +167,7 @@ class SearchLexer(Lexer):
                   "T__20", "T__21", "T__22", "T__23", "T__24", "T__25", 
                   "T__26", "T__27", "T__28", "T__29", "T__30", "T__31", 
                   "T__32", "T__33", "T__34", "T__35", "T__36", "T__37", 
-                  "T__38", "T__39", "T__40", "T__41", "T__42", "T__43", 
-                  "T__44", "T__45", "T__46", "WS" ]
+                  "T__38", "T__39", "WS" ]
 
     grammarFileName = "Search.g4"
 
diff --git a/code/antlr4/SearchListener.py b/code/antlr4/SearchListener.py
index 1879435..41f83c2 100644
--- a/code/antlr4/SearchListener.py
+++ b/code/antlr4/SearchListener.py
@@ -17,12 +17,12 @@ class SearchListener(ParseTreeListener):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#expr.
-    def enterExpr(self, ctx:SearchParser.ExprContext):
+    # Enter a parse tree produced by SearchParser#code.
+    def enterCode(self, ctx:SearchParser.CodeContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#expr.
-    def exitExpr(self, ctx:SearchParser.ExprContext):
+    # Exit a parse tree produced by SearchParser#code.
+    def exitCode(self, ctx:SearchParser.CodeContext):
         pass
 
 
@@ -35,48 +35,57 @@ class SearchListener(ParseTreeListener):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#identifier.
-    def enterIdentifier(self, ctx:SearchParser.IdentifierContext):
+    # Enter a parse tree produced by SearchParser#keyword.
+    def enterKeyword(self, ctx:SearchParser.KeywordContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#identifier.
-    def exitIdentifier(self, ctx:SearchParser.IdentifierContext):
+    # Exit a parse tree produced by SearchParser#keyword.
+    def exitKeyword(self, ctx:SearchParser.KeywordContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#digit.
-    def enterDigit(self, ctx:SearchParser.DigitContext):
+    # Enter a parse tree produced by SearchParser#punctuator.
+    def enterPunctuator(self, ctx:SearchParser.PunctuatorContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#digit.
-    def exitDigit(self, ctx:SearchParser.DigitContext):
+    # Exit a parse tree produced by SearchParser#punctuator.
+    def exitPunctuator(self, ctx:SearchParser.PunctuatorContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#keyword.
-    def enterKeyword(self, ctx:SearchParser.KeywordContext):
+    # Enter a parse tree produced by SearchParser#identifier.
+    def enterIdentifier(self, ctx:SearchParser.IdentifierContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#keyword.
-    def exitKeyword(self, ctx:SearchParser.KeywordContext):
+    # Exit a parse tree produced by SearchParser#identifier.
+    def exitIdentifier(self, ctx:SearchParser.IdentifierContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#punctuator.
-    def enterPunctuator(self, ctx:SearchParser.PunctuatorContext):
+    # Enter a parse tree produced by SearchParser#operator.
+    def enterOperator(self, ctx:SearchParser.OperatorContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#punctuator.
-    def exitPunctuator(self, ctx:SearchParser.PunctuatorContext):
+    # Exit a parse tree produced by SearchParser#operator.
+    def exitOperator(self, ctx:SearchParser.OperatorContext):
         pass
 
 
-    # Enter a parse tree produced by SearchParser#op.
-    def enterOp(self, ctx:SearchParser.OpContext):
+    # Enter a parse tree produced by SearchParser#literal.
+    def enterLiteral(self, ctx:SearchParser.LiteralContext):
         pass
 
-    # Exit a parse tree produced by SearchParser#op.
-    def exitOp(self, ctx:SearchParser.OpContext):
+    # Exit a parse tree produced by SearchParser#literal.
+    def exitLiteral(self, ctx:SearchParser.LiteralContext):
+        pass
+
+
+    # Enter a parse tree produced by SearchParser#digit.
+    def enterDigit(self, ctx:SearchParser.DigitContext):
+        pass
+
+    # Exit a parse tree produced by SearchParser#digit.
+    def exitDigit(self, ctx:SearchParser.DigitContext):
         pass
 
 
diff --git a/code/antlr4/SearchParser.py b/code/antlr4/SearchParser.py
index 64b4fa5..800cb84 100644
--- a/code/antlr4/SearchParser.py
+++ b/code/antlr4/SearchParser.py
@@ -7,48 +7,54 @@ import sys
 
 def serializedATN():
     with StringIO() as buf:
-        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3\62")
-        buf.write("y\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7\4\b")
-        buf.write("\t\b\4\t\t\t\3\2\3\2\3\2\3\2\3\3\7\3\30\n\3\f\3\16\3\33")
-        buf.write("\13\3\3\4\3\4\3\4\3\4\3\4\5\4\"\n\4\3\5\3\5\7\5&\n\5\f")
-        buf.write("\5\16\5)\13\5\3\5\3\5\3\5\7\5.\n\5\f\5\16\5\61\13\5\3")
-        buf.write("\5\3\5\3\5\5\5\66\n\5\3\6\3\6\3\7\3\7\3\b\3\b\7\b>\n\b")
-        buf.write("\f\b\16\bA\13\b\3\b\3\b\3\b\7\bF\n\b\f\b\16\bI\13\b\3")
-        buf.write("\b\3\b\3\b\7\bN\n\b\f\b\16\bQ\13\b\3\b\3\b\3\b\7\bV\n")
-        buf.write("\b\f\b\16\bY\13\b\3\b\3\b\3\b\3\b\3\b\5\b`\n\b\3\t\3\t")
-        buf.write("\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\3\t\7")
-        buf.write("\tq\n\t\f\t\16\tt\13\t\3\t\5\tw\n\t\3\t\2\2\n\2\4\6\b")
-        buf.write("\n\f\16\20\2\4\3\2\n\23\3\2\24\32\2\u0093\2\22\3\2\2\2")
-        buf.write("\4\31\3\2\2\2\6!\3\2\2\2\b\65\3\2\2\2\n\67\3\2\2\2\f9")
-        buf.write("\3\2\2\2\16_\3\2\2\2\20v\3\2\2\2\22\23\5\4\3\2\23\24\7")
-        buf.write("\3\2\2\24\25\5\4\3\2\25\3\3\2\2\2\26\30\5\6\4\2\27\26")
-        buf.write("\3\2\2\2\30\33\3\2\2\2\31\27\3\2\2\2\31\32\3\2\2\2\32")
-        buf.write("\5\3\2\2\2\33\31\3\2\2\2\34\"\5\b\5\2\35\"\5\f\7\2\36")
-        buf.write("\"\5\16\b\2\37\"\5\20\t\2 \"\7\4\2\2!\34\3\2\2\2!\35\3")
-        buf.write("\2\2\2!\36\3\2\2\2!\37\3\2\2\2! \3\2\2\2\"\7\3\2\2\2#")
-        buf.write("\'\7\5\2\2$&\5\n\6\2%$\3\2\2\2&)\3\2\2\2\'%\3\2\2\2\'")
-        buf.write("(\3\2\2\2(*\3\2\2\2)\'\3\2\2\2*\66\7\6\2\2+/\7\7\2\2,")
-        buf.write(".\5\n\6\2-,\3\2\2\2.\61\3\2\2\2/-\3\2\2\2/\60\3\2\2\2")
-        buf.write("\60\62\3\2\2\2\61/\3\2\2\2\62\66\7\6\2\2\63\66\7\b\2\2")
-        buf.write("\64\66\7\t\2\2\65#\3\2\2\2\65+\3\2\2\2\65\63\3\2\2\2\65")
-        buf.write("\64\3\2\2\2\66\t\3\2\2\2\678\t\2\2\28\13\3\2\2\29:\t\3")
-        buf.write("\2\2:\r\3\2\2\2;?\7\33\2\2<>\5\6\4\2=<\3\2\2\2>A\3\2\2")
-        buf.write("\2?=\3\2\2\2?@\3\2\2\2@B\3\2\2\2A?\3\2\2\2B`\7\34\2\2")
-        buf.write("CG\7\35\2\2DF\5\6\4\2ED\3\2\2\2FI\3\2\2\2GE\3\2\2\2GH")
-        buf.write("\3\2\2\2HJ\3\2\2\2IG\3\2\2\2J`\7\36\2\2KO\7\37\2\2LN\5")
-        buf.write("\6\4\2ML\3\2\2\2NQ\3\2\2\2OM\3\2\2\2OP\3\2\2\2PR\3\2\2")
-        buf.write("\2QO\3\2\2\2R`\7 \2\2SW\7!\2\2TV\5\6\4\2UT\3\2\2\2VY\3")
-        buf.write("\2\2\2WU\3\2\2\2WX\3\2\2\2XZ\3\2\2\2YW\3\2\2\2Z`\7!\2")
-        buf.write("\2[`\7\"\2\2\\`\7#\2\2]`\7$\2\2^`\7%\2\2_;\3\2\2\2_C\3")
-        buf.write("\2\2\2_K\3\2\2\2_S\3\2\2\2_[\3\2\2\2_\\\3\2\2\2_]\3\2")
-        buf.write("\2\2_^\3\2\2\2`\17\3\2\2\2aw\7&\2\2bw\7\'\2\2cw\7(\2\2")
-        buf.write("dw\7)\2\2ew\7*\2\2fw\7+\2\2gw\7\6\2\2hw\7,\2\2iw\7-\2")
-        buf.write("\2jw\7*\2\2kw\7.\2\2lw\7/\2\2mw\7\60\2\2nr\7\61\2\2oq")
-        buf.write("\5\n\6\2po\3\2\2\2qt\3\2\2\2rp\3\2\2\2rs\3\2\2\2su\3\2")
-        buf.write("\2\2tr\3\2\2\2uw\7\6\2\2va\3\2\2\2vb\3\2\2\2vc\3\2\2\2")
-        buf.write("vd\3\2\2\2ve\3\2\2\2vf\3\2\2\2vg\3\2\2\2vh\3\2\2\2vi\3")
-        buf.write("\2\2\2vj\3\2\2\2vk\3\2\2\2vl\3\2\2\2vm\3\2\2\2vn\3\2\2")
-        buf.write("\2w\21\3\2\2\2\16\31!\'/\65?GOW_rv")
+        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3+")
+        buf.write("\u008a\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7")
+        buf.write("\4\b\t\b\4\t\t\t\4\n\t\n\3\2\3\2\3\2\3\2\3\3\7\3\32\n")
+        buf.write("\3\f\3\16\3\35\13\3\3\4\3\4\3\4\3\4\3\4\3\4\5\4%\n\4\3")
+        buf.write("\5\3\5\3\6\3\6\7\6+\n\6\f\6\16\6.\13\6\3\6\3\6\3\6\7\6")
+        buf.write("\63\n\6\f\6\16\6\66\13\6\3\6\3\6\3\6\7\6;\n\6\f\6\16\6")
+        buf.write(">\13\6\3\6\3\6\3\6\7\6C\n\6\f\6\16\6F\13\6\3\6\3\6\3\6")
+        buf.write("\3\6\3\6\5\6M\n\6\3\7\3\7\7\7Q\n\7\f\7\16\7T\13\7\3\7")
+        buf.write("\3\7\3\7\7\7Y\n\7\f\7\16\7\\\13\7\3\7\3\7\5\7`\n\7\3\b")
+        buf.write("\3\b\7\bd\n\b\f\b\16\bg\13\b\3\b\3\b\3\b\7\bl\n\b\f\b")
+        buf.write("\16\bo\13\b\3\b\3\b\5\bs\n\b\3\t\3\t\7\tw\n\t\f\t\16\t")
+        buf.write("z\13\t\3\t\3\t\3\t\7\t\177\n\t\f\t\16\t\u0082\13\t\3\t")
+        buf.write("\3\t\5\t\u0086\n\t\3\n\3\n\3\n\2\2\13\2\4\6\b\n\f\16\20")
+        buf.write("\22\2\4\3\2\5\13\3\2!*\2\u009d\2\24\3\2\2\2\4\33\3\2\2")
+        buf.write("\2\6$\3\2\2\2\b&\3\2\2\2\nL\3\2\2\2\f_\3\2\2\2\16r\3\2")
+        buf.write("\2\2\20\u0085\3\2\2\2\22\u0087\3\2\2\2\24\25\5\4\3\2\25")
+        buf.write("\26\7\3\2\2\26\27\5\4\3\2\27\3\3\2\2\2\30\32\5\6\4\2\31")
+        buf.write("\30\3\2\2\2\32\35\3\2\2\2\33\31\3\2\2\2\33\34\3\2\2\2")
+        buf.write("\34\5\3\2\2\2\35\33\3\2\2\2\36%\5\f\7\2\37%\5\b\5\2 %")
+        buf.write("\5\n\6\2!%\5\16\b\2\"%\5\20\t\2#%\7\4\2\2$\36\3\2\2\2")
+        buf.write("$\37\3\2\2\2$ \3\2\2\2$!\3\2\2\2$\"\3\2\2\2$#\3\2\2\2")
+        buf.write("%\7\3\2\2\2&\'\t\2\2\2\'\t\3\2\2\2(,\7\f\2\2)+\5\6\4\2")
+        buf.write("*)\3\2\2\2+.\3\2\2\2,*\3\2\2\2,-\3\2\2\2-/\3\2\2\2.,\3")
+        buf.write("\2\2\2/M\7\r\2\2\60\64\7\16\2\2\61\63\5\6\4\2\62\61\3")
+        buf.write("\2\2\2\63\66\3\2\2\2\64\62\3\2\2\2\64\65\3\2\2\2\65\67")
+        buf.write("\3\2\2\2\66\64\3\2\2\2\67M\7\17\2\28<\7\20\2\29;\5\6\4")
+        buf.write("\2:9\3\2\2\2;>\3\2\2\2<:\3\2\2\2<=\3\2\2\2=?\3\2\2\2>")
+        buf.write("<\3\2\2\2?M\7\21\2\2@D\7\22\2\2AC\5\6\4\2BA\3\2\2\2CF")
+        buf.write("\3\2\2\2DB\3\2\2\2DE\3\2\2\2EG\3\2\2\2FD\3\2\2\2GM\7\22")
+        buf.write("\2\2HM\7\23\2\2IM\7\24\2\2JM\7\25\2\2KM\7\26\2\2L(\3\2")
+        buf.write("\2\2L\60\3\2\2\2L8\3\2\2\2L@\3\2\2\2LH\3\2\2\2LI\3\2\2")
+        buf.write("\2LJ\3\2\2\2LK\3\2\2\2M\13\3\2\2\2NR\7\27\2\2OQ\5\22\n")
+        buf.write("\2PO\3\2\2\2QT\3\2\2\2RP\3\2\2\2RS\3\2\2\2SU\3\2\2\2T")
+        buf.write("R\3\2\2\2U`\7\30\2\2VZ\7\31\2\2WY\5\22\n\2XW\3\2\2\2Y")
+        buf.write("\\\3\2\2\2ZX\3\2\2\2Z[\3\2\2\2[]\3\2\2\2\\Z\3\2\2\2]`")
+        buf.write("\7\30\2\2^`\7\32\2\2_N\3\2\2\2_V\3\2\2\2_^\3\2\2\2`\r")
+        buf.write("\3\2\2\2ae\7\33\2\2bd\5\22\n\2cb\3\2\2\2dg\3\2\2\2ec\3")
+        buf.write("\2\2\2ef\3\2\2\2fh\3\2\2\2ge\3\2\2\2hs\7\30\2\2im\7\34")
+        buf.write("\2\2jl\5\22\n\2kj\3\2\2\2lo\3\2\2\2mk\3\2\2\2mn\3\2\2")
+        buf.write("\2np\3\2\2\2om\3\2\2\2ps\7\30\2\2qs\7\35\2\2ra\3\2\2\2")
+        buf.write("ri\3\2\2\2rq\3\2\2\2s\17\3\2\2\2tx\7\36\2\2uw\5\22\n\2")
+        buf.write("vu\3\2\2\2wz\3\2\2\2xv\3\2\2\2xy\3\2\2\2y{\3\2\2\2zx\3")
+        buf.write("\2\2\2{\u0086\7\30\2\2|\u0080\7\37\2\2}\177\5\22\n\2~")
+        buf.write("}\3\2\2\2\177\u0082\3\2\2\2\u0080~\3\2\2\2\u0080\u0081")
+        buf.write("\3\2\2\2\u0081\u0083\3\2\2\2\u0082\u0080\3\2\2\2\u0083")
+        buf.write("\u0086\7\30\2\2\u0084\u0086\7 \2\2\u0085t\3\2\2\2\u0085")
+        buf.write("|\3\2\2\2\u0085\u0084\3\2\2\2\u0086\21\3\2\2\2\u0087\u0088")
+        buf.write("\t\3\2\2\u0088\23\3\2\2\2\22\33$,\64<DLRZ_emrx\u0080\u0085")
         return buf.getvalue()
 
 
@@ -62,14 +68,13 @@ class SearchParser ( Parser ):
 
     sharedContextCache = PredictionContextCache()
 
-    literalNames = [ "<INVALID>", "'->'", "'_'", "'#ID<'", "'>'", "'#N<'", 
-                     "'#ID<.>'", "'#N<.>'", "'0'", "'1'", "'2'", "'3'", 
-                     "'4'", "'5'", "'6'", "'7'", "'8'", "'9'", "'if'", "'else'", 
-                     "'for'", "'forEach'", "'while'", "'return'", "'NULL'", 
-                     "'('", "')'", "'['", "']'", "'{'", "'}'", "'\"'", "'='", 
-                     "'.'", "','", "';'", "'+'", "'\u2212'", "'*'", "'/'", 
-                     "'=='", "'<'", "'<='", "'>='", "'!='", "'&&'", "'||'", 
-                     "'#OP<'" ]
+    literalNames = [ "<INVALID>", "'->'", "'_'", "'if'", "'else'", "'for'", 
+                     "'forEach'", "'while'", "'return'", "'NULL'", "'('", 
+                     "')'", "'['", "']'", "'{'", "'}'", "'\"'", "'='", "'.'", 
+                     "','", "';'", "'#ID<'", "'>'", "'#ID<!'", "'#ID<.>'", 
+                     "'#OP<'", "'#OP<!'", "'#OP<.>'", "'#LT<'", "'#LT<!'", 
+                     "'#LT<.>'", "'0'", "'1'", "'2'", "'3'", "'4'", "'5'", 
+                     "'6'", "'7'", "'8'", "'9'" ]
 
     symbolicNames = [ "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
@@ -81,21 +86,20 @@ class SearchParser ( Parser ):
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                       "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
-                      "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
-                      "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
-                      "WS" ]
+                      "<INVALID>", "WS" ]
 
     RULE_query = 0
-    RULE_expr = 1
+    RULE_code = 1
     RULE_token = 2
-    RULE_identifier = 3
-    RULE_digit = 4
-    RULE_keyword = 5
-    RULE_punctuator = 6
-    RULE_op = 7
+    RULE_keyword = 3
+    RULE_punctuator = 4
+    RULE_identifier = 5
+    RULE_operator = 6
+    RULE_literal = 7
+    RULE_digit = 8
 
-    ruleNames =  [ "query", "expr", "token", "identifier", "digit", "keyword", 
-                   "punctuator", "op" ]
+    ruleNames =  [ "query", "code", "token", "keyword", "punctuator", "identifier", 
+                   "operator", "literal", "digit" ]
 
     EOF = Token.EOF
     T__0=1
@@ -138,14 +142,7 @@ class SearchParser ( Parser ):
     T__37=38
     T__38=39
     T__39=40
-    T__40=41
-    T__41=42
-    T__42=43
-    T__43=44
-    T__44=45
-    T__45=46
-    T__46=47
-    WS=48
+    WS=41
 
     def __init__(self, input:TokenStream, output:TextIO = sys.stdout):
         super().__init__(input, output)
@@ -161,11 +158,11 @@ class SearchParser ( Parser ):
             super().__init__(parent, invokingState)
             self.parser = parser
 
-        def expr(self, i:int=None):
+        def code(self, i:int=None):
             if i is None:
-                return self.getTypedRuleContexts(SearchParser.ExprContext)
+                return self.getTypedRuleContexts(SearchParser.CodeContext)
             else:
-                return self.getTypedRuleContext(SearchParser.ExprContext,i)
+                return self.getTypedRuleContext(SearchParser.CodeContext,i)
 
 
         def getRuleIndex(self):
@@ -188,12 +185,12 @@ class SearchParser ( Parser ):
         self.enterRule(localctx, 0, self.RULE_query)
         try:
             self.enterOuterAlt(localctx, 1)
-            self.state = 16
-            self.expr()
-            self.state = 17
-            self.match(SearchParser.T__0)
             self.state = 18
-            self.expr()
+            self.code()
+            self.state = 19
+            self.match(SearchParser.T__0)
+            self.state = 20
+            self.code()
         except RecognitionException as re:
             localctx.exception = re
             self._errHandler.reportError(self, re)
@@ -202,7 +199,7 @@ class SearchParser ( Parser ):
             self.exitRule()
         return localctx
 
-    class ExprContext(ParserRuleContext):
+    class CodeContext(ParserRuleContext):
 
         def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
             super().__init__(parent, invokingState)
@@ -216,33 +213,33 @@ class SearchParser ( Parser ):
 
 
         def getRuleIndex(self):
-            return SearchParser.RULE_expr
+            return SearchParser.RULE_code
 
         def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterExpr" ):
-                listener.enterExpr(self)
+            if hasattr( listener, "enterCode" ):
+                listener.enterCode(self)
 
         def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitExpr" ):
-                listener.exitExpr(self)
+            if hasattr( listener, "exitCode" ):
+                listener.exitCode(self)
 
 
 
 
-    def expr(self):
+    def code(self):
 
-        localctx = SearchParser.ExprContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 2, self.RULE_expr)
+        localctx = SearchParser.CodeContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 2, self.RULE_code)
         self._la = 0 # Token type
         try:
             self.enterOuterAlt(localctx, 1)
-            self.state = 23
+            self.state = 25
             self._errHandler.sync(self)
             _la = self._input.LA(1)
-            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                self.state = 20
+            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                self.state = 22
                 self.token()
-                self.state = 25
+                self.state = 27
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
 
@@ -272,8 +269,12 @@ class SearchParser ( Parser ):
             return self.getTypedRuleContext(SearchParser.PunctuatorContext,0)
 
 
-        def op(self):
-            return self.getTypedRuleContext(SearchParser.OpContext,0)
+        def operator(self):
+            return self.getTypedRuleContext(SearchParser.OperatorContext,0)
+
+
+        def literal(self):
+            return self.getTypedRuleContext(SearchParser.LiteralContext,0)
 
 
         def getRuleIndex(self):
@@ -295,124 +296,38 @@ class SearchParser ( Parser ):
         localctx = SearchParser.TokenContext(self, self._ctx, self.state)
         self.enterRule(localctx, 4, self.RULE_token)
         try:
-            self.state = 31
+            self.state = 34
             self._errHandler.sync(self)
             token = self._input.LA(1)
-            if token in [SearchParser.T__2, SearchParser.T__4, SearchParser.T__5, SearchParser.T__6]:
+            if token in [SearchParser.T__20, SearchParser.T__22, SearchParser.T__23]:
                 self.enterOuterAlt(localctx, 1)
-                self.state = 26
+                self.state = 28
                 self.identifier()
                 pass
-            elif token in [SearchParser.T__17, SearchParser.T__18, SearchParser.T__19, SearchParser.T__20, SearchParser.T__21, SearchParser.T__22, SearchParser.T__23]:
+            elif token in [SearchParser.T__2, SearchParser.T__3, SearchParser.T__4, SearchParser.T__5, SearchParser.T__6, SearchParser.T__7, SearchParser.T__8]:
                 self.enterOuterAlt(localctx, 2)
-                self.state = 27
+                self.state = 29
                 self.keyword()
                 pass
-            elif token in [SearchParser.T__24, SearchParser.T__26, SearchParser.T__28, SearchParser.T__30, SearchParser.T__31, SearchParser.T__32, SearchParser.T__33, SearchParser.T__34]:
+            elif token in [SearchParser.T__9, SearchParser.T__11, SearchParser.T__13, SearchParser.T__15, SearchParser.T__16, SearchParser.T__17, SearchParser.T__18, SearchParser.T__19]:
                 self.enterOuterAlt(localctx, 3)
-                self.state = 28
+                self.state = 30
                 self.punctuator()
                 pass
-            elif token in [SearchParser.T__3, SearchParser.T__35, SearchParser.T__36, SearchParser.T__37, SearchParser.T__38, SearchParser.T__39, SearchParser.T__40, SearchParser.T__41, SearchParser.T__42, SearchParser.T__43, SearchParser.T__44, SearchParser.T__45, SearchParser.T__46]:
+            elif token in [SearchParser.T__24, SearchParser.T__25, SearchParser.T__26]:
                 self.enterOuterAlt(localctx, 4)
-                self.state = 29
-                self.op()
+                self.state = 31
+                self.operator()
                 pass
-            elif token in [SearchParser.T__1]:
+            elif token in [SearchParser.T__27, SearchParser.T__28, SearchParser.T__29]:
                 self.enterOuterAlt(localctx, 5)
-                self.state = 30
-                self.match(SearchParser.T__1)
+                self.state = 32
+                self.literal()
                 pass
-            else:
-                raise NoViableAltException(self)
-
-        except RecognitionException as re:
-            localctx.exception = re
-            self._errHandler.reportError(self, re)
-            self._errHandler.recover(self, re)
-        finally:
-            self.exitRule()
-        return localctx
-
-    class IdentifierContext(ParserRuleContext):
-
-        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
-            super().__init__(parent, invokingState)
-            self.parser = parser
-
-        def digit(self, i:int=None):
-            if i is None:
-                return self.getTypedRuleContexts(SearchParser.DigitContext)
-            else:
-                return self.getTypedRuleContext(SearchParser.DigitContext,i)
-
-
-        def getRuleIndex(self):
-            return SearchParser.RULE_identifier
-
-        def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterIdentifier" ):
-                listener.enterIdentifier(self)
-
-        def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitIdentifier" ):
-                listener.exitIdentifier(self)
-
-
-
-
-    def identifier(self):
-
-        localctx = SearchParser.IdentifierContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 6, self.RULE_identifier)
-        self._la = 0 # Token type
-        try:
-            self.state = 51
-            self._errHandler.sync(self)
-            token = self._input.LA(1)
-            if token in [SearchParser.T__2]:
-                self.enterOuterAlt(localctx, 1)
+            elif token in [SearchParser.T__1]:
+                self.enterOuterAlt(localctx, 6)
                 self.state = 33
-                self.match(SearchParser.T__2)
-                self.state = 37
-                self._errHandler.sync(self)
-                _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0):
-                    self.state = 34
-                    self.digit()
-                    self.state = 39
-                    self._errHandler.sync(self)
-                    _la = self._input.LA(1)
-
-                self.state = 40
-                self.match(SearchParser.T__3)
-                pass
-            elif token in [SearchParser.T__4]:
-                self.enterOuterAlt(localctx, 2)
-                self.state = 41
-                self.match(SearchParser.T__4)
-                self.state = 45
-                self._errHandler.sync(self)
-                _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0):
-                    self.state = 42
-                    self.digit()
-                    self.state = 47
-                    self._errHandler.sync(self)
-                    _la = self._input.LA(1)
-
-                self.state = 48
-                self.match(SearchParser.T__3)
-                pass
-            elif token in [SearchParser.T__5]:
-                self.enterOuterAlt(localctx, 3)
-                self.state = 49
-                self.match(SearchParser.T__5)
-                pass
-            elif token in [SearchParser.T__6]:
-                self.enterOuterAlt(localctx, 4)
-                self.state = 50
-                self.match(SearchParser.T__6)
+                self.match(SearchParser.T__1)
                 pass
             else:
                 raise NoViableAltException(self)
@@ -425,49 +340,6 @@ class SearchParser ( Parser ):
             self.exitRule()
         return localctx
 
-    class DigitContext(ParserRuleContext):
-
-        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
-            super().__init__(parent, invokingState)
-            self.parser = parser
-
-
-        def getRuleIndex(self):
-            return SearchParser.RULE_digit
-
-        def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterDigit" ):
-                listener.enterDigit(self)
-
-        def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitDigit" ):
-                listener.exitDigit(self)
-
-
-
-
-    def digit(self):
-
-        localctx = SearchParser.DigitContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 8, self.RULE_digit)
-        self._la = 0 # Token type
-        try:
-            self.enterOuterAlt(localctx, 1)
-            self.state = 53
-            _la = self._input.LA(1)
-            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0)):
-                self._errHandler.recoverInline(self)
-            else:
-                self._errHandler.reportMatch(self)
-                self.consume()
-        except RecognitionException as re:
-            localctx.exception = re
-            self._errHandler.reportError(self, re)
-            self._errHandler.recover(self, re)
-        finally:
-            self.exitRule()
-        return localctx
-
     class KeywordContext(ParserRuleContext):
 
         def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
@@ -492,13 +364,13 @@ class SearchParser ( Parser ):
     def keyword(self):
 
         localctx = SearchParser.KeywordContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 10, self.RULE_keyword)
+        self.enterRule(localctx, 6, self.RULE_keyword)
         self._la = 0 # Token type
         try:
             self.enterOuterAlt(localctx, 1)
-            self.state = 55
+            self.state = 36
             _la = self._input.LA(1)
-            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23))) != 0)):
+            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8))) != 0)):
                 self._errHandler.recoverInline(self)
             else:
                 self._errHandler.reportMatch(self)
@@ -541,100 +413,100 @@ class SearchParser ( Parser ):
     def punctuator(self):
 
         localctx = SearchParser.PunctuatorContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 12, self.RULE_punctuator)
+        self.enterRule(localctx, 8, self.RULE_punctuator)
         self._la = 0 # Token type
         try:
-            self.state = 93
+            self.state = 74
             self._errHandler.sync(self)
             token = self._input.LA(1)
-            if token in [SearchParser.T__24]:
+            if token in [SearchParser.T__9]:
                 self.enterOuterAlt(localctx, 1)
-                self.state = 57
-                self.match(SearchParser.T__24)
-                self.state = 61
+                self.state = 38
+                self.match(SearchParser.T__9)
+                self.state = 42
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                    self.state = 58
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                    self.state = 39
                     self.token()
-                    self.state = 63
+                    self.state = 44
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 64
-                self.match(SearchParser.T__25)
+                self.state = 45
+                self.match(SearchParser.T__10)
                 pass
-            elif token in [SearchParser.T__26]:
+            elif token in [SearchParser.T__11]:
                 self.enterOuterAlt(localctx, 2)
-                self.state = 65
-                self.match(SearchParser.T__26)
-                self.state = 69
+                self.state = 46
+                self.match(SearchParser.T__11)
+                self.state = 50
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                    self.state = 66
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                    self.state = 47
                     self.token()
-                    self.state = 71
+                    self.state = 52
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 72
-                self.match(SearchParser.T__27)
+                self.state = 53
+                self.match(SearchParser.T__12)
                 pass
-            elif token in [SearchParser.T__28]:
+            elif token in [SearchParser.T__13]:
                 self.enterOuterAlt(localctx, 3)
-                self.state = 73
-                self.match(SearchParser.T__28)
-                self.state = 77
+                self.state = 54
+                self.match(SearchParser.T__13)
+                self.state = 58
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__21) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__26) | (1 << SearchParser.T__28) | (1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39) | (1 << SearchParser.T__40) | (1 << SearchParser.T__41) | (1 << SearchParser.T__42) | (1 << SearchParser.T__43) | (1 << SearchParser.T__44) | (1 << SearchParser.T__45) | (1 << SearchParser.T__46))) != 0):
-                    self.state = 74
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__1) | (1 << SearchParser.T__2) | (1 << SearchParser.T__3) | (1 << SearchParser.T__4) | (1 << SearchParser.T__5) | (1 << SearchParser.T__6) | (1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__11) | (1 << SearchParser.T__13) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16) | (1 << SearchParser.T__17) | (1 << SearchParser.T__18) | (1 << SearchParser.T__19) | (1 << SearchParser.T__20) | (1 << SearchParser.T__22) | (1 << SearchParser.T__23) | (1 << SearchParser.T__24) | (1 << SearchParser.T__25) | (1 << SearchParser.T__26) | (1 << SearchParser.T__27) | (1 << SearchParser.T__28) | (1 << SearchParser.T__29))) != 0):
+                    self.state = 55
                     self.token()
-                    self.state = 79
+                    self.state = 60
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 80
-                self.match(SearchParser.T__29)
+                self.state = 61
+                self.match(SearchParser.T__14)
                 pass
-            elif token in [SearchParser.T__30]:
+            elif token in [SearchParser.T__15]:
                 self.enterOuterAlt(localctx, 4)
-                self.state = 81
-                self.match(SearchParser.T__30)
-                self.state = 85
+                self.state = 62
+                self.match(SearchParser.T__15)
+                self.state = 66
                 self._errHandler.sync(self)
-                _alt = self._interp.adaptivePredict(self._input,8,self._ctx)
+                _alt = self._interp.adaptivePredict(self._input,5,self._ctx)
                 while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                     if _alt==1:
-                        self.state = 82
+                        self.state = 63
                         self.token() 
-                    self.state = 87
+                    self.state = 68
                     self._errHandler.sync(self)
-                    _alt = self._interp.adaptivePredict(self._input,8,self._ctx)
+                    _alt = self._interp.adaptivePredict(self._input,5,self._ctx)
 
-                self.state = 88
-                self.match(SearchParser.T__30)
+                self.state = 69
+                self.match(SearchParser.T__15)
                 pass
-            elif token in [SearchParser.T__31]:
+            elif token in [SearchParser.T__16]:
                 self.enterOuterAlt(localctx, 5)
-                self.state = 89
-                self.match(SearchParser.T__31)
+                self.state = 70
+                self.match(SearchParser.T__16)
                 pass
-            elif token in [SearchParser.T__32]:
+            elif token in [SearchParser.T__17]:
                 self.enterOuterAlt(localctx, 6)
-                self.state = 90
-                self.match(SearchParser.T__32)
+                self.state = 71
+                self.match(SearchParser.T__17)
                 pass
-            elif token in [SearchParser.T__33]:
+            elif token in [SearchParser.T__18]:
                 self.enterOuterAlt(localctx, 7)
-                self.state = 91
-                self.match(SearchParser.T__33)
+                self.state = 72
+                self.match(SearchParser.T__18)
                 pass
-            elif token in [SearchParser.T__34]:
+            elif token in [SearchParser.T__19]:
                 self.enterOuterAlt(localctx, 8)
-                self.state = 92
-                self.match(SearchParser.T__34)
+                self.state = 73
+                self.match(SearchParser.T__19)
                 pass
             else:
                 raise NoViableAltException(self)
@@ -647,7 +519,7 @@ class SearchParser ( Parser ):
             self.exitRule()
         return localctx
 
-    class OpContext(ParserRuleContext):
+    class IdentifierContext(ParserRuleContext):
 
         def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
             super().__init__(parent, invokingState)
@@ -661,125 +533,285 @@ class SearchParser ( Parser ):
 
 
         def getRuleIndex(self):
-            return SearchParser.RULE_op
+            return SearchParser.RULE_identifier
 
         def enterRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "enterOp" ):
-                listener.enterOp(self)
+            if hasattr( listener, "enterIdentifier" ):
+                listener.enterIdentifier(self)
 
         def exitRule(self, listener:ParseTreeListener):
-            if hasattr( listener, "exitOp" ):
-                listener.exitOp(self)
+            if hasattr( listener, "exitIdentifier" ):
+                listener.exitIdentifier(self)
 
 
 
 
-    def op(self):
+    def identifier(self):
 
-        localctx = SearchParser.OpContext(self, self._ctx, self.state)
-        self.enterRule(localctx, 14, self.RULE_op)
+        localctx = SearchParser.IdentifierContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 10, self.RULE_identifier)
         self._la = 0 # Token type
         try:
-            self.state = 116
+            self.state = 93
             self._errHandler.sync(self)
-            la_ = self._interp.adaptivePredict(self._input,11,self._ctx)
-            if la_ == 1:
+            token = self._input.LA(1)
+            if token in [SearchParser.T__20]:
                 self.enterOuterAlt(localctx, 1)
-                self.state = 95
-                self.match(SearchParser.T__35)
-                pass
+                self.state = 76
+                self.match(SearchParser.T__20)
+                self.state = 80
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 77
+                    self.digit()
+                    self.state = 82
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 2:
-                self.enterOuterAlt(localctx, 2)
-                self.state = 96
-                self.match(SearchParser.T__36)
+                self.state = 83
+                self.match(SearchParser.T__21)
                 pass
+            elif token in [SearchParser.T__22]:
+                self.enterOuterAlt(localctx, 2)
+                self.state = 84
+                self.match(SearchParser.T__22)
+                self.state = 88
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 85
+                    self.digit()
+                    self.state = 90
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 3:
+                self.state = 91
+                self.match(SearchParser.T__21)
+                pass
+            elif token in [SearchParser.T__23]:
                 self.enterOuterAlt(localctx, 3)
-                self.state = 97
-                self.match(SearchParser.T__37)
+                self.state = 92
+                self.match(SearchParser.T__23)
                 pass
+            else:
+                raise NoViableAltException(self)
 
-            elif la_ == 4:
-                self.enterOuterAlt(localctx, 4)
-                self.state = 98
-                self.match(SearchParser.T__38)
-                pass
+        except RecognitionException as re:
+            localctx.exception = re
+            self._errHandler.reportError(self, re)
+            self._errHandler.recover(self, re)
+        finally:
+            self.exitRule()
+        return localctx
 
-            elif la_ == 5:
-                self.enterOuterAlt(localctx, 5)
-                self.state = 99
-                self.match(SearchParser.T__39)
-                pass
+    class OperatorContext(ParserRuleContext):
 
-            elif la_ == 6:
-                self.enterOuterAlt(localctx, 6)
-                self.state = 100
-                self.match(SearchParser.T__40)
-                pass
+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
+            super().__init__(parent, invokingState)
+            self.parser = parser
 
-            elif la_ == 7:
-                self.enterOuterAlt(localctx, 7)
-                self.state = 101
-                self.match(SearchParser.T__3)
-                pass
+        def digit(self, i:int=None):
+            if i is None:
+                return self.getTypedRuleContexts(SearchParser.DigitContext)
+            else:
+                return self.getTypedRuleContext(SearchParser.DigitContext,i)
+
+
+        def getRuleIndex(self):
+            return SearchParser.RULE_operator
+
+        def enterRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "enterOperator" ):
+                listener.enterOperator(self)
+
+        def exitRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "exitOperator" ):
+                listener.exitOperator(self)
+
+
+
+
+    def operator(self):
+
+        localctx = SearchParser.OperatorContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 12, self.RULE_operator)
+        self._la = 0 # Token type
+        try:
+            self.state = 112
+            self._errHandler.sync(self)
+            token = self._input.LA(1)
+            if token in [SearchParser.T__24]:
+                self.enterOuterAlt(localctx, 1)
+                self.state = 95
+                self.match(SearchParser.T__24)
+                self.state = 99
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 96
+                    self.digit()
+                    self.state = 101
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 8:
-                self.enterOuterAlt(localctx, 8)
                 self.state = 102
-                self.match(SearchParser.T__41)
+                self.match(SearchParser.T__21)
                 pass
-
-            elif la_ == 9:
-                self.enterOuterAlt(localctx, 9)
+            elif token in [SearchParser.T__25]:
+                self.enterOuterAlt(localctx, 2)
                 self.state = 103
-                self.match(SearchParser.T__42)
-                pass
+                self.match(SearchParser.T__25)
+                self.state = 107
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 104
+                    self.digit()
+                    self.state = 109
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
 
-            elif la_ == 10:
-                self.enterOuterAlt(localctx, 10)
-                self.state = 104
-                self.match(SearchParser.T__39)
+                self.state = 110
+                self.match(SearchParser.T__21)
                 pass
-
-            elif la_ == 11:
-                self.enterOuterAlt(localctx, 11)
-                self.state = 105
-                self.match(SearchParser.T__43)
+            elif token in [SearchParser.T__26]:
+                self.enterOuterAlt(localctx, 3)
+                self.state = 111
+                self.match(SearchParser.T__26)
                 pass
+            else:
+                raise NoViableAltException(self)
 
-            elif la_ == 12:
-                self.enterOuterAlt(localctx, 12)
-                self.state = 106
-                self.match(SearchParser.T__44)
-                pass
+        except RecognitionException as re:
+            localctx.exception = re
+            self._errHandler.reportError(self, re)
+            self._errHandler.recover(self, re)
+        finally:
+            self.exitRule()
+        return localctx
+
+    class LiteralContext(ParserRuleContext):
+
+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
+            super().__init__(parent, invokingState)
+            self.parser = parser
+
+        def digit(self, i:int=None):
+            if i is None:
+                return self.getTypedRuleContexts(SearchParser.DigitContext)
+            else:
+                return self.getTypedRuleContext(SearchParser.DigitContext,i)
+
+
+        def getRuleIndex(self):
+            return SearchParser.RULE_literal
+
+        def enterRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "enterLiteral" ):
+                listener.enterLiteral(self)
+
+        def exitRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "exitLiteral" ):
+                listener.exitLiteral(self)
 
-            elif la_ == 13:
-                self.enterOuterAlt(localctx, 13)
-                self.state = 107
-                self.match(SearchParser.T__45)
-                pass
 
-            elif la_ == 14:
-                self.enterOuterAlt(localctx, 14)
-                self.state = 108
-                self.match(SearchParser.T__46)
-                self.state = 112
+
+
+    def literal(self):
+
+        localctx = SearchParser.LiteralContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 14, self.RULE_literal)
+        self._la = 0 # Token type
+        try:
+            self.state = 131
+            self._errHandler.sync(self)
+            token = self._input.LA(1)
+            if token in [SearchParser.T__27]:
+                self.enterOuterAlt(localctx, 1)
+                self.state = 114
+                self.match(SearchParser.T__27)
+                self.state = 118
                 self._errHandler.sync(self)
                 _la = self._input.LA(1)
-                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__7) | (1 << SearchParser.T__8) | (1 << SearchParser.T__9) | (1 << SearchParser.T__10) | (1 << SearchParser.T__11) | (1 << SearchParser.T__12) | (1 << SearchParser.T__13) | (1 << SearchParser.T__14) | (1 << SearchParser.T__15) | (1 << SearchParser.T__16))) != 0):
-                    self.state = 109
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 115
                     self.digit()
-                    self.state = 114
+                    self.state = 120
                     self._errHandler.sync(self)
                     _la = self._input.LA(1)
 
-                self.state = 115
-                self.match(SearchParser.T__3)
+                self.state = 121
+                self.match(SearchParser.T__21)
+                pass
+            elif token in [SearchParser.T__28]:
+                self.enterOuterAlt(localctx, 2)
+                self.state = 122
+                self.match(SearchParser.T__28)
+                self.state = 126
+                self._errHandler.sync(self)
+                _la = self._input.LA(1)
+                while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0):
+                    self.state = 123
+                    self.digit()
+                    self.state = 128
+                    self._errHandler.sync(self)
+                    _la = self._input.LA(1)
+
+                self.state = 129
+                self.match(SearchParser.T__21)
+                pass
+            elif token in [SearchParser.T__29]:
+                self.enterOuterAlt(localctx, 3)
+                self.state = 130
+                self.match(SearchParser.T__29)
                 pass
+            else:
+                raise NoViableAltException(self)
+
+        except RecognitionException as re:
+            localctx.exception = re
+            self._errHandler.reportError(self, re)
+            self._errHandler.recover(self, re)
+        finally:
+            self.exitRule()
+        return localctx
+
+    class DigitContext(ParserRuleContext):
 
+        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
+            super().__init__(parent, invokingState)
+            self.parser = parser
 
+
+        def getRuleIndex(self):
+            return SearchParser.RULE_digit
+
+        def enterRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "enterDigit" ):
+                listener.enterDigit(self)
+
+        def exitRule(self, listener:ParseTreeListener):
+            if hasattr( listener, "exitDigit" ):
+                listener.exitDigit(self)
+
+
+
+
+    def digit(self):
+
+        localctx = SearchParser.DigitContext(self, self._ctx, self.state)
+        self.enterRule(localctx, 16, self.RULE_digit)
+        self._la = 0 # Token type
+        try:
+            self.enterOuterAlt(localctx, 1)
+            self.state = 133
+            _la = self._input.LA(1)
+            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << SearchParser.T__30) | (1 << SearchParser.T__31) | (1 << SearchParser.T__32) | (1 << SearchParser.T__33) | (1 << SearchParser.T__34) | (1 << SearchParser.T__35) | (1 << SearchParser.T__36) | (1 << SearchParser.T__37) | (1 << SearchParser.T__38) | (1 << SearchParser.T__39))) != 0)):
+                self._errHandler.recoverInline(self)
+            else:
+                self._errHandler.reportMatch(self)
+                self.consume()
         except RecognitionException as re:
             localctx.exception = re
             self._errHandler.reportError(self, re)
diff --git a/code/example.txt b/code/example.txt
index 56c4c47..a8ab280 100644
--- a/code/example.txt
+++ b/code/example.txt
@@ -1,21 +1,23 @@
-9for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<0>;#ID<.>#OP<.>){->for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<1>;#ID<.>#OP<.>){
-#ID<.>.#ID<.>(#N<0>,#N<1>);->#ID<.>.#ID<.>(#N<2>,#N<3>);
-#ID<.>.#ID<.>(#N<.>);->_
+for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<0>;#ID<.>#OP<.>){->for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<1>;#ID<.>#OP<.>){
+#ID<.>.#ID<.>(#LT<0>,#LT<1>);->#ID<.>.#ID<.>(#LT<!0>,#LT<!1>);
+#ID<.>.#ID<.>(#LT<.>);->_
 _->#ID<.>.#ID<.>();
-for(#ID<.>=#N<.>;#ID<.>#OP<0>#N<0>;#ID<.>#OP<.>){->for(#ID<.>=#N<.>;#ID<.>#OP<1>#N<1>;#ID<.>#OP<.>){
-for(#ID<.>=#N<.>;#ID<.>#OP<0>#N<0>;#ID<0>#OP<1>){->for(#ID<.>=#N<.>;#ID<.>#OP<2>#N<1>;#ID<1>#OP<3>){
-if(#ID<.>#OP<0>#N<.>){->if(#ID<.>#OP<1>#N<.>){
-if(#ID<.>#OP<.>#N<0>){->if(#ID<.>#OP<.>#N<1>){
-if(#ID<.>#OP<0>#N<.>){->if(#ID<.>#OP<1>#N<.>){
-#ID<.>.#ID<.>(#N<0>,#N<1>);->#ID<.>.#ID<.>(#N<2>,#N<3>);
-#ID<.>.#ID<.>(#N<.>);->_
-if(#ID<.>#OP<.>#N<0>){->if(#ID<.>#OP<.>#N<1>){
+for(#ID<.>=#LT<.>;#ID<.>#OP<0>#LT<0>;#ID<.>#OP<.>){->for(#ID<.>=#LT<.>;#ID<.>#OP<1>#LT<1>;#ID<.>#OP<.>){
+for(#ID<.>=#LT<.>;#ID<.>#OP<0>#LT<0>;#ID<0>#OP<1>){->for(#ID<.>=#LT<.>;#ID<.>#OP<2>#LT<1>;#ID<1>#OP<3>){
+if(#ID<.>#OP<0>#LT<.>){->if(#ID<.>#OP<1>#LT<.>){
+if(#ID<.>#OP<.>#LT<0>){->if(#ID<.>#OP<.>#LT<1>){
+if(#ID<.>#OP<0>#LT<.>){->if(#ID<.>#OP<1>#LT<.>){
+#ID<.>.#ID<.>(#LT<0>,#LT<1>);->#ID<.>.#ID<.>(#LT<2>,#LT<3>);
 
-if(#ID<.>#OP<0>#N<.>) -> if(#ID<.>#OP<1>#N<.>)
-if(#ID<.>#OP<.>#N<0>) -> if(#ID<.>#OP<.>#N<1>)
+if(#ID<.>#OP<.>#LT<0>){->if(#ID<.>#OP<.>#LT<1>){
 
-#ID<.>.#ID<.>(#N<100>,#N<21321>)->#ID<.>.#ID<.>(#N<23222>,,#N<2312313>
+if(#ID<.>#OP<0>#LT<.>) -> if(#ID<.>#OP<!0>#LT<.>)
+if(#ID<.>#OP<1>#LT<.>) -> if(#ID<.>#OP<1>#LT<.>)
+if(#ID<.>#OP<1>#LT<.>){ -> if(#ID<.>#OP<1>#LT<.>){
 
-if(#ID<.>#OP<0>#N<.>){ -> if(#ID<.>#OP<3>#N<.>){
-if(#ID<.>#OP<1>#N<.>) -> if(#ID<.>#OP<2>#N<.>)
-for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<1>;#ID<.>#OP<.>)->for(#ID<.>=#N<.>;#ID<.>#OP<.>#N<2>;#ID<.>#OP<.>)
\ No newline at end of file
+#ID<.>.#ID<.>(#LT<100>,#LT<21321>)->#ID<.>.#ID<.>(#LT<23222>,,#LT<2312313>
+
+if(#ID<.>#OP<0>#LT<.>){ -> if(#ID<.>#OP<3>#LT<.>){
+if(#ID<.>#OP<1>#LT<.>) -> if(#ID<.>#OP<2>#LT<.>)
+for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<1>;#ID<.>#OP<.>)->for(#ID<.>=#LT<.>;#ID<.>#OP<.>#LT<2>;#ID<.>#OP<.>)
+_ ->#ID<.>.#ID<.>(#LT<.>,#LT<.>);
diff --git a/code/git_changes.txt b/code/git_changes.txt
index b106a2d..3276ed5 100644
--- a/code/git_changes.txt
+++ b/code/git_changes.txt
@@ -7,12 +7,15 @@ index d58db74..f1c27f0 100644
  
     public static void main(String[] args) {
 
--        for(j=0;j<2;j++){
-+        for(j=0;j<3;j++){
+-              if(y>0){
++              if(y>5){
+
+-              if(y==0){
++              if(y!=0){
 
          Scanner s= new Scanner(System.in);
 
-         System.out.println("Geometry Area:\n1)Circle\n2)Rectangle\n3)Triangle\n");
+         System.out.println("Geometry Area:\n");
 
          switch(i) {
             case 1:
@@ -30,45 +33,27 @@ index d58db74..f1c27f0 100644
         }
 
 
-diff --git a/Area.java b/Area.java
+diff --git a/main.cpp b/main.cpp
 index d58db74..f1c27f0 100644
---- a/Area.java
-+++ b/Area.java
-@@ -3,24 +3,23 @@ import java.util.Scanner;
- public class Area {
+--- a/main.cpp
++++ b/maoin.cpp
+@@ -16,10 +16,10 @@ int main()
  
-    public static void main(String[] args) {
+    //add a call method
 
--        for(j=0;j>0;j++){
-+        for(j=0;j<1;j++){
+-    if(n>2)
++    if(n<2)
+      myfile << n;
 
--        for(j=0;j>0;i--){
-+        for(j=0;j<1;j++){
+-    while(i<1){
++    while(i>1){
+        cout << "The result is: " << sub(x2,x1) << endl; //swap arguments DONE
+        i++;
+    }
+@@ -32,7 +32,7 @@ int main()
 
-         Scanner s= new Scanner(System.in);
-
-         System.out.println("Geometry Area:\n1)Circle\n2)Rectangle\n3)Triangle\n");
 
--              if(x>0){
-+              if(x<0){
 
--              if(y>0){
-+              if(y>5){
-
--              if(y==0){
-+              if(y!=0){
-
-         switch(i) {
-            case 1:
--              Area.circle(6,7);
-+              Area.circle(5,5);
-              break;
-            case 2:
--              Area.rectangle(3);
-               Area.rectangle(2,1);
-              break;
-            default:
--              if(y>9){
-+              if(y>1){
-          }
-        }
+-    return 0;
++    return -1;
+}
diff --git a/code/git_functions.py b/code/git_functions.py
index 059745e..36e35a4 100644
--- a/code/git_functions.py
+++ b/code/git_functions.py
@@ -25,9 +25,9 @@ def git_clone():
 def git_log(repository):
     commit_log = []
 
-    command = "cd " + repository + "&& git log > git_log.txt"
+    command = "git log > ./test-changes/git_log.txt"
     os.system(command)
-    filename = repository + "/git_log.txt"
+    filename ="test-changes/git_log.txt"
 
     with open(filename) as fp:
         for line in fp:
@@ -45,9 +45,9 @@ def git_log(repository):
 #Compute the git diff
 def git_diff(commit_log, repository):
 
-    command = "echo '' > git_changes.txt"
+    command = "echo '' > ./test_changes/git_changes.txt"
     os.system(command)
 
     for i in commit_log:
-        command = "cd " + repository + "&& git diff " + i + " HEAD >> git_changes.txt"
+        command = "cd ./test-changes && git diff " + i + " HEAD >> git_changes.txt"
         os.system(command)
\ No newline at end of file
diff --git a/code/main.py b/code/main.py
index 2a8683c..c95c46d 100644
--- a/code/main.py
+++ b/code/main.py
@@ -19,7 +19,7 @@ def main():
             git_functions.git_diff(git_functions.git_log(repository), repository)
 
     #Insertion of the query
-    query = input("Insert a query: ")
+    query = input("Please, insert a query: ")
 
     start_time = time.time()
 
@@ -29,13 +29,26 @@ def main():
     #Computation of similarity in different ways(cosine distance and jaccard index)
     position = 0
     ngrams = 3
+
     #[0] cosine distance threshold [1] jaccard distance threshold
-    thresholds = [0.1, 0.1]
+    thresholds = [0.83, 0.8]
+    ranked_list = []
+
+    query_tokens, query_ngrams = my_functions.query_normalization(query,ngrams)
 
+    my_functions.dataset_csv(changes_list_real, changes_list_abstract)
+    
     for change in changes_list_abstract:
-        my_functions.similarity(query.replace(' ', '').replace('\n', ''), change, position, ngrams, thresholds, changes_list_real)
+        my_functions.similarity(query_tokens, query_ngrams, change, position, ngrams, thresholds, changes_list_real, ranked_list)
         position += 1
 
+    # sort list with key
+    ranked_list.sort(reverse=True, key=my_functions.takeSecond)
+
+    print("\nThe changes found are:\n ")
+    for i in ranked_list:
+        print(i[0] + ' cosine: ' + i[1] + ' jaccard: ' +  i[2])
+
     #Programs ends
     end = time.time()
     print("\nThe program ends in:", round(end - start_time,1), "seconds. Total changes in the repository: ", position) 
diff --git a/code/my_functions.py b/code/my_functions.py
index f025d9c..1d55af1 100644
--- a/code/my_functions.py
+++ b/code/my_functions.py
@@ -7,6 +7,8 @@ from math import*
 from decimal import Decimal
 import copy
 from collections import Counter
+import csv
+from itertools import zip_longest
 import antlr4 
 
 import sys
@@ -22,6 +24,10 @@ def diff(first, second):
     else:
         return [i for i in range(len(first)) if first[i] != second[i]]
 
+#Take second element for list sorting key
+def takeSecond(elem):
+    return elem[1]
+    
 #Compute ngram of a string
 def ngram(change, ngrams):
     ngrams_list = {}
@@ -64,7 +70,7 @@ def antlr4_AbstractGrammar_Tokenizer(query):
 
     return list_abstract_token
 
-#Exacrt the changes from the git diff file
+#Extract the changes from the git diff file
 def analyze_diff_file(filename):
     temporary_array = []
     changes_list = []
@@ -149,10 +155,10 @@ def scanner(changes_list):
                     else:
                         if token.isdigit():
                             if(count in diff1 and bool == False):
-                                old[count] = '#N<' + str(n_num) + '>'
+                                old[count] = '#LT<' + str(n_num) + '>'
                                 n_num = n_num + 1 
                             else:    
-                                old[count] = '#N<.>'
+                                old[count] = '#LT<.>'
                         else: 
                             if(count in diff1 and bool == False):
                                 old[count] = '#ID<' + str(n_id) + '>'
@@ -163,6 +169,9 @@ def scanner(changes_list):
             count = count + 1
 
         count = 0
+        n_op = 0
+        n_id = 0
+        n_num = 0
 
         for token in new:
             if token == 'if' or token == 'else' or token =='for' or token =='while' or token =='forEach' or token =='while' or token =='return' or token =='NULL':
@@ -182,10 +191,10 @@ def scanner(changes_list):
                     else:
                         if token.isdigit():
                             if(count in diff1 and bool == False):
-                                new[count] = '#N<' + str(n_num) + '>'
+                                new[count] = '#LT<' + str(n_num) + '>'
                                 n_num = n_num + 1 
                             else:    
-                                new[count] = '#N<.>'
+                                new[count] = '#LT<.>'
                         else: 
                             if(count in diff1 and bool == False):
                                 new[count] = '#ID<' + str(n_id) + '>'
@@ -219,15 +228,13 @@ def scanner(changes_list):
 #Compute cosine similarity
 def cosine_similarity_ngrams(a, b):
 
-    vec1 = Counter(a)
-    vec2 = Counter(b)
+    v1 = Counter(a)
+    v2 = Counter(b)
     
-    intersection = set(vec1.keys()) & set(vec2.keys())
-    numerator = sum([vec1[x] * vec2[x] for x in intersection])
+    intersection = set(v1.keys()) & set(v2.keys())
 
-    sum1 = sum([vec1[x]**2 for x in vec1.keys()])
-    sum2 = sum([vec2[x]**2 for x in vec2.keys()])
-    denominator = math.sqrt(sum1) * math.sqrt(sum2)
+    numerator = sum([v1[x] * v2[x] for x in intersection])
+    denominator = math.sqrt(sum([v1[x]**2 for x in v1.keys()])) * math.sqrt(sum([v2[x]**2 for x in v2.keys()]))
 
     if not denominator:
         return 0.0
@@ -240,22 +247,76 @@ def getNgrams(string, n):
 #Compute Jaccard index similarity
 def jaccard_similarity(x,y):
  
- intersection_cardinality = len(set.intersection(*[set(x), set(y)]))
- union_cardinality = len(set.union(*[set(x), set(y)]))
+    intersection = len(set.intersection(*[set(x), set(y)]))
+    union = len(set.union(*[set(x), set(y)]))
  
- return intersection_cardinality/float(union_cardinality)
+    return intersection/float(union)
 
 #Compute the similarity between query and one change using different similarity algorithm. Print the change if over thresholds 
-def similarity(query, change, position, ngram, thresholds, changes_list_real):
+def similarity(query_tokens, query_ngrams, change, position, ngram, thresholds, changes_list_real, ranked_list):
+
+    temporary_list = []
 
-    ngrams_list1 = getNgrams(query, ngram)
+    #ngrams_list1 = getNgrams(query, ngram)
     ngrams_list2 = getNgrams(change, ngram)
 
-    abstract_tokens1 = antlr4_AbstractGrammar_Tokenizer(query)
+    #abstract_tokens1 = antlr4_AbstractGrammar_Tokenizer(query)
     abstract_tokens2 = antlr4_AbstractGrammar_Tokenizer(change)
 
-    cosine_score = cosine_similarity_ngrams(ngrams_list1,ngrams_list2)
-    jaccard_score = jaccard_similarity(abstract_tokens1, abstract_tokens2)
+    cosine_score = cosine_similarity_ngrams(query_ngrams,ngrams_list2)
+    jaccard_score = jaccard_similarity(query_tokens, abstract_tokens2)
    
     if cosine_score > thresholds[0] and jaccard_score > thresholds[1] :
-        print(changes_list_real[position] + ' cosine: ' + str(round(cosine_score,2)) + ' jaccard: ' + str(round(jaccard_score,2)))#+ ' eucledian: ' + str(round(eucledian_score,2)))
+        
+        temporary_list.append(changes_list_real[position])
+        temporary_list.append(str(round(cosine_score,2)))
+        temporary_list.append(str(round(jaccard_score,2)))
+
+        ranked_list.append(temporary_list)
+
+#Query digits normalization and n-grams and tokens computation
+def query_normalization(query, ngrams):
+    query_normalize = []
+
+    id = 0
+    op = 0
+    lt = 0
+    n = 0
+    l = len(str(query))
+
+    for n in range(0, l):
+        if(query[n] == '-'):
+                id = 0
+                op = 0
+                lt = 0
+
+                query_normalize.append(query[n])
+        else:
+            if query[n].isdigit():
+                if(n > 1):
+                    if(query[n-2] == 'D'):
+                        query_normalize.append(str(id))
+                        id += 1
+                    else:
+                        if(query[n-2] == 'P'):
+                            query_normalize.append(str(op))
+                            op += 1
+                        else:
+                           # if(query[n-2] == 'T'):
+                                query_normalize.append(str(lt))
+                                lt += 1
+                else: 
+                    query_normalize.append(query[n])
+            else: 
+                    query_normalize.append(query[n])
+
+        
+        n += 1
+
+    query_n = ''.join(query_normalize).replace(' ', '').replace('\n', '')
+
+    query_tokens = antlr4_AbstractGrammar_Tokenizer(query_n)
+    query_ngrams = getNgrams(query_n, ngrams)
+    
+
+    return query_tokens, query_ngrams
diff --git a/code/tests.py b/code/tests.py
index 6e72061..9b25953 100644
--- a/code/tests.py
+++ b/code/tests.py
@@ -1,41 +1,32 @@
+ #  stream = antlr4.CommonTokenStream(lexer)
+   # parser = SearchParser(stream)
+   # tree = parser.query()
+    #printer = SearchPrintListener()
+   # walker = antlr4.ParseTreeWalker()
+    #walker.walk(printer, tree)
+  #  print(tree.toStringTree())
+    
 import antlr4 
 
 import sys
-# insert at 1, 0 is the script path (or '' in REPL)
-sys.path.insert(1, './antlr4')
-
+sys.path.insert(1, './code/antlr4')
 from SearchLexer import SearchLexer
 from SearchListener import SearchListener
 from SearchParser import SearchParser
 
-#echo "3 * 3 - 2 + 2 * 2" | python main.py
-
 class SearchPrintListener(SearchListener):
-    def enterSearch(self, ctx):
-        print("Search: %s" % ctx.ID())
+    def enterHi(self, ctx):
+        print("Hello: %s" % ctx.ID())
 
-def antlr4_AbstractGrammar_Tokenizer(query):
+def main(query):
     lexer = SearchLexer(antlr4.InputStream(query))
-    list_abstract_token = []
-    while(1):
-        token = lexer.nextToken()
-        if(token.text == '<EOF>'):
-            break
-        list_abstract_token.append(token.text)
-
-    
-    for i in list_abstract_token:
-       print(i)
-
-    return list_abstract_token
-  #  stream = antlr4.CommonTokenStream(lexer)
-   # parser = SearchParser(stream)
-   # tree = parser.query()
-    #printer = SearchPrintListener()
-   # walker = antlr4.ParseTreeWalker()
-    #walker.walk(printer, tree)
-  #  print(tree.toStringTree())
-    
+    stream = antlr4.CommonTokenStream(lexer)
+    parser = SearchParser(stream)
+    tree = parser.query()
+    printer = SearchPrintListener()
+    walker = antlr4.ParseTreeWalker()
+    walker.walk(printer, tree)
+    #print(tree.toStringTree())
 
 if __name__ == '__main__':
-    antlr4_AbstractGrammar_Tokenizer('if(#ID<.>#OP<0>#N<.>) -> if(#ID<.>#OP<3>#N<.>)')
+    main('if(#ID<.>#OP<1>#LT<.>){ -> if(#ID<.>#OP<1>#LT<.>){<')
